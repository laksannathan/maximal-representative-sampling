The ROC curve provides in-sight into trade-offs between the classiﬁer’s accuracies onpositive versus negative examples over a range of decisionthresholds. 
Although model learning and performance evaluation in asupervised setting are well understood (Hastie et al. 2001),the availability of unlabeled data gives additional optionsand also presents new challenges. A typical semi-supervisedscenario involves the availability of positive, negative and(large quantities of) unlabeled data. Here, the unlabeled datacan be used to improve training (Blum and Mitchell 1998) orunbias the labeled data (Cortes et al. 2008); e.g., to estimateclass proportions that are necessary to calibrate the modeland accurately estimate precision when class balances (butnot class-conditional distributions) in labeled data are notrepresentative (Saerens et al. 2002). This is often the casewhen it is more expensive or difﬁcult to label examples ofone class than the examples of the other. 

Such perfor-mance estimation often involves computing the fraction(s)of correctly and incorrectly classiﬁed examples from bothclasses; however, in absence of labeled negatives, the frac-tions computed under the non-traditional evaluation are in-correct, resulting in biased estimates. Figure 1 illustratesthe effect of this bias by showing the traditional and non-traditional ROC curves on a handmade data set. Becausesome of the unlabeled examples in the training set are infact positive, the area under the ROC curve estimated whenthe unlabeled examples were considered negative (non-traditional setting) underestimates the true performance forpositive versus negative classiﬁcation (traditional setting).This paper formalizes and evaluates performance estima-tion of a non-traditional classiﬁer in the traditional settingwhen the only available training data are (possibly noisy)positive examples and unlabeled data. hough the efﬁcacy of non-traditional classiﬁers has beenthoroughly studied (Peng et al. 2003; Elkan and Noto 2008;Ward et al. 2009; Menon et al. 2015), estimating their true performance has been much less explored. be recov-ered with the knowledge of class priors. results in biased empirical estimates of the classiﬁer performance
