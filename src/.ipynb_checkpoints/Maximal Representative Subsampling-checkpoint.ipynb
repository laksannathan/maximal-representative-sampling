{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Maximal Representative Subsampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import roc_curve  \n",
    "\n",
    "path = Path(os.getcwd()).parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRS ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_sample(softmax, temperature):\n",
    "\n",
    "    EPSILON = 10e-16\n",
    "    softmax = (np.array(softmax) + EPSILON).astype('float64')\n",
    "    \n",
    "    preds = np.log(softmax) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "\n",
    "    return probas[0]\n",
    "\n",
    "def plot_roc(fpr, tpr):\n",
    "    \n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def get_size_of_minority_class(df, label):\n",
    "    return min(len(df[df[label]==1]), len(df[df[label]==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MRS(nonrep: pd.DataFrame, \n",
    "        rep: pd.DataFrame, \n",
    "        columns,\n",
    "        temp,  \n",
    "        drop, \n",
    "        ensemble_size):\n",
    "    \n",
    "    AUC = []\n",
    "    \n",
    "    nonrep['label'] = 1\n",
    "    rep['label'] = 0\n",
    "    \n",
    "    df = pd.concat([nonrep, rep], sort=True)\n",
    "    \n",
    "    for drop_count in range(drop):\n",
    "        print(drop_count)\n",
    "    \n",
    "        df['preds'] = 0\n",
    "        n = get_size_of_minority_class(df, 'label')\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        for train_index, test_index in StratifiedKFold(n_splits=2).split(df, df.label):\n",
    "            \n",
    "            train, test = df.loc[train_index], df.loc[test_index]\n",
    "            \n",
    "            grid = GridSearchCV(LinearSVC(max_iter=1000000),\n",
    "                                param_grid={'C': [0.01, 0.02, 0.05, 0.1]}, \n",
    "                                cv=2, iid=True)\n",
    "            grid.fit(train[columns], train.label)\n",
    "\n",
    "            for _ in range(ensemble_size):\n",
    "\n",
    "                bootstrap = train.sample(n=len(train), random_state=1, replace=True)\n",
    "\n",
    "                linear_svc = LinearSVC(C=grid.best_estimator_.C, max_iter=1000000)\n",
    "                clf = CalibratedClassifierCV(linear_svc, method='sigmoid', cv=2)\n",
    "                clf.fit(bootstrap[columns], bootstrap.label)\n",
    "\n",
    "                df.loc[test_index]['preds'] = [(a[0]/ensemble_size)+b for a,b in zip(clf.predict_proba(test[columns]), \n",
    "                                                                                     test.preds)]\n",
    "                print(df)\n",
    "        AUC.append(metrics.roc_auc_score(test.label, test.preds))\n",
    "        \n",
    "        df['removed'] = temp_sample(df.preds, temp)\n",
    "        df = df[df['removed'] == 0]\n",
    "        \n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "auc = MRS(nonrep=gbs, rep=gesis, columns=cols, temp=0.25, ensemble_size=2, drop=5)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US National Census (Income) <a name=\"us\"></a>\n",
    "\n",
    "*About this Dataset*\n",
    "\n",
    "**US Adult Census** (1994) relates income to social factors: \n",
    "\n",
    "- *age*: continuous.\n",
    "- *workclass*: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "- *fnlwgt*: continuous.\n",
    "- *education*: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "- *education-num*: continuous.\n",
    "- *marital-status*: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "- *occupation*: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "- *relationship*: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "- *race*: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "- *sex*: Female, Male.\n",
    "- *capital-gain*: continuous.\n",
    "- *capital-loss*: continuous.\n",
    "- *hours-per-week*: continuous.\n",
    "- *native-country*: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n",
    "Each row is labelled as either having a salary greater than \">50K\" or \"<=50K\".\n",
    "\n",
    "Note: This Dataset was obtained from the UCI repository, it can be found on\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/census+income, http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: \n",
      "  <=50K    200\n",
      " >50K     200\n",
      "Name: Above/Below 50K, dtype: int64 \n",
      "\n",
      "Nonrep: \n",
      "  <=50K    200\n",
      " >50K     200\n",
      "Name: Above/Below 50K, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Above/Below 50K</th>\n",
       "      <th>Age</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Country_ ?</th>\n",
       "      <th>Country_ Cambodia</th>\n",
       "      <th>Country_ Canada</th>\n",
       "      <th>Country_ China</th>\n",
       "      <th>Country_ Columbia</th>\n",
       "      <th>Country_ Cuba</th>\n",
       "      <th>...</th>\n",
       "      <th>Workclass_ Federal-gov</th>\n",
       "      <th>Workclass_ Local-gov</th>\n",
       "      <th>Workclass_ Never-worked</th>\n",
       "      <th>Workclass_ Private</th>\n",
       "      <th>Workclass_ Self-emp-inc</th>\n",
       "      <th>Workclass_ Self-emp-not-inc</th>\n",
       "      <th>Workclass_ State-gov</th>\n",
       "      <th>Workclass_ Without-pay</th>\n",
       "      <th>fnlgwt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>267540.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125492.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93977.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46395.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101480.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Above/Below 50K Age  Capital Gain  Capital Loss  Country_ ?  \\\n",
       "0           <=50K  38           0.0           0.0           0   \n",
       "1           <=50K  46           0.0           0.0           0   \n",
       "2           <=50K  23           0.0           0.0           0   \n",
       "3           <=50K  39           0.0           0.0           0   \n",
       "4           <=50K  58           0.0           0.0           0   \n",
       "\n",
       "   Country_ Cambodia  Country_ Canada  Country_ China  Country_ Columbia  \\\n",
       "0                  0                0               0                  0   \n",
       "1                  0                0               0                  0   \n",
       "2                  0                0               0                  0   \n",
       "3                  0                0               0                  0   \n",
       "4                  0                0               0                  0   \n",
       "\n",
       "   Country_ Cuba  ...    Workclass_ Federal-gov  Workclass_ Local-gov  \\\n",
       "0              0  ...                         0                     0   \n",
       "1              0  ...                         0                     0   \n",
       "2              0  ...                         0                     0   \n",
       "3              0  ...                         0                     0   \n",
       "4              0  ...                         0                     1   \n",
       "\n",
       "   Workclass_ Never-worked  Workclass_ Private  Workclass_ Self-emp-inc  \\\n",
       "0                        0                   0                        0   \n",
       "1                        0                   1                        0   \n",
       "2                        0                   1                        0   \n",
       "3                        0                   1                        0   \n",
       "4                        0                   0                        0   \n",
       "\n",
       "   Workclass_ Self-emp-not-inc  Workclass_ State-gov  Workclass_ Without-pay  \\\n",
       "0                            0                     1                       0   \n",
       "1                            0                     0                       0   \n",
       "2                            0                     0                       0   \n",
       "3                            0                     0                       0   \n",
       "4                            0                     0                       0   \n",
       "\n",
       "     fnlgwt  label  \n",
       "0  267540.0      1  \n",
       "1  125492.0      1  \n",
       "2   93977.0      1  \n",
       "3   46395.0      1  \n",
       "4  101480.0      1  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Age','Workclass','fnlgwt','Education','Education Num','Marital Status',\n",
    "           'Occupation','Relationship','Race','Sex','Capital Gain','Capital Loss',\n",
    "           'Hours/Week','Country','Above/Below 50K']\n",
    "\n",
    "train = pd.read_csv(os.path.join(path, 'data/census_income/adult.data'), names=columns)\n",
    "test = pd.read_csv(os.path.join(path, 'data/census_income/adult.test'), names=columns)\n",
    "test = test.iloc[1:]\n",
    "\n",
    "df = pd.concat([train, test]).copy(deep=True)\n",
    "\n",
    "del train, test\n",
    "\n",
    "df.replace(' >50K.', ' >50K', inplace=True)\n",
    "df.replace(' <=50K.', ' <=50K', inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "ctg = ['Workclass', 'Sex', 'Education', 'Marital Status', \n",
    "       'Occupation', 'Relationship', 'Race', 'Country']\n",
    "for c in ctg:\n",
    "    df = pd.concat([df, pd.get_dummies(df[c], \n",
    "                                       prefix=c,\n",
    "                                       dummy_na=False)], axis=1).drop([c],axis=1)\n",
    "\n",
    "'''Rep: <=50K    37155 ;; >50K     11687'''\n",
    "\n",
    "df_high = df[df['Above/Below 50K'] == \" >50K\"].copy(deep=True)\n",
    "df_low = df[df['Above/Below 50K'] == \" <=50K\"].copy(deep=True)\n",
    "\n",
    "df_low = df_low.reindex(np.random.permutation(df_low.index))\n",
    "df_high = df_high.reindex(np.random.permutation(df_high.index))\n",
    "\n",
    "rep = pd.concat([df_low.head(200).copy(deep=True),\n",
    "                 df_high.head(200).copy(deep=True)], sort=True)\n",
    "\n",
    "nonrep = pd.concat([df_low.tail(200).copy(deep=True),\n",
    "                    df_high.tail(200).copy(deep=True)], sort=True)\n",
    "\n",
    "print('Rep: \\n', rep['Above/Below 50K'].value_counts(), '\\n')\n",
    "print('Nonrep: \\n', nonrep['Above/Below 50K'].value_counts())\n",
    "\n",
    "nonrep['label'] = 1\n",
    "rep['label'] = 0\n",
    "\n",
    "del df, df_low, df_high\n",
    "\n",
    "us = pd.concat([nonrep, rep], sort=True)\n",
    "\n",
    "us_columns = list(us.columns)\n",
    "meta = ['label', 'Above/Below 50K', 'index', 'bootstrap']\n",
    "for m in meta:\n",
    "    if m in us_columns:\n",
    "        us_columns.remove(m)\n",
    "\n",
    "us.reset_index(drop=True, inplace=True)\n",
    "us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e763a6c4e6e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mus_nonrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMRS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnonrep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mus_nonrep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mus_rep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mus_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensemble_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-6bd538d8afd8>\u001b[0m in \u001b[0;36mMRS\u001b[1;34m(nonrep, rep, columns, temp, drop, ensemble_size)\u001b[0m\n\u001b[0;32m     27\u001b[0m                                 \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                                 cv=1, iid=True)\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensemble_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laksa\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    649\u001b[0m                 \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         scorers, self.multimetric_ = _check_multimetric_scoring(\n",
      "\u001b[1;32mc:\\users\\laksa\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[1;34m(cv, y, classifier)\u001b[0m\n\u001b[0;32m   2057\u001b[0m         if (classifier and (y is not None) and\n\u001b[0;32m   2058\u001b[0m                 (type_of_target(y) in ('binary', 'multiclass'))):\n\u001b[1;32m-> 2059\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laksa\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNSPLIT_WARNING\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_test_folds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laksa\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    287\u001b[0m                 \u001b[1;34m\"k-fold cross-validation requires at least one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[1;34m\" train/test split by setting n_splits=2 or more,\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                 \" got n_splits={0}.\".format(n_splits))\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=1."
     ]
    }
   ],
   "source": [
    "us_rep = us[us['label'] == 0].copy()\n",
    "us_nonrep = us[us['label'] == 1].copy()\n",
    "\n",
    "auc = MRS(nonrep=us_nonrep, rep=us_rep, columns=us_columns, temp=0.25, ensemble_size=5, drop=10)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allensbach = pd.read_csv(os.path.join(path, 'data/allensbach_mrs.csv'))\n",
    "\n",
    "allensbach.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "allensbach_columns = ['BRS1', 'BRS2', 'BRS3', 'BRS4', 'BRS5', 'BRS6', \n",
    "                      'Berufsgruppe', 'Erwerbstätigkeit', 'Geschlecht',\n",
    "                      'Optimismus', 'Pessimismus', 'Schulabschluss', 'woechentlicheArbeitszeit']\n",
    "allensbach.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesis = pd.read_csv(os.path.join(path, 'data/gesis_processed.csv'), engine='python')\n",
    "gbs = pd.read_csv(os.path.join(path, 'data/gbs_processed.csv'), engine='python')\n",
    "\n",
    "gesis = gesis[gesis.Wahlteilnahme != 0.5] #drop gesis where wahlteilnahme unknown\n",
    "\n",
    "absicht = {3:0.5, 2:0, 1:0}\n",
    "gbs = gbs.replace({'Wahlabsicht': absicht})\n",
    "absicht2 = {5:1, 4:1}\n",
    "gbs = gbs.replace({'Wahlabsicht': absicht2})\n",
    "\n",
    "gesis['label'] = 0\n",
    "gbs['label'] = 1\n",
    "\n",
    "cols = ['Geschlecht', 'Geburtsjahr', 'Nationalitaet', 'Geburtsland', 'Nettoeinkommen Selbst',\n",
    "        'Nettoeinkommen Haushalt', 'Personen im Haushalt', 'Berufsgruppe',\n",
    "       'Resilienz', 'Wahlteilnahme', 'Wahlabsicht', 'Hoechster Bildungsabschluss',\n",
    "       'Familienstand', 'Erwerbstaetigkeit'] \n",
    "        \n",
    "de = 'Aktiv', 'Schlechter Schlaf', 'Leben genießen', 'Alles anstrengend', 'Berufliche Ausbildung'\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(pd.concat([gesis, gbs], sort = False)[cols].values)\n",
    "gesis[cols] = scaler.transform(gesis[cols]) \n",
    "gbs[cols] = scaler.transform(gbs[cols]) \n",
    "\n",
    "'''\n",
    "Desinteresse Politiker\n",
    "'Wach', 'Zurueckhaltend', 'Zufriedenheit Wahlergebnis',\n",
    "'leicht Vertrauen', 'Faulheit', 'Entspannt',\n",
    "'wenig kuenstlerisches Interesse', 'Gesellig',\n",
    "'Andere kritisieren',\n",
    "'Schlechter Schlaf', 'Leben genießen',\n",
    "'Zu Nichts aufraffen', 'Alles anstrengend', '\n",
    "'Gruendlich', 'Nervoes', 'Phantasievoll', 'Optimismus Zukunft\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    plt.plot([a[0] for a in auc[i]], [a[1] for a in auc[i]], label='GBS')\n",
    "    plt.xlabel(\"removed instances\")\n",
    "    \n",
    "\n",
    "plt.plot([a[0] for a in auc[i]], len(auc[i])*[0.5], linestyle='--', label='random')\n",
    "plt.grid()\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('Multiple Runs: GBS vs GESIS')\n",
    "plt.savefig('GBS-GESIS___.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"removed instances\")\n",
    "plt.plot(auc, len(auc[i])*[0.5], linestyle='--', label='random')\n",
    "plt.plot(auc for a in auc[i], [a[1] for a in auc[i]], label='GBS')\n",
    "plt.grid()\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('GBS vs GESIS')\n",
    "plt.savefig('GBS-GESIS___withCV.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allens = allensbach[allensbach.label==0]\n",
    "gbs_a = allensbach[allensbach.label==1]\n",
    "\n",
    "auc_2 = []\n",
    "\n",
    "C = [0.001, 0.002, 0.005, 0.008, 0.01, 0.015, 0.02, 0.05, 0.1, 0.2, 0.5, 0.7]\n",
    "for T in [0.1, 0.15, 0.2]:\n",
    "    auc_2.append(MRS(nonrep=gbs_a, rep=allens, columns=allensbach_columns,\n",
    "                     temperature=T, ensemble_size=10, n_drop=10, limit=15, C=C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    #plt.figure(figsize=(12,10), dpi=80)\n",
    "    plt.plot([a[0] for a in auc_2[i]], [a[1] for a in auc_2[i]], label='GBS')\n",
    "    plt.xlabel(\"removed instances\")\n",
    "    \n",
    "plt.plot([a[0] for a in auc_2[i]], len(auc_2[i])*[0.5], linestyle='--', label='random')\n",
    "plt.grid()\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('Multiple Runs: GBS vs Allensbach')\n",
    "plt.savefig('GBS-Allensbach___.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Political Participation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBS (Original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbs_ori = gbs.copy(deep=True)\n",
    "\n",
    "gbs_ori.drop('Wahlabsicht', axis=1, inplace=True)\n",
    "cols.remove('Wahlabsicht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbs_ori['Class'] = [False if i < 0 else True for i in gbs_ori[\"Wahlteilnahme\"]]\n",
    "\n",
    "print(gbs_ori['Class'].value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(gbs_ori[cols], gbs_ori.Class, test_size=0.33, \n",
    "                                                    random_state=42)\n",
    "\n",
    "\n",
    "tuned_parameters = [{'C': [0.001, 0.002, 0.005, 0.01, 0.05,\n",
    "                     0.1, 0.2, 0.5, 1, 2 , 5, 10, 25, 50, \n",
    "                     75, 100, 150, 200, 500, 1000]}]\n",
    "\n",
    "clf = GridSearchCV(LinearSVC(C=1, max_iter=1_000_000), tuned_parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_params_)\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(C=0.5, random_state=0, tol=1e-5, max_iter=1_000_000)\n",
    "clf.fit(X_train[cols], y_train)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, preds)\n",
    "\n",
    "#metrics compare preds and y_test.\n",
    "\n",
    "#del X_train, y_train, X_test,  y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBS (MRS-Sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbs_mrs = nonrep.copy(deep=True)\n",
    "\n",
    "print(gbs_mrs['Wahlteilnahme'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbs_mrs['Class'] = [False if i < 0 else True for i in gbs_mrs[\"Wahlteilnahme\"]]\n",
    "\n",
    "print(gbs_mrs['Class'].value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(gbs_mrs[cols], gbs_mrs.Class, test_size=0.33, \n",
    "                                                    random_state=42)\n",
    "\n",
    "\n",
    "tuned_parameters = [{'C': [0.001, 0.002, 0.005, 0.01, 0.05,\n",
    "                     0.1, 0.2, 0.5, 1, 2 , 5, 10, 25, 50, \n",
    "                     75, 100, 150, 200, 500, 1000]}]\n",
    "\n",
    "clf = GridSearchCV(LinearSVC(C=1, max_iter=1_000_000), tuned_parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_params_)\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
