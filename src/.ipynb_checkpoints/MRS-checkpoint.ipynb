{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Maximal Representative Subsampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert- block alert-warning\"> <b>Todo:</b> \n",
    "\n",
    "- Use unprundes trees\n",
    "\n",
    "- Try linear svm with C param tuning\n",
    "\n",
    "- next meeting: 5th september 11h.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-189-e52694ce4cc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "np.seterr(divide = 'ignore')\n",
    "import random\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "\n",
    "path = Path(os.getcwd()).parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRS ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_sample(softmax, temperature, drop):\n",
    "\n",
    "    EPSILON = 10e-16 # to avoid taking the log of zero\n",
    "    softmax = (np.array(softmax) + EPSILON).astype('float64')\n",
    "    \n",
    "    preds = np.log(softmax) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(drop, preds, 1)\n",
    "\n",
    "    return probas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bootstrap(df, n):\n",
    "    train = df.sample(n, replace=True)\n",
    "    tmp = df.index.isin(train.index)\n",
    "    test = df[~tmp]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_param_selection(X, y, nfolds):\n",
    "    \n",
    "    svc = LinearSVC(max_iter=1000)\n",
    "    C = [0.001, 0.01, 0.1, 1, 10]\n",
    "    param_grid = {'C': C}\n",
    "    grid = GridSearchCV(estimator=svc, iid=True, param_grid=dict(C=C), cv=nfolds)\n",
    "    grid.fit(X, y)\n",
    "    grid.best_params_\n",
    "    return grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MRS(nonrep, rep, columns, temperature, n_drop, limit, ensemble_size, C=1.0):\n",
    "    \n",
    "    auc = []\n",
    "    \n",
    "    nonrep['label'] = 1\n",
    "    rep['label'] = 0\n",
    "    \n",
    "    while (nonrep.shape[0] > limit):\n",
    "    \n",
    "        nonrep['__preds'] = 0\n",
    "        rep['__preds'] = 0\n",
    "    \n",
    "        nonrep['__count'] = 0\n",
    "        rep['__count'] = 0\n",
    "    \n",
    "        n = min(nonrep.shape[0], rep.shape[0])\n",
    "        print(n, end=', ')\n",
    "        \n",
    "        for _ in range(ensemble_size):\n",
    "\n",
    "            train_nonrep, test_nonrep = _bootstrap(nonrep, n)\n",
    "            train_rep, test_rep = _bootstrap(rep, n)\n",
    "            \n",
    "            train = pd.concat([train_nonrep, train_rep], sort=False)\n",
    "            test = pd.concat([test_nonrep, test_rep], sort=False)\n",
    "            \n",
    "            svm = LinearSVC(C=C, max_iter=1_000_000)\n",
    "            clf = CalibratedClassifierCV(svm, cv=5)\n",
    "            clf.fit(train[columns], train.label)\n",
    "            \n",
    "            test['__preds'] = [i+j[1] for i,j in zip(test['__preds'], clf.predict_proba(test[columns]))]\n",
    "            test['__count'] = [i+1 for i in test['__count']]\n",
    "            \n",
    "            df = pd.concat([train.drop_duplicates(subset=train.columns, keep='first', inplace=False), test])\n",
    "            \n",
    "            nonrep = df[df.label == 1].copy(deep=True)\n",
    "            rep = df[df.label == 0].copy(deep=True)\n",
    "            \n",
    "            del train_nonrep, test_nonrep, train_rep, test_rep, train, test\n",
    "        \n",
    "        oosample = df[df.__count!=0] #predicted at least once\n",
    "        insample = df[df.__count==0] #only used to train\n",
    "        oosample['__preds'] = [i/j for i,j in zip(oosample['__preds'], oosample['__count'])]\n",
    "\n",
    "        auc.append((-n, metrics.roc_auc_score(oosample.label, oosample.__preds)))\n",
    "\n",
    "        del oosample, insample\n",
    "        \n",
    "        drop = df[(df.__count!=0) & (df.label==1)]\n",
    "        keep = df[(df.__count==0) | (df.label==0)]\n",
    "        \n",
    "        drop['removed'] = temp_sample(drop.__preds, temperature, n_drop) \n",
    "        \n",
    "        drop = drop[drop.removed == 0]\n",
    "        drop.drop('removed', axis=1, inplace=True)\n",
    "        \n",
    "        df = pd.concat([drop, keep], sort=True)\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "        del drop, keep\n",
    "        \n",
    "        nonrep = df[df.label==1].copy(deep=True)\n",
    "        rep = df[df.label==0].copy(deep=True)\n",
    "        \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US National Census (Income) <a name=\"us\"></a>\n",
    "\n",
    "*About this Dataset*\n",
    "\n",
    "**US Adult Census** (1994) relates income to social factors: \n",
    "\n",
    "- *age*: continuous.\n",
    "- *workclass*: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "- *fnlwgt*: continuous.\n",
    "- *education*: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "- *education-num*: continuous.\n",
    "- *marital-status*: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "- *occupation*: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "- *relationship*: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "- *race*: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "- *sex*: Female, Male.\n",
    "- *capital-gain*: continuous.\n",
    "- *capital-loss*: continuous.\n",
    "- *hours-per-week*: continuous.\n",
    "- *native-country*: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n",
    "Each row is labelled as either having a salary greater than \">50K\" or \"<=50K\".\n",
    "\n",
    "Note: This Dataset was obtained from the UCI repository, it can be found on\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/census+income, http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Age','Workclass','fnlgwt','Education','Education Num','Marital Status',\n",
    "           'Occupation','Relationship','Race','Sex','Capital Gain','Capital Loss',\n",
    "           'Hours/Week','Country','Above/Below 50K']\n",
    "\n",
    "train = pd.read_csv(os.path.join(path, 'data/census_income/adult.data'), names=columns)\n",
    "test = pd.read_csv(os.path.join(path, 'data/census_income/adult.test'), names=columns)\n",
    "test = test.iloc[1:]\n",
    "\n",
    "df = pd.concat([train, test]).copy(deep=True)\n",
    "\n",
    "del train, test\n",
    "\n",
    "df.replace(' >50K.', ' >50K', inplace=True)\n",
    "df.replace(' <=50K.', ' <=50K', inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "ctg = ['Workclass', 'Sex', 'Education', 'Marital Status', \n",
    "       'Occupation', 'Relationship', 'Race', 'Country']\n",
    "for c in ctg:\n",
    "    df = pd.concat([df, pd.get_dummies(df[c], \n",
    "                                       prefix=c,\n",
    "                                       dummy_na=False)], axis=1).drop([c],axis=1)\n",
    "\n",
    "'''Rep: <=50K    37155 ;; >50K     11687'''\n",
    "\n",
    "df_high = df[df['Above/Below 50K'] == \" >50K\"].copy(deep=True)\n",
    "df_low = df[df['Above/Below 50K'] == \" <=50K\"].copy(deep=True)\n",
    "\n",
    "df_low = df_low.reindex(np.random.permutation(df_low.index))\n",
    "df_high = df_high.reindex(np.random.permutation(df_high.index))\n",
    "\n",
    "rep = pd.concat([df_low.head(5000).copy(deep=True),\n",
    "                 df_high.head(5000).copy(deep=True)], sort=True)\n",
    "\n",
    "nonrep = pd.concat([df_low.tail(5000).copy(deep=True),\n",
    "                    df_high.tail(5000).copy(deep=True)], sort=True)\n",
    "\n",
    "print('Rep: \\n', rep['Above/Below 50K'].value_counts(), '\\n')\n",
    "print('Nonrep: \\n', nonrep['Above/Below 50K'].value_counts())\n",
    "\n",
    "nonrep['label'] = 1\n",
    "rep['label'] = 0\n",
    "\n",
    "del df, df_low, df_high\n",
    "\n",
    "us = pd.concat([nonrep, rep], sort=True)\n",
    "\n",
    "us_columns = list(us.columns)\n",
    "meta = ['label', 'Above/Below 50K', 'index', 'bootstrap']\n",
    "for m in meta:\n",
    "    if m in us_columns:\n",
    "        us_columns.remove(m)\n",
    "\n",
    "us.reset_index(drop=True, inplace=True)\n",
    "us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allensbach = pd.read_csv(os.path.join(path, 'data/allensbach_mrs.csv'))\n",
    "\n",
    "allensbach.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "allensbach_columns = ['BRS1', 'BRS2', 'BRS3', 'BRS4', 'BRS5', 'BRS6', \n",
    "                      'Berufsgruppe', 'Erwerbstätigkeit', 'Geschlecht',\n",
    "                      'Optimismus', 'Pessimismus', 'Schulabschluss', 'woechentlicheArbeitszeit']\n",
    "allensbach.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\laksa\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:24: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "c:\\users\\laksa\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:25: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nDesinteresse Politiker\\n       'Wach', 'Zurueckhaltend', '', 'Zufriedenheit Wahlergebnis',\\n       'leicht Vertrauen', 'Faulheit', 'Entspannt',\\n       'wenig kuenstlerisches Interesse', 'Gesellig',\\n       'Andere kritisieren',\\n'Schlechter Schlaf', 'Leben genießen',\\n       'Zu Nichts aufraffen', 'Alles anstrengend', '\\n       'Gruendlich', 'Nervoes', 'Phantasievoll', 'Optimismus Zukunft']\""
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gesis = pd.read_csv(os.path.join(path, 'data/gesis_processed.csv'), engine='python')\n",
    "gbs = pd.read_csv(os.path.join(path, 'data/gbs_processed.csv'), engine='python')\n",
    "\n",
    "gesis = gesis[gesis.Wahlteilnahme != 0.5] #drop gesis where wahlteilnahme unknown\n",
    "\n",
    "absicht = {3:0.5, 2:0, 1:0}\n",
    "gbs = gbs.replace({'Wahlabsicht': absicht})\n",
    "absicht2 = {5:1, 4:1}\n",
    "gbs = gbs.replace({'Wahlabsicht': absicht2})\n",
    "\n",
    "gesis['label'] = 0\n",
    "gbs['label'] = 1\n",
    "\n",
    "cols = ['Geschlecht', 'Geburtsjahr', 'Nationalitaet', 'Geburtsland', 'Nettoeinkommen Selbst',\n",
    "        'Nettoeinkommen Haushalt', 'Personen im Haushalt', 'Berufsgruppe',\n",
    "       'Resilienz', 'Wahlteilnahme', 'Wahlabsicht', 'Hoechster Bildungsabschluss',\n",
    "       'Familienstand', 'Berufliche Ausbildung', 'Erwerbstaetigkeit'] \n",
    "        \n",
    "de = 'Aktiv', 'Schlechter Schlaf', 'Leben genießen', 'Alles anstrengend'\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(pd.concat([gesis, gbs], sort = False)[cols].values)\n",
    "# is it reasonable to fit scaler on rep and nonrep data?\n",
    "gesis[cols] = scaler.transform(gesis[cols]) \n",
    "gbs[cols] = scaler.transform(gbs[cols]) \n",
    "\n",
    "'''\n",
    "Desinteresse Politiker\n",
    "'Wach', 'Zurueckhaltend', 'Zufriedenheit Wahlergebnis',\n",
    "'leicht Vertrauen', 'Faulheit', 'Entspannt',\n",
    "'wenig kuenstlerisches Interesse', 'Gesellig',\n",
    "'Andere kritisieren',\n",
    "'Schlechter Schlaf', 'Leben genießen',\n",
    "'Zu Nichts aufraffen', 'Alles anstrengend', '\n",
    "'Gruendlich', 'Nervoes', 'Phantasievoll', 'Optimismus Zukunft\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579, 533, 477, 432, 389, 343, "
     ]
    }
   ],
   "source": [
    "for C in [0.001, 0.1, 0.5, 1, 5, 10, 20]:\n",
    "    for T in [0.15]:\n",
    "\n",
    "        auc = MRS(nonrep=gbs, rep=gesis, columns=cols,\n",
    "                  temperature=T, ensemble_size=10, n_drop=100, limit=10, C=C)\n",
    "\n",
    "        plt.plot([a[0] for a in auc], [a[1] for a in auc], \n",
    "                 label='C=' + str(C) + \", T=\" + str(T))\n",
    "        plt.plot([a[0] for a in auc], len(auc)*[0.5], linestyle='--')\n",
    "        plt.xlabel(\"removed instances\")\n",
    "        plt.legend(loc='lower left')\n",
    "        plt.grid()\n",
    "        \n",
    "plt.figure(figsize=(12, 8), dpi=240, facecolor='w', edgecolor='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
