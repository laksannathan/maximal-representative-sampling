{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MRS Algorithm\n",
    "\n",
    "To allow statistical inference in social sciences, survey participants must be selected at random\n",
    "from the target population. When samples are drawn from parts of the population that are\n",
    "close to hand, subgroups might be over-represented. This leads to statistical analyses under\n",
    "sampling bias, which in turn may produce similarly biased outcomes. This notebook uses machine learning to reduce this selection bias in a psychological survey (**GBS**) using auxiliary information (**GESIS**/**Allensbach**) from comparable studies that are known to be representative. The proposed algorithm is first tested on US national Census data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "from cycler import cycler\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.spatial.distance import pdist\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "path = Path(os.getcwd()).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_auc_average(auc_score, std_aucs, drop, file_name, number_of_samples, save, mrs_iterations,\n",
    "                    wide=False):\n",
    "    if wide:\n",
    "        plt.figure(figsize=(6.4 * 2, 4.8)) \n",
    "    aucs_upper = np.minimum(auc_score + std_aucs, 1)\n",
    "    aucs_younger = np.maximum(auc_score - std_aucs, 0)\n",
    "    x_labels = range(number_of_samples, drop, -drop)\n",
    "    plt.fill_between(x_labels, aucs_younger, aucs_upper, color='blue', alpha=0.2)\n",
    "    plt.plot(x_labels, auc_score, color='blue', linestyle='-')\n",
    "    plt.plot((len(x_labels)-1)*drop *[0.5], color='black', linestyle='--', label='Random')\n",
    "    plt.ylabel('AUROC')\n",
    "    mrs_iterations = number_of_samples - np.array(mrs_iterations)\n",
    "    minimum = min(0.5, np.min(aucs_younger))\n",
    "    maximum = plt.gca().get_ylim()[1]\n",
    "    plt.margins(0.05, 0)\n",
    "    plt.vlines(mrs_iterations, minimum, maximum, colors='black', linestyles='solid')\n",
    "    plt.xticks(list(range(number_of_samples, 0, -100)) + [0])\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xlabel('Number of remaining samples')\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    ax2 = plt.gca().twiny()\n",
    "    ax2.set_xlim(xlim)\n",
    "    plt.xticks(list(mrs_iterations))\n",
    "    [tick.set_color(\"blue\") for tick in plt.gca().get_xticklabels()]\n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_auc(auc_score, drop, file_name, number_of_samples, save=False, mrs_iterations=None):\n",
    "    x_labels = range(number_of_samples, 0, -drop)\n",
    "    plt.plot(x_labels, auc_score, color='blue', linestyle='-', label='AUROC')\n",
    "    plt.plot((len(x_labels)-1)*drop *[0.5], color='black', linestyle='--', label='Random')\n",
    "    plt.ylabel('AUROC')\n",
    "\n",
    "    mrs_iterations = number_of_samples - np.array(mrs_iterations)\n",
    "    minimum = min(0.5, np.min(auc_score))\n",
    "    maximum = plt.gca().get_ylim()[1]\n",
    "    plt.margins(0.05, 0)\n",
    "    plt.vlines(mrs_iterations, minimum, maximum, colors='black', linestyles='solid')\n",
    "    plt.xticks(list(range(number_of_samples, 0, -500)) + [0])\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xlabel('Number of remaining samples')\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    ax2 = plt.gca().twiny()\n",
    "    ax2.set_xlim(xlim)\n",
    "    plt.xticks([mrs_iterations])\n",
    "    [tick.set_color(\"blue\") for tick in plt.gca().get_xticklabels()]\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "def plot_rocs(rocs, file_name,  save=False):\n",
    "    default_cycle = (cycler('linestyle',[':','-.', (0, (3, 5, 1, 5, 1, 5)), '-',]) +\n",
    "                    cycler(color=['blue', 'orange', 'orangered', 'cyan']))\n",
    "    plt.rc('')\n",
    "    plt.rc('axes', prop_cycle=default_cycle)\n",
    "    for fper, tper, std, deleted_elements in rocs:\n",
    "        tpfrs_higher = np.minimum(tper + std, 1)\n",
    "        tpfrs_lower = np.maximum(tper - std, 0)\n",
    "        plt.plot(fper, tper, label=f'{int(deleted_elements[0])} samples removed')\n",
    "        plt.fill_between(fper, tpfrs_lower, tpfrs_higher, alpha=0.2)\n",
    "    plt.plot([0, 1], [0, 1], color='black', linestyle='--', label='Random', linewidth=0.8)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_mmds(mmds, drop, mmd_iteration, file_name, mrs_iterations, number_of_samples, save=False):\n",
    "    x_labels = range(number_of_samples, 0, -drop * mmd_iteration)\n",
    "    plt.plot(x_labels, mmds, linestyle='-')\n",
    "    minimum =  np.min(mmds)\n",
    "    maximum = plt.gca().get_ylim()[1]\n",
    "    plt.margins(0.05, 0)\n",
    "    mrs_iterations = number_of_samples - np.array(mrs_iterations)\n",
    "    plt.vlines(mrs_iterations, minimum, maximum, colors='black', linestyles='solid')\n",
    "    plt.ylabel('Maximum Mean Discrepancy')\n",
    "    plt.xlabel('Number of remaining samples')\n",
    "    plt.xticks(list(range(number_of_samples, 0, -500)) + [0])\n",
    "    plt.gca().invert_xaxis()\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    ax2 = plt.gca().twiny()\n",
    "    ax2.set_xlim(xlim)\n",
    "    plt.xticks([mrs_iterations])\n",
    "    [tick.set_color(\"blue\") for tick in plt.gca().get_xticklabels()]\n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_mmds_average(mmds, std, drop, mmd_iteration, file_name, mrs_iterations,\n",
    "                      number_of_samples, save=False):\n",
    "    mmds_upper = np.minimum(mmds + std, 1)\n",
    "    mmds_more_negative = np.maximum(mmds - std, 0)\n",
    "    x_labels = range(number_of_samples, drop*mmd_iteration, -drop*mmd_iteration)\n",
    "    plt.fill_between(x_labels, mmds_more_negative, mmds_upper, color='black', alpha=0.2)\n",
    "    plt.plot(x_labels, mmds, linestyle='-')\n",
    "    minimum = np.min(mmds_more_negative)\n",
    "    maximum = plt.gca().get_ylim()[1]\n",
    "    plt.margins(0.05, 0)\n",
    "    mrs_iterations = number_of_samples - np.array(mrs_iterations)\n",
    "    plt.vlines(mrs_iterations, minimum, maximum, colors='black', linestyles='solid')\n",
    "    plt.ylabel('Maximum Mean Discrepancy')\n",
    "    plt.xlabel('Number of remaining samples')\n",
    "    plt.xticks(list(range(number_of_samples, 0, -100)) + [0])\n",
    "    plt.gca().invert_xaxis()\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    ax2 = plt.gca().twiny()\n",
    "    ax2.set_xlim(xlim)\n",
    "    plt.xticks(mrs_iterations)\n",
    "    [tick.set_color(\"blue\") for tick in plt.gca().get_xticklabels()]\n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "def plot_class_ratio(ratios, representative_ratio, file_name,  mrs_iterations, number_of_samples, save=False):\n",
    "    plt.xlabel('Number of remaining samples')\n",
    "    plt.ylabel('Ratio of married persons')\n",
    "    x_labels = range(number_of_samples, 0, -drop)\n",
    "\n",
    "    plt.plot(x_labels, ratios, label='non-representative', linestyle='-', color='blue')\n",
    "    plt.plot(number_of_samples*[representative_ratio], color='black', linestyle='--', label='representative')\n",
    "    minimum = np.min(ratios)\n",
    "    maximum = plt.gca().get_ylim()[1]\n",
    "    plt.margins(0.05, 0)\n",
    "    mrs_iterations = number_of_samples - np.array(mrs_iterations)\n",
    "    plt.vlines(mrs_iterations, minimum, maximum, colors='black', linestyles='solid')\n",
    "    plt.xticks(list(range(number_of_samples, 0, -500)) + [0])\n",
    "    plt.legend()\n",
    "    plt.gca().invert_xaxis()\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    ax2 = plt.gca().twiny()\n",
    "    ax2.set_xlim(xlim)\n",
    "    plt.xticks([mrs_iterations])\n",
    "    [tick.set_color(\"blue\") for tick in plt.gca().get_xticklabels()]\n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()\n",
    "  \n",
    "    \n",
    "def plot_experiment_comparison_auc(auc_score_mrs, std_aucs_mrs, auc_score_experiment, std_aucs_experiment, \n",
    "                               experiment_label, drop, file_name, number_of_samples, save=False):\n",
    "    aucs_upper = np.minimum(auc_score_mrs + std_aucs_mrs, 1)\n",
    "    aucs_lower = np.maximum(auc_score_mrs - std_aucs_mrs, 0)\n",
    "    \n",
    "    aucs_upper_experiment = np.minimum(auc_score_experiment + std_aucs_experiment, 1)\n",
    "    aucs_lower_experiment = np.maximum(auc_score_experiment - std_aucs_experiment, 0)\n",
    "    \n",
    "    x_labels = range(number_of_samples, drop, -drop)\n",
    "    \n",
    "    plt.fill_between(x_labels, aucs_lower, aucs_upper, color='blue', alpha=0.2)\n",
    "    plt.plot(x_labels, auc_score_mrs, color='blue', linestyle='-', label='MRS')\n",
    "    \n",
    "    plt.fill_between(x_labels, aucs_lower_experiment, aucs_upper_experiment, color='orange', alpha=0.2)\n",
    "    plt.plot(x_labels, auc_score_experiment, linestyle=':', color='orange', label=experiment_label)\n",
    "    \n",
    "    plt.plot(len(auc_score_mrs)*drop*[0.5], color='black', linestyle='--')\n",
    "    \n",
    "    plt.ylabel('AUROC')\n",
    "    plt.xlabel('Number of remaining samples')\n",
    "    plt.xticks(list(range(number_of_samples, 0, -100)) + [0])\n",
    "    plt.legend()\n",
    "    plt.gca().invert_xaxis()\n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_experiment_comparison_mmd(median_mmd, std_mmd,  median_mmd_experiment, std_mmd_experiment, \n",
    "                               experiment_label, drop, mmd_iteration, file_name, number_of_samples,\n",
    "                                   save=False):\n",
    "    mmd_upper = np.minimum(median_mmd + std_mmd, 1)\n",
    "    mmd_lower = np.maximum(median_mmd - std_mmd, 0)\n",
    "    \n",
    "    mmd_upper_experiment = np.minimum(median_mmd_experiment + std_mmd_experiment, 1)\n",
    "    mmd_lower_experiment = np.maximum(median_mmd_experiment - std_mmd_experiment, 0)\n",
    "    \n",
    "    x_labels = range(number_of_samples, drop*mmd_iteration, -drop*mmd_iteration)\n",
    "    \n",
    "    plt.fill_between(x_labels, mmd_lower, mmd_upper, color='blue', alpha=0.2)\n",
    "    plt.plot(x_labels, median_mmd, color='blue', linestyle='-', label='MRS')\n",
    "    \n",
    "    plt.fill_between(x_labels, mmd_lower_experiment, mmd_upper_experiment, color='orange', alpha=0.2)\n",
    "    plt.plot(x_labels, median_mmd_experiment, linestyle=':', color='orange', label=experiment_label)\n",
    "    \n",
    "    plt.ylabel('Maximum mean discrepancy')\n",
    "    plt.xlabel('Number of remaining samples')\n",
    "    plt.xticks(list(range(number_of_samples, 0, -100)) + [0])\n",
    "    plt.legend()\n",
    "    plt.gca().invert_xaxis()\n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_rbf_gamma(aggregate_set):\n",
    "    all_distances = pdist(aggregate_set.values, 'euclid')\n",
    "    sigma = np.median(all_distances)\n",
    "    return 1 / (2 * (sigma ** 2))\n",
    "\n",
    "def compute_maximum_mean_discrepancy(x, y):\n",
    "    gamma = calculate_rbf_gamma(pd.concat([x, y]))\n",
    "    x_x_rbf_matrix = rbf_kernel(x, x, gamma)\n",
    "    y_y_rbf_matrix = rbf_kernel(y, y, gamma)\n",
    "    x_y_rbf_matrix = rbf_kernel(x, y, gamma)\n",
    "    maximum_mean_discrepancy_value = (x_x_rbf_matrix.mean()) + y_y_rbf_matrix.mean() - 2 * x_y_rbf_matrix.mean()\n",
    "    return np.sqrt(maximum_mean_discrepancy_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def grid_search(X_train, y_train, cv=5):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "    ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "    ccp_alphas[ccp_alphas < 0] = 0\n",
    "    param_grid = {'ccp_alpha': ccp_alphas}\n",
    "    grid = GridSearchCV(DecisionTreeClassifier(random_state=5), param_grid, cv=cv, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def temperature_sample(softmax: list,\n",
    "                       temperature: float,\n",
    "                       drop: int):\n",
    "    EPSILON = 10e-16 # to avoid taking the log of zero\n",
    "    softmax = (np.array(softmax)).astype('float64')\n",
    "    softmax[softmax == 0] = EPSILON\n",
    "    preds = np.log(softmax) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    count = 0\n",
    "    while np.isnan(preds).any() and count < 100:\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        count += 1\n",
    "        \n",
    "    if count == 100:\n",
    "        return []\n",
    "        \n",
    "    if len(preds[preds != 0]) < drop:\n",
    "        drop = preds[preds != 0]\n",
    "    return np.random.choice(len(preds), drop, replace=False, p=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cv_bootstrap_prediction(N, R, number_of_splits, columns, cv):\n",
    "    preds = np.zeros(len(N))\n",
    "    preds_r = np.zeros(len(R))\n",
    "    bootstrap_iterations = 10\n",
    "    \n",
    "    kf = KFold(n_splits=number_of_splits, shuffle=True)\n",
    "    for split_n, split_r in zip(kf.split(N), kf.split(R)):\n",
    "        train_index, test_index = split_n\n",
    "        train_index_r, test_index_r  = split_r\n",
    "        N_train, N_test = N.iloc[train_index], N.iloc[test_index]\n",
    "        R_train, R_test = R.iloc[train_index_r], R.iloc[test_index_r]\n",
    "        n = min(len(R_train), len(N_train))\n",
    "        bootstrap_predictions = []\n",
    "        bootstrap_predictions_r = []\n",
    "        for j in range(bootstrap_iterations):\n",
    "            bootstrap = pd.concat([N_train.sample(n=n, replace=True),\n",
    "                                      R_train.sample(n=n, replace=True)])\n",
    "            clf = grid_search(bootstrap[columns], bootstrap.label, cv)\n",
    "            bootstrap_predictions.append(clf.predict_proba(N_test[columns])[:,1])\n",
    "            bootstrap_predictions_r.append(clf.predict_proba(R_test[columns])[:,1])\n",
    "        preds[test_index]  = np.mean(bootstrap_predictions, axis=0)\n",
    "        preds_r[test_index_r] = np.mean(bootstrap_predictions_r, axis=0)\n",
    "    return preds, preds_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def auc_prediction(N, R, columns, drop, iteration, cv=5, calculate_roc=False):\n",
    "    data = pd.concat([N, R])\n",
    "    auroc_scores = []\n",
    "    rocs = []\n",
    "    median_roc = None\n",
    "    mean_roc = None\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    for train, test in kf.split(data[columns], data['label']):\n",
    "        train, test = data.iloc[train], data.iloc[test]\n",
    "        y_train = train['label']\n",
    "        clf = grid_search(train[columns], y_train, cv)\n",
    "        y_predict = clf.predict_proba(test[columns])[:,1]\n",
    "        y_test = test['label']\n",
    "        auroc_scores.append(roc_auc_score(y_test, y_predict))\n",
    "        if calculate_roc:\n",
    "            rocs.append(interpolate_roc(y_test, y_predict, drop, iteration))\n",
    "    if calculate_roc:\n",
    "        median_roc = calculate_median_roc(rocs)\n",
    "        mean_roc = calculate_mean_roc(rocs)\n",
    "        \n",
    "    return np.mean(auroc_scores), median_roc, mean_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def interpolate_roc(y_test, y_predict, drop, iteration):\n",
    "    interpolation_points = 250\n",
    "    interpolated_fpr = np.linspace(0, 1, interpolation_points)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_predict)\n",
    "    interp_tpr = np.interp(interpolated_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    return interpolated_fpr, interp_tpr, [iteration * drop] * interpolation_points\n",
    "\n",
    "def calculate_median_roc(rocs):\n",
    "    rocs = np.array(rocs)\n",
    "    median_fpr = np.median(rocs[:, 0], axis = 0)\n",
    "    median_tpr = np.median(rocs[:, 1], axis = 0)\n",
    "    mad_tpr = np.median(np.absolute(rocs[:, 1] - np.median(rocs[:, 1], axis=0)), axis=0)\n",
    "    removed_samples = rocs[0, 2]\n",
    "    return median_fpr, median_tpr, mad_tpr, removed_samples\n",
    "\n",
    "def calculate_mean_roc(rocs):\n",
    "    rocs = np.array(rocs)\n",
    "    mean_fpr = np.mean(rocs[:, 0], axis = 0)\n",
    "    mean_tpr = np.mean(rocs[:, 1], axis = 0)\n",
    "    std_tpr = np.std(rocs[:, 1], axis = 0)\n",
    "    removed_samples = rocs[0, 2]\n",
    "    return mean_fpr, mean_tpr, std_tpr, removed_samples\n",
    "\n",
    "def calculate_median_rocs(rocs):\n",
    "    rocs = np.array(rocs)\n",
    "    median_rocs = []\n",
    "    for i in range(rocs.shape[1]):\n",
    "        rocs_at_iteration = rocs[:, i]\n",
    "        median_fpr = np.median(rocs_at_iteration[:, 0], axis = 0)\n",
    "        median_tpr = np.median(rocs_at_iteration[:, 1], axis = 0)\n",
    "        mad_tpr = np.median(np.absolute(rocs_at_iteration[:, 1] - np.median(rocs_at_iteration[:, 1], axis=0)), axis=0)\n",
    "        removed_samples = rocs_at_iteration[0, 3]\n",
    "        median_rocs.append((median_fpr, median_tpr, mad_tpr, removed_samples))\n",
    "    return median_rocs\n",
    "\n",
    "def calculate_mean_rocs(rocs):\n",
    "    rocs = np.array(rocs)\n",
    "    median_rocs = []\n",
    "    for i in range(rocs.shape[1]):\n",
    "        rocs_at_iteration = rocs[:, i]\n",
    "        mean_fpr = np.mean(rocs_at_iteration[:, 0], axis = 0)\n",
    "        mean_tpr = np.mean(rocs_at_iteration[:, 1], axis = 0)\n",
    "        std_tpr = np.std(rocs_at_iteration[:, 1], axis = 0)\n",
    "        removed_samples = rocs_at_iteration[0, 3]\n",
    "        median_rocs.append((mean_fpr, mean_tpr, std_tpr, removed_samples))\n",
    "    return median_rocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def MRS(N, R, columns, number_of_splits = 5, n_drop: int=1, cv=5, temperature_sampling=True):\n",
    "    \"\"\"\n",
    "    MRS Algorithm\n",
    "    \n",
    "    Input:\n",
    "        * N: dataset that is assumed to not be representative.\n",
    "        * R: dataset that is known to be representative.\n",
    "        * temperature: temperature value for probabilistic sampling procedure.\n",
    "        * drop: number of instances to drop per iteration (small values result in long runtimes).\n",
    "        * number_of_splits: splits per iteration.\n",
    "    \n",
    "    Output:\n",
    "        * N/Drop: N without the dropped elements\n",
    "    \"\"\" \n",
    "    \n",
    "    preds, preds_r = cv_bootstrap_prediction(N, R, number_of_splits, columns, cv)\n",
    "    all_preds = np.concatenate([preds, preds_r])\n",
    "    all_true = np.concatenate([np.ones(len(preds)), np.zeros(len(preds_r))])\n",
    "    auc = roc_auc_score(all_true, all_preds)\n",
    "    \n",
    "    if temperature_sampling:\n",
    "        mapped_auc = abs(auc - 0.5)\n",
    "        temperature = -0.55 * mapped_auc + 0.3\n",
    "    else:\n",
    "        temperature = 1\n",
    "    drop_ids = temperature_sample(preds, temperature, n_drop)\n",
    "    \n",
    "   \n",
    "    return N.drop(N.index[drop_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def repeated_MRS(df, columns, number_of_splits, n_drop=1, cv=5, us=False,\n",
    "                 census_bias='', temperature_sampling=True, number_of_iterations=None, mmd_iteration = 1):\n",
    "    \n",
    "    N = df[df['label'] == 1].copy()\n",
    "    R = df[df['label'] == 0].copy()\n",
    "    if number_of_iterations is None:\n",
    "        number_of_iterations = int(len(N) / drop)\n",
    "    aucs = []\n",
    "    mean_rocs = []\n",
    "    median_rocs = []\n",
    "    ratio = []\n",
    "    mmds = []\n",
    "    \n",
    "    \n",
    "    auroc_iteration = int(int(len(N) / n_drop) / 3.5) + 1\n",
    "    \n",
    "    if us:\n",
    "        ratio.extend([len(N[N[census_bias] == 1]) / (len(N[N[census_bias] == 0]))])\n",
    "        \n",
    "    #start value\n",
    "    auc, median_roc, mean_roc = auc_prediction(N, R, columns, drop, 0, cv, True)\n",
    "    aucs.append(auc)\n",
    "    median_rocs.append(median_roc)\n",
    "    mean_rocs.append(mean_roc)\n",
    "    mmds.append(compute_maximum_mean_discrepancy(N[columns], R[columns]))\n",
    "    \n",
    "    best_auc = auc\n",
    "    mrs_iteration = 0\n",
    "    min_delta = 0.01\n",
    "    mrs = N\n",
    "    \n",
    "    for i in tqdm(range(number_of_iterations)):\n",
    "        N = MRS(N, R, columns,\n",
    "                                number_of_splits=number_of_splits,\n",
    "                                n_drop=n_drop, cv=cv,\n",
    "                                temperature_sampling=temperature_sampling)\n",
    "\n",
    "        if (i+1) % auroc_iteration == 0:\n",
    "            auc, median_roc, mean_roc = auc_prediction(N, R, columns, drop, i+1, cv, calculate_roc=True)\n",
    "            aucs.append(auc)\n",
    "            median_rocs.append(median_roc)\n",
    "            mean_rocs.append(mean_roc)\n",
    "        else:\n",
    "            auc, _, _ = auc_prediction(N, R, columns, drop, i+1, cv, calculate_roc=False)\n",
    "            aucs.append(auc)\n",
    "        \n",
    "        if abs(auc - 0.5) < abs(best_auc - 0.5) - min_delta:\n",
    "            best_auc = auc\n",
    "            mrs_iteration = (i + 1) * n_drop\n",
    "            mrs = N.copy(deep=True)\n",
    "            \n",
    "        \n",
    "        # only for US Census experiment\n",
    "        if us:\n",
    "            ratio.extend([len(N[N[census_bias] == 1]) / (len(N[N[census_bias] == 0]))])\n",
    "                 \n",
    "        if (i+1) % mmd_iteration == 0:\n",
    "            mmds.append(compute_maximum_mean_discrepancy(N[columns], R[columns]))\n",
    "            \n",
    "        if len(N)-drop <= cv or len(N)-drop <= number_of_splits:\n",
    "            break\n",
    "    \n",
    "    if us:\n",
    "        return ratio, aucs,  mmds, mrs_iteration\n",
    "    else:\n",
    "        return aucs, mean_rocs, median_rocs, mrs, mmds, mrs_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment 1\n",
    "### <font color='darkblue'>US National Census (Income)</font>  <a name=\"us\"></a>\n",
    "\n",
    "*About this Dataset*\n",
    "\n",
    "**US Adult Census** (1994) relates income to social factors: \n",
    "\n",
    "- *age*: continuous.\n",
    "- *workclass*: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "- *fnlwgt*: continuous.\n",
    "- *education*: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "- *education-num*: continuous.\n",
    "- *marital-status*: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "- *occupation*: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "- *relationship*: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "- *race*: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "- *sex*: Female, Male.\n",
    "- *capital-gain*: continuous.\n",
    "- *capital-loss*: continuous.\n",
    "- *hours-per-week*: continuous.\n",
    "- *native-country*: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n",
    "Each row is labelled as either being married or not.\n",
    "\n",
    "Note: This Dataset was obtained from the UCI repository, it can be found on:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/census+income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columns = ['Age','Workclass','fnlgwt','Education','Education Num','Marital Status',\n",
    "           'Occupation','Relationship','Race','Sex','Capital Gain','Capital Loss',\n",
    "           'Hours/Week','Country','Above_Below 50K']\n",
    "\n",
    "df = pd.read_csv(os.path.join(path, 'data/Census_Income/adult.data'), names=columns, \n",
    "                    na_values=['-1', -1, ' ?'])\n",
    "\n",
    "df = df.replace([\" Cambodia\" , \" China\", \" Hong\", \" Laos\", \" Thailand\",\n",
    "                \" Japan\", \" Taiwan\", \" Vietnam\", \" Philippines\", \" India\", \" Iran\",\n",
    "                \" Cuba\", \" Guatemala\", \" Jamaica\", \" Nicaragua\", \n",
    "                        \" Puerto-Rico\",  \" Dominican-Republic\", \" El-Salvador\", \n",
    "                        \" Haiti\", \" Honduras\", \" Mexico\", \" Trinadad&Tobago\",\n",
    "                \" Ecuador\", \" Peru\", \" Columbia\", \" South\",\n",
    "               \" Poland\", \" Yugoslavia\", \" Hungary\", \" Outlying-US(Guam-USVI-etc)\"], \"other\")\n",
    "df = df.replace([\" England\", \" Germany\", \" Holand-Netherlands\", \" Ireland\", \n",
    "                \" France\", \" Greece\", \" Italy\", \" Portugal\", \" Scotland\"], \"west_europe\")\n",
    "df = df.replace([\" Married-civ-spouse\", \" Married-spouse-absent\", \" Married-AF-spouse\"], 'Married')\n",
    "\n",
    "df.replace(' >50K.', 1, inplace=True)\n",
    "df.replace(' >50K', 1, inplace=True)\n",
    "df.replace(' <=50K.', 0, inplace=True)\n",
    "df.replace(' <=50K', 0, inplace=True)\n",
    "\n",
    "df['Sex'].replace(' Male', 1, inplace=True)\n",
    "df['Sex'].replace(' Female', 0, inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "census_bias = 'Marital Status_Married'\n",
    "education_num_border =  12\n",
    "\n",
    "ctg = [\n",
    "    'Workclass', \n",
    "    'Marital Status',       \n",
    "    'Occupation',\n",
    "    'Race', \n",
    "    'Country'\n",
    "      ]\n",
    "\n",
    "for c in ctg:\n",
    "    df = pd.concat([df, pd.get_dummies(df[c], \n",
    "                                       prefix=c,\n",
    "                                       dummy_na=False)], axis=1).drop([c],axis=1)\n",
    "    \n",
    "census_columns = list(df.columns)\n",
    "meta = ['label', 'index', 'fnlgwt', 'Education', 'Relationship', census_bias]\n",
    "for m in meta:\n",
    "    if m in census_columns:\n",
    "        census_columns.remove(m)\n",
    "\n",
    "\n",
    "scaling_columns = [\n",
    "    'Age', \n",
    "    'Capital Loss',\n",
    "    'Capital Gain',\n",
    "    'Education Num',\n",
    "    'Hours/Week',\n",
    "]\n",
    "\n",
    "scale = StandardScaler()\n",
    "df[scaling_columns] = scale.fit_transform(df[scaling_columns])\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correlation = df.corr()\n",
    "plt.matshow(abs(correlation))\n",
    "plt.savefig('final_results/census/correlation_census.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correlation = abs(correlation)\n",
    "correlation_ranking = correlation.mean().sort_values(ascending=False)\n",
    "correlation_ranking.to_csv('final_results/census/correlation_ranking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)\n",
    "\n",
    "df_copy = df.copy()\n",
    "df_positive_class = df_copy[(df_copy[census_bias] == 1)].copy()\n",
    "df_negative_class = df_copy[(df_copy[census_bias] == 0)].copy()\n",
    "\n",
    "rep_fraction = 0.12\n",
    "bias_fraction = 0.05\n",
    "negative_normal = len(df_negative_class)\n",
    "positive_normal = len(df_positive_class)\n",
    "\n",
    "\n",
    "#-----------------Simulate non-representative data---------------------#\n",
    "rep = pd.concat([df_negative_class.head(int(negative_normal * 0.2)),\n",
    "                df_positive_class.head(int(positive_normal * 0.2))],\n",
    "                ignore_index=True) \n",
    "\n",
    "nonrep_more_negative_class = pd.concat([df_negative_class.tail(int(negative_normal * rep_fraction)), \n",
    "                             df_positive_class.tail(int(positive_normal * (rep_fraction - bias_fraction)))],\n",
    "                            ignore_index=True)\n",
    "\n",
    "nonrep_more_positive_class = pd.concat([df_negative_class.tail(int(negative_normal * (rep_fraction - bias_fraction))),\n",
    "                             df_positive_class.tail(int(positive_normal * rep_fraction))], \n",
    "                             ignore_index=True)\n",
    "\n",
    "\n",
    "#-----------------Simulate representative data---------------------#\n",
    "rep2 = pd.concat([df_negative_class.tail(int(negative_normal * rep_fraction)),\n",
    "                 df_positive_class.tail(int(positive_normal * rep_fraction))], \n",
    "                 ignore_index=True) \n",
    "\n",
    "rep['label'] = 0\n",
    "nonrep_more_negative_class['label'] = 1\n",
    "nonrep_more_positive_class['label'] = 1\n",
    "rep2['label'] = 1\n",
    "\n",
    "print(\"Current setting:\")\n",
    "print('Rep: \\n', rep[census_bias].value_counts())\n",
    "print('Rep 2: \\n', rep2[census_bias].value_counts())\n",
    "print('nonrep_more_positive_class: \\n', nonrep_more_positive_class[census_bias].value_counts())\n",
    "print('nonrep_more_negative_class: \\n', nonrep_more_negative_class[census_bias].value_counts())\n",
    "\n",
    "census_nonrep_more_negative_class = pd.concat([rep.copy(deep=True), nonrep_more_negative_class.copy(deep=True)])\n",
    "census_nonrep_more_positive_class = pd.concat([rep.copy(deep=True), nonrep_more_positive_class.copy(deep=True)])\n",
    "census_rep = pd.concat([rep.copy(deep=True), rep2.copy(deep=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment 1 a)\n",
    "\n",
    "\n",
    "### Simulate non-representative data. More married persons than in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop = 25\n",
    "number_of_splits = 5\n",
    "cv = 5\n",
    "mmd_iteration = 1\n",
    "\n",
    "representative_ratio = (len(rep[rep[census_bias] == 1]) / len(rep[rep[census_bias] == 0]))\n",
    "ratio, auc_more_negative, mmds, mrs_iteration = repeated_MRS(census_nonrep_more_negative_class,\n",
    "                    census_columns,\n",
    "                    number_of_splits = number_of_splits, \n",
    "                    n_drop = drop,\n",
    "                    cv = cv, us = True,\n",
    "                    census_bias=census_bias, \n",
    "                    mmd_iteration=mmd_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(ratio, open(\"results/ratio_more_negative_class\", 'wb'))\n",
    "pickle.dump(representative_ratio, open(\"results/representative_ratio_more_negative_class\", 'wb'))\n",
    "pickle.dump(auc_more_negative, open(\"results/auc_more_negative_class\", 'wb'))\n",
    "pickle.dump(mmds, open(\"results/mmd_more_negative_class\", 'wb'))\n",
    "pickle.dump(mrs_iteration, open(\"results/more_negative_class_mrs_iterations\", 'wb'))\n",
    "pickle.dump(len(nonrep_more_negative_class), \n",
    "            open('results/len_of_more_negative_class', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratio_more_negative_class = pickle.load(open(\"results/ratio_more_negative_class\", 'rb'))\n",
    "representative_ratio_more_negative_class = pickle.load(open(\n",
    "    \"results/representative_ratio_more_negative_class\", 'rb'))\n",
    "auc_more_negative = pickle.load(open(\"results/auc_more_negative_class\", 'rb'))\n",
    "mmd_more_negative_class = pickle.load(open(\"results/mmd_more_negative_class\", 'rb'))\n",
    "more_negative_class_mrs_iterations = pickle.load(open(\"results/more_negative_class_mrs_iterations\", 'rb'))\n",
    "len_of_more_negative_class = pickle.load(open('results/len_of_more_negative_class', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "mmd_iteration = 1\n",
    "drop = 25\n",
    "\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/census/more_negative/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "\n",
    "plot_class_ratio(ratio_more_negative_class, representative_ratio_more_negative_class, \n",
    "                 file_directory+'ratio_more_negative',\n",
    "                 more_negative_class_mrs_iterations, len_of_more_negative_class,\n",
    "                 save=save)\n",
    "plot_auc(auc_more_negative, drop, file_directory+'auc_more_negative', len_of_more_negative_class,\n",
    "         save=save, \n",
    "         mrs_iterations=more_negative_class_mrs_iterations)\n",
    "plot_mmds(mmd_more_negative_class, drop, mmd_iteration, file_directory+'mmd_more_negative', \n",
    "          more_negative_class_mrs_iterations, len_of_more_negative_class, save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment 1 b)\n",
    "\n",
    "\n",
    "### Simulate non-representative data. Less married persons than in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop = 25\n",
    "number_of_splits = 5\n",
    "mmd_iteration = 1\n",
    "representative_ratio = (len(rep[rep[census_bias] == 1]) / len(rep[rep[census_bias] == 0]))\n",
    "save = True\n",
    "cv = 5\n",
    "\n",
    "ratio, auc_more_positive_class, mmds, mrs_iteration = repeated_MRS(census_nonrep_more_positive_class, census_columns,\n",
    "                                                   number_of_splits = number_of_splits, n_drop = drop,\n",
    "                                                   cv = cv, us = True,\n",
    "                                                   census_bias=census_bias, \n",
    "                                                   mmd_iteration=mmd_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(ratio, open(\"results/ratio_more_positive_class\", 'wb'))\n",
    "pickle.dump(representative_ratio, open(\"results/representative_ratio_more_positive_class\", 'wb'))\n",
    "pickle.dump(auc_more_positive_class, open(\"results/auc_more_positive_class\", 'wb'))\n",
    "pickle.dump(mmds, open(\"results/mmd_more_positive_class\", 'wb'))\n",
    "pickle.dump(mrs_iteration, open(\"results/more_positive_class_mrs_iterations\", 'wb'))\n",
    "pickle.dump(len(nonrep_more_positive_class), \n",
    "            open('results/len_of_more_positive_class', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratio_more_positive = pickle.load(open(\"results/ratio_more_positive_class\", 'rb'))\n",
    "representative_ratio_more_positive = pickle.load(open(\"results/representative_ratio_more_positive_class\", 'rb'))\n",
    "auc_more_positive_class = pickle.load(open(\"results/auc_more_positive_class\", 'rb'))\n",
    "mmd_more_positive = pickle.load(open(\"results/mmd_more_positive_class\", 'rb'))\n",
    "more_positive_mrs_iterations = pickle.load(open(\"results/more_positive_class_mrs_iterations\", 'rb'))\n",
    "len_of_more_positive_class = pickle.load(open('results/len_of_more_positive_class', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "mmd_iteration = 1\n",
    "\n",
    "drop = 25\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/census/more_positive/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "\n",
    "plot_class_ratio(ratio_more_positive, representative_ratio_more_positive,\n",
    "                 file_directory+'ratio_more_positive', more_positive_mrs_iterations, \n",
    "                 len_of_more_positive_class, save=save)\n",
    "plot_auc(auc_more_positive_class, drop, file_directory+'auc_more_positive', len_of_more_positive_class, \n",
    "         save=save,\n",
    "         mrs_iterations=more_positive_mrs_iterations)\n",
    "plot_mmds(mmd_more_positive, drop, mmd_iteration, file_directory+'mmd_more_positive', \n",
    "          more_positive_mrs_iterations, len_of_more_positive_class, save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment 1 c)\n",
    "\n",
    "\n",
    "### Simulate already representative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop = 25\n",
    "number_of_splits = 5\n",
    "representative_ratio = (len(rep[rep[census_bias] == 1]) / len(rep[rep[census_bias] == 0]))\n",
    "cv = 3\n",
    "mmd_iteration = 1\n",
    "save = True\n",
    "\n",
    "ratio, auc_same, mmds, mrs_iteration = repeated_MRS(census_rep, census_columns,\n",
    "                                            number_of_splits = number_of_splits, n_drop = drop,\n",
    "                                            cv = cv, us = True,\n",
    "                                            census_bias=census_bias, \n",
    "                                            mmd_iteration=mmd_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(ratio, open(\"results/ratio_same\", 'wb'))\n",
    "pickle.dump(representative_ratio, open(\"results/representative_ratio_same\", 'wb'))\n",
    "pickle.dump(auc_same, open(\"results/auc_same\", 'wb'))\n",
    "pickle.dump(mmds, open(\"results/mmd_same\", 'wb'))\n",
    "pickle.dump(mrs_iteration, open(\"results/same_mrs_iterations\", 'wb'))\n",
    "pickle.dump(len(rep2), open('results/len_of_rep', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratio_same = pickle.load(open(\"results/ratio_same\", 'rb'))\n",
    "representative_ratio_same = pickle.load(open(\"results/representative_ratio_same\", 'rb'))\n",
    "auc_same = pickle.load(open(\"results/auc_same\", 'rb'))\n",
    "mmd_same = pickle.load(open(\"results/mmd_same\", 'rb'))\n",
    "same_mrs_iterations = pickle.load(open(\"results/same_mrs_iterations\", 'rb'))\n",
    "len_of_rep = pickle.load(open('results/len_of_rep', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "mmd_iteration = 1\n",
    "same_drop = 25\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/census/same/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "\n",
    "plot_class_ratio(ratio_same, representative_ratio_same, file_directory+'ratio_same', \n",
    "                 same_mrs_iterations, len_of_rep, save=save)\n",
    "plot_auc(auc_same, same_drop, file_directory+'auc_same', len_of_rep, \n",
    "         save=save, mrs_iterations=same_mrs_iterations)\n",
    "plot_mmds(mmd_same, same_drop, mmd_iteration,\n",
    "          file_directory+'mmd_same', same_mrs_iterations, len_of_rep, save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment 2\n",
    "### <font color='darkgreen'>Allensbach</font>   <---MRS---> <font color='darkred'>GBS</font> <---MRS---> <font color='darkgreen'>GESIS</font> \n",
    "\n",
    "*Figure shows MRS concept on GBS and GESIS for experiment 2 a). Replace Allensbach with GESIS for experiment 2 b)*\n",
    "\n",
    "<img src=\"overview.PNG\" width=\"450\" height=\"450\"/>\n",
    "\n",
    "\n",
    "**Multivariate auxiliary information GESIS linked to GBS so that expected selection bias can be detected and corrected for. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment 2 a)\n",
    "### <font color='darkgreen'>Allensbach Studie - Institut für Demoskopie(IfD)</font>  <a name=\"us\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color='darkred'>Important note:</font>  <a name=\"allensbach\"></a> Allensbach is already merged with GBS in this data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "allensbach = pd.read_csv(os.path.join(path, 'data/allensbach_mrs.csv'))\n",
    "allensbach.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "allensbach_columns = ['Alter', 'Berufsgruppe', 'Erwerbstaetigkeit', 'Geschlecht',\n",
    "                      'Optimismus', 'Pessimismus', 'Schulabschluss', 'woechentlicheArbeitszeit', 'Resilienz']\n",
    "allensbach_scaler = StandardScaler()\n",
    "scaled_allensbach = allensbach.copy(deep=True)\n",
    "scaled_allensbach[allensbach_columns] = allensbach_scaler.fit_transform(scaled_allensbach[allensbach_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop = 5\n",
    "number_of_splits = 5\n",
    "repetitions = 10\n",
    "cv = 5\n",
    "\n",
    "number_of_iterations = int(len(scaled_allensbach[scaled_allensbach['label']  == 1]) / drop)\n",
    "\n",
    "aucs = []\n",
    "median_rocs = []\n",
    "mean_rocs = []\n",
    "mmds = []\n",
    "mmd_iteration = 1\n",
    "mrs_iterations = []\n",
    "\n",
    "for _ in tqdm(range(repetitions)):\n",
    "    auc, mean_roc, median_roc, mrs, mmd, mrs_iteration = repeated_MRS(scaled_allensbach, allensbach_columns,\n",
    "                     number_of_splits=number_of_splits, n_drop=drop, cv=cv)\n",
    "    aucs.append(auc)\n",
    "    mean_rocs.append(mean_roc)\n",
    "    median_rocs.append(median_roc)\n",
    "    mmds.append(mmd)\n",
    "    mrs_iterations.append(mrs_iteration)\n",
    "\n",
    "mean_mmds = np.mean(mmds, axis = 0)\n",
    "std_mmds = np.std(mmds, axis = 0)\n",
    "mean_aucs = np.mean(aucs, axis = 0)\n",
    "std_aucs = np.std(aucs, axis = 0)\n",
    "\n",
    "median_mmds = np.median(mmds, axis = 0)\n",
    "mad_mmds = np.median(np.abs(mmds - np.median(mmds, axis=0)), axis=0)\n",
    "median_aucs = np.median(aucs, axis = 0)\n",
    "mad_aucs = np.median(np.abs(aucs - np.median(aucs, axis=0)), axis=0)\n",
    "\n",
    "median_rocs = calculate_median_rocs(median_rocs)\n",
    "mean_rocs = calculate_mean_rocs(mean_rocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(mrs_iterations, open(\"results/allensbach_mrs_iterations\", 'wb'))\n",
    "pickle.dump(drop, open(\"results/allensbach_drop\", \"wb\"))\n",
    "\n",
    "pickle.dump(median_rocs, open(\"results/allensbach_median_rocs\", 'wb'))\n",
    "pickle.dump(median_aucs, open(\"results/allensbach_median_aucs\", 'wb'))\n",
    "pickle.dump(std_aucs, open(\"results/allensbach_std_aucs\", 'wb'))\n",
    "pickle.dump(median_mmds, open(\"results/allensbach_median_mmds\", 'wb'))\n",
    "pickle.dump(std_mmds, open(\"results/allensbach_std_mmds\", 'wb'))\n",
    "\n",
    "pickle.dump(mean_rocs, open(\"results/allensbach_mean_rocs\", 'wb'))\n",
    "pickle.dump(mean_aucs, open(\"results/allensbach_mean_aucs\", 'wb'))\n",
    "pickle.dump(mad_aucs, open(\"results/allensbach_mad_aucs\", 'wb'))\n",
    "pickle.dump(mean_mmds, open(\"results/allensbach_mean_mmds\", 'wb'))\n",
    "pickle.dump(mad_mmds, open(\"results/allensbach_mad_mmds\", 'wb'))\n",
    "\n",
    "pickle.dump(mmd_iteration, (open(\"results/allensbach_mmd_iteration\", 'wb')))\n",
    "pickle.dump(len(allensbach[allensbach['label']  == 1]), (open(\"results/allensbach_len\", 'wb')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load  results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "allensbach_mrs_iterations =  pickle.load(open(\"results/allensbach_mrs_iterations\", 'rb'))\n",
    "allensbach_drop = pickle.load(open(\"results/allensbach_drop\", 'rb'))\n",
    "allensbach_mmd_iteration = pickle.load(open(\"results/allensbach_mmd_iteration\", 'rb'))\n",
    "allensbach_len = pickle.load(open(\"results/allensbach_len\", 'rb'))\n",
    "\n",
    "allensbach_mean_rocs = pickle.load(open(\"results/allensbach_mean_rocs\", \"rb\"))\n",
    "allensbach_mean_aucs = pickle.load(open(\"results/allensbach_mean_aucs\", \"rb\"))\n",
    "allensbach_std_aucs = pickle.load(open(\"results/allensbach_std_aucs\", \"rb\"))\n",
    "allensbach_mean_mmds =  pickle.load(open(\"results/allensbach_mean_mmds\", 'rb'))\n",
    "allensbach_std_mmds =  pickle.load(open(\"results/allensbach_std_mmds\", 'rb'))\n",
    "\n",
    "allensbach_median_rocs = pickle.load(open(\"results/allensbach_median_rocs\", \"rb\"))\n",
    "allensbach_median_aucs = pickle.load(open(\"results/allensbach_median_aucs\", \"rb\"))\n",
    "allensbach_mad_aucs = pickle.load(open(\"results/allensbach_mad_aucs\", \"rb\"))\n",
    "allensbach_median_mmds =  pickle.load(open(\"results/allensbach_median_mmds\", 'rb'))\n",
    "allensbach_mad_mmds =  pickle.load(open(\"results/allensbach_mad_mmds\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/allensbach/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "mmd_iteration = 1\n",
    "\n",
    "plot_auc_average(allensbach_mean_aucs, allensbach_std_aucs, allensbach_drop,\n",
    "                 file_directory +\"allensbach_auc_with_iterations_mean\", allensbach_len, save=save,\n",
    "                 mrs_iterations=allensbach_mrs_iterations, wide=True)\n",
    "\n",
    "plot_rocs(allensbach_mean_rocs, file_directory+\"allensbach_mean_rocs\", save=save)\n",
    "\n",
    "\n",
    "plot_mmds_average(allensbach_mean_mmds, allensbach_std_mmds, allensbach_drop, allensbach_mmd_iteration,\n",
    "                  file_directory + \"mean_mmds_allensbach\", allensbach_mrs_iterations, allensbach_len,\n",
    "                  save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Experiment 2 b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### <font color='darkgreen'>Load Gesis</font>  <a name=\"us\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gesis = pd.read_csv(os.path.join(path, 'data/gesis_processed.csv'), engine='python')\n",
    "gbs = pd.read_csv(os.path.join(path, 'data/gbs_processed.csv'), engine='python')\n",
    "\n",
    "gesis_columns = ['Geschlecht', 'Geburtsjahr', 'Geburtsland',\n",
    "       'Nationalitaet', 'Familienstand', 'Hoechster Bildungsabschluss',\n",
    "       'Berufliche Ausbildung', 'Erwerbstaetigkeit', 'Nettoeinkommen Selbst',\n",
    "       'Zufriedenheit Wahlergebnis', 'Gesellig', 'Andere kritisieren',\n",
    "       'Gruendlich', 'Nervoes', 'Phantasievoll', 'Berufsgruppe', 'Wahlteilnahme', 'BRS6']\n",
    "\n",
    "N = gbs.copy()\n",
    "R = gesis.copy()\n",
    "\n",
    "N['label'] = 1\n",
    "R['label'] = 0\n",
    "\n",
    "gesis_gbs = pd.concat([N, R], ignore_index=True)\n",
    "\n",
    "gesis_scaler = StandardScaler()\n",
    "scaled_gesis_gbs = gesis_gbs.copy(deep=True)\n",
    "scaled_gesis_gbs[gesis_columns] = gesis_scaler.fit_transform(scaled_gesis_gbs[gesis_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop = 5\n",
    "number_of_splits = 5\n",
    "cv = 5\n",
    "\n",
    "repetitions = 10\n",
    "number_of_iterations = int(len(scaled_gesis_gbs[scaled_gesis_gbs['label'] == 1]) / drop)\n",
    "\n",
    "aucs = []\n",
    "mean_rocs = []\n",
    "median_rocs = []\n",
    "mmds = []\n",
    "mmd_iteration = 1\n",
    "mrs_iterations = []\n",
    "\n",
    "for _ in tqdm(range(repetitions)):\n",
    "    auc, mean_roc, median_roc, mrs, mmd, mrs_iteration = repeated_MRS(scaled_gesis_gbs, gesis_columns,\n",
    "                                                     number_of_splits=number_of_splits,\n",
    "                        n_drop=drop,  cv=cv, number_of_iterations=number_of_iterations)\n",
    "    aucs.append(auc)\n",
    "    mean_rocs.append(mean_roc)\n",
    "    median_rocs.append(median_roc)\n",
    "    mmds.append(mmd)\n",
    "    mrs_iterations.append(mrs_iteration)\n",
    "\n",
    "mean_mmds = np.mean(mmds, axis = 0)\n",
    "std_mmds = np.std(mmds, axis = 0)\n",
    "mean_aucs = np.mean(aucs, axis = 0)\n",
    "std_aucs = np.std(aucs, axis = 0)\n",
    "\n",
    "median_mmds = np.median(mmds, axis = 0)\n",
    "mad_mmds = np.median(np.abs(mmds - np.median(mmds, axis=0)), axis=0)\n",
    "median_aucs = np.median(aucs, axis = 0)\n",
    "mad_aucs = np.median(np.abs(aucs - np.median(aucs, axis=0)), axis=0)\n",
    "\n",
    "median_rocs = calculate_median_rocs(median_rocs)\n",
    "mean_rocs = calculate_mean_rocs(mean_rocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(mean_aucs, open(\"results/gesis_mean_aucs\", 'wb'))\n",
    "pickle.dump(std_aucs, open(\"results/gesis_std_aucs\", 'wb'))\n",
    "pickle.dump(mean_rocs, open(\"results/gesis_mean_rocs\", 'wb'))\n",
    "pickle.dump(mean_mmds, open(\"results/gesis_mean_mmds\", 'wb'))\n",
    "pickle.dump(std_mmds, open(\"results/gesis_std_mmds\", 'wb'))\n",
    "\n",
    "pickle.dump(mrs_iterations, open(\"results/gesis_mrs_iterations\", 'wb'))\n",
    "pickle.dump(drop, open(\"results/gesis_drop\", \"wb\"))\n",
    "pickle.dump(mmd_iteration, open(\"results/gesis_mmd_iteration\", 'wb'))\n",
    "pickle.dump(len(gbs), open('results/len_gbs', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gesis_mean_aucs = pickle.load(open(\"results/gesis_mean_aucs\", 'rb'))\n",
    "gesis_std_aucs = pickle.load(open(\"results/gesis_std_aucs\", 'rb'))\n",
    "gesis_mean_rocs =  pickle.load(open(\"results/gesis_mean_rocs\", 'rb'))\n",
    "gesis_mean_mmds =  pickle.load(open(\"results/gesis_mean_mmds\", 'rb'))\n",
    "gesis_std_mmds =  pickle.load(open(\"results/gesis_std_mmds\", 'rb'))\n",
    "\n",
    "gesis_mrs_iterations =  pickle.load(open(\"results/gesis_mrs_iterations\", 'rb'))\n",
    "gesis_drop = pickle.load(open(\"results/gesis_drop\", 'rb'))\n",
    "gesis_mmd_iteration = pickle.load(open(\"results/gesis_mmd_iteration\", 'rb'))\n",
    "len_gbs = pickle.load(open('results/len_gbs', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/gesis/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "\n",
    "plot_auc_average(gesis_mean_aucs, gesis_std_aucs, gesis_drop,\n",
    "                 file_directory +\"gesis_auc_mean_with_iterations\", len_gbs, save=save,\n",
    "                 mrs_iterations=gesis_mrs_iterations, wide=True)\n",
    "plot_rocs(gesis_mean_rocs, file_directory+\"gesis_mean_rocs\", save=save)\n",
    "plot_mmds_average(gesis_mean_mmds, gesis_std_mmds, gesis_drop, gesis_mmd_iteration,\n",
    "                  file_directory + \"mean_mmds_gesis\", gesis_mrs_iterations, len_gbs, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Compare MRS with temperature sampling and sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop = 5\n",
    "number_of_splits = 5\n",
    "\n",
    "cv= 5\n",
    "repetitions = 10\n",
    "number_of_iterations = int(len(scaled_gesis_gbs[scaled_gesis_gbs['label'] == 1]) / drop)\n",
    "aucs_without_temperature = []\n",
    "mmds_without_temperature = []\n",
    "mrs_iterations = []\n",
    "mmd_iteration = 1\n",
    "    \n",
    "for _ in tqdm(range(repetitions)):\n",
    "    auc, _, _, mrs, mmd, mrs_iteration = repeated_MRS(scaled_gesis_gbs, gesis_columns,\n",
    "                     number_of_splits=number_of_splits,\n",
    "                    n_drop=drop, cv=cv,\n",
    "                                                 number_of_iterations=number_of_iterations, \n",
    "                                                     temperature_sampling=False)\n",
    "    \n",
    "    aucs_without_temperature.append(auc)\n",
    "    mmds_without_temperature.append(mmd)\n",
    "    mrs_iterations.append(mrs_iteration)\n",
    "\n",
    "\n",
    "mean_mmds = np.mean(mmds_without_temperature, axis = 0)\n",
    "std_mmds = np.std(mmds_without_temperature, axis = 0)\n",
    "mean_aucs = np.mean(aucs_without_temperature, axis = 0)\n",
    "std_aucs = np.std(aucs_without_temperature, axis = 0)\n",
    "\n",
    "median_mmds = np.median(mmds_without_temperature, axis = 0)\n",
    "mad_mmds = np.median(np.abs(mmds_without_temperature - np.median(mmds_without_temperature, axis=0)), axis=0)\n",
    "median_aucs = np.median(aucs_without_temperature, axis = 0)\n",
    "mad_aucs = np.median(np.abs(aucs_without_temperature - np.median(aucs_without_temperature, axis=0)), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(median_aucs, open(\"results/median_aucs_without_temperature\", 'wb'))\n",
    "pickle.dump(mad_aucs, open(\"results/mad_aucs_without_temperature\", 'wb'))\n",
    "pickle.dump(median_mmds, open(\"results/median_mmds_without_temperature\", 'wb'))\n",
    "pickle.dump(mad_mmds, open(\"results/mad_mmds_without_temperature\", 'wb'))\n",
    "\n",
    "pickle.dump(mean_aucs, open(\"results/mean_aucs_without_temperature\", 'wb'))\n",
    "pickle.dump(std_aucs, open(\"results/std_aucs_without_temperature\", 'wb'))\n",
    "pickle.dump(mean_mmds, open(\"results/mean_mmds_without_temperature\", 'wb'))\n",
    "pickle.dump(std_mmds, open(\"results/std_mmds_without_temperature\", 'wb'))\n",
    "\n",
    "pickle.dump(mrs_iterations, open(\"results/mrs_iterations_without_temperature\", 'wb'))\n",
    "pickle.dump(drop, open(\"results/drop_without_temperature\", 'wb'))\n",
    "pickle.dump(mmd_iteration, open(\"results/mmd_iteration_without_temperature\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load saved results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mean_aucs_without_temperature = pickle.load(open(\"results/mean_aucs_without_temperature\", 'rb'))\n",
    "std_aucs_without_temperature = pickle.load(open(\"results/std_aucs_without_temperature\", 'rb'))\n",
    "mean_aucs_temperature = pickle.load(open(\"results/gesis_mean_aucs\", 'rb'))\n",
    "std_aucs_temperature = pickle.load(open(\"results/gesis_std_aucs\", 'rb'))\n",
    "mean_mmds_without_temperature = pickle.load(open(\"results/mean_mmds_without_temperature\", 'rb'))\n",
    "std_mmds_without_temperature = pickle.load(open(\"results/std_mmds_without_temperature\", 'rb'))\n",
    "gesis_mean_mmds = pickle.load(open(\"results/gesis_mean_mmds\", 'rb'))\n",
    "gesis_std_mmds = pickle.load(open(\"results/gesis_std_mmds\", 'rb'))\n",
    "\n",
    "mrs_iterations_without_temperature = pickle.load(open(\"results/mrs_iterations_without_temperature\", 'rb'))\n",
    "drop_without_temperature = pickle.load(open(\"results/drop_without_temperature\", 'rb'))\n",
    "mmd_iteration_without_temperature = pickle.load(open(\"results/mmd_iteration_without_temperature\", 'rb'))\n",
    "len_gbs = pickle.load(open('results/len_gbs', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "experiment_label = 'MRS without \\ntemperature sampling'\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/temperature_comparison/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "save = True\n",
    "\n",
    "plot_experiment_comparison_auc(mean_aucs_temperature, std_aucs_temperature, mean_aucs_without_temperature,\n",
    "                            std_aucs_without_temperature, experiment_label,\n",
    "                                drop_without_temperature, file_directory + 'aucs_temperature_mean', len_gbs,\n",
    "                               save=save)   \n",
    "plot_experiment_comparison_mmd(gesis_mean_mmds, gesis_std_mmds,  mean_mmds_without_temperature,\n",
    "                               std_mmds_without_temperature, \n",
    "                               experiment_label, drop_without_temperature, mmd_iteration_without_temperature, \n",
    "                               file_directory + 'mmds_temperature_mean', len_gbs, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Compare MRS with cross-validation and without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mrs_without_cv(N: pd.DataFrame, R: pd.DataFrame, columns: list, n_drop: int=1):\n",
    "    EPSILON = 10e-16 # to avoid dividing by zero\n",
    "    bootstrap_iterations = 25\n",
    "    bootstrap_predictions_n = np.zeros(len(N))\n",
    "    bootstrap_predictions_r = np.zeros(len(R))\n",
    "    counter_n = np.zeros(len(N))\n",
    "    counter_r = np.zeros(len(R))\n",
    "    \n",
    "    n = min(len(R), len(N))\n",
    "    for _ in range(bootstrap_iterations):\n",
    "        n_sample = N.sample(n=n, replace=True)\n",
    "        N_test = N.drop(n_sample.index)\n",
    "        r_sample = R.sample(n=n, replace=True)\n",
    "        R_test = R.drop(r_sample.index)\n",
    "        locations_not_in_bootstrap_n = list(set([N.index.get_loc(index) for index in N_test.index]))\n",
    "        locations_not_in_bootstrap_r = list(set([R.index.get_loc(index) for index in R_test.index]))\n",
    "        \n",
    "        bootstrap = pd.concat([n_sample, r_sample])\n",
    "        clf = grid_search(bootstrap[columns], bootstrap.label, 5)\n",
    "        proba_n = clf.predict_proba(N_test[columns])[:,1]\n",
    "        proba_r = clf.predict_proba(R_test[columns])[:,1]\n",
    "        bootstrap_single_n = np.zeros(len(N))\n",
    "        bootstrap_single_n[list(locations_not_in_bootstrap_n)] = proba_n\n",
    "        counter_n[list(locations_not_in_bootstrap_n)] += 1\n",
    "        bootstrap_predictions_n += bootstrap_single_n\n",
    "        \n",
    "        bootstrap_single_r = np.zeros(len(R))\n",
    "        bootstrap_single_r[list(locations_not_in_bootstrap_r)] = proba_r\n",
    "        counter_r[list(locations_not_in_bootstrap_r)] += 1\n",
    "        bootstrap_predictions_r += bootstrap_single_r\n",
    "        \n",
    "    counter_n = [EPSILON if x == 0 else x for x in counter_n]\n",
    "    counter_r = [EPSILON if x == 0 else x for x in counter_r]\n",
    "    preds_n = bootstrap_predictions_n / counter_n\n",
    "    preds_r = bootstrap_predictions_r / counter_r\n",
    "    \n",
    "    all_preds = np.concatenate([preds_n, preds_r])\n",
    "    all_true = np.concatenate([np.ones(len(preds_n)), np.zeros(len(preds_r))])\n",
    "    auc = roc_auc_score(all_true, all_preds)\n",
    "    mapped_auc = abs(auc - 0.5)\n",
    "    temperature = -0.55 * mapped_auc + 0.3\n",
    "    drop_ids = temperature_sample(preds_n, temperature, n_drop)\n",
    "    return N.drop(N.index[drop_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def repeated_MRS_without_cv(df, columns, number_of_splits, n_drop=1, cv=5, us=False, census_bias='', number_of_iterations=None):\n",
    "    \n",
    "    N = df[df['label'] == 1].copy()\n",
    "    R = df[df['label'] == 0].copy()\n",
    "    if number_of_iterations is None:\n",
    "        number_of_iterations = int(len(N) / drop)\n",
    "    aucs = []\n",
    "    ratio = []\n",
    "    mmds = []\n",
    "    mmd_iteration = 1\n",
    "    \n",
    "    auroc_iteration = int(int(len(N) / n_drop) / 3.5) + 1\n",
    "    \n",
    "    if us:\n",
    "        ratio.extend([len(N[N[census_bias] == 1]) / \n",
    "                         (len(N[N[census_bias] == 0]))]*drop)\n",
    "        \n",
    "    #start value\n",
    "    auc, _, _ = auc_prediction(N, R, columns, drop, 0, cv, False)\n",
    "    aucs.append(auc)\n",
    "    mmds.append(compute_maximum_mean_discrepancy(N[columns], R[columns]))\n",
    "    \n",
    "    best_auc = auc\n",
    "    mrs_iteration = 0\n",
    "    min_delta = 0.005\n",
    "    mrs = N\n",
    "    \n",
    "    for i in tqdm(range(number_of_iterations)):\n",
    "        N = mrs_without_cv(N, R, columns, n_drop=n_drop)\n",
    "        auc, _, _ = auc_prediction(N, R, columns, drop, i+1, cv, calculate_roc=False)\n",
    "        aucs.append(auc)\n",
    "        \n",
    "        if abs(auc - 0.5) < abs(best_auc - 0.5) - min_delta:\n",
    "            best_auc = auc\n",
    "            mrs_iteration = (i + 1) * n_drop\n",
    "            mrs = N.copy(deep=True)\n",
    "\n",
    "        if (i+1) % mmd_iteration == 0:\n",
    "            mmds.append(compute_maximum_mean_discrepancy(N[columns], R[columns]))\n",
    "            \n",
    "        if len(N)-drop <= cv or len(N)-drop <= number_of_splits:\n",
    "            break\n",
    "    \n",
    "    return aucs, mrs, mmds, mrs_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop = 5\n",
    "number_of_splits = 5\n",
    "\n",
    "number_of_iterations = int(len(scaled_gesis_gbs[scaled_gesis_gbs['label']  == 1]) / drop)\n",
    "repetitions = 10\n",
    "cv = 5\n",
    "aucs_without_cv = []\n",
    "mmds_without_cv = []\n",
    "mrs_iterations = []\n",
    "mmd_iteration = 1\n",
    "save=False\n",
    "    \n",
    "for temp in tqdm(range(repetitions)):\n",
    "    auc,  mrs, mmd, mrs_iteration = repeated_MRS_without_cv(scaled_gesis_gbs, gesis_columns,\n",
    "                    number_of_splits=number_of_splits,\n",
    "                    n_drop=drop,  cv=cv, number_of_iterations=number_of_iterations)\n",
    "    \n",
    "    aucs_without_cv.append(auc)\n",
    "    mmds_without_cv.append(mmd)\n",
    "    mrs_iterations.append(mrs_iteration)\n",
    "\n",
    "mean_mmds = np.mean(mmds_without_cv, axis = 0)\n",
    "std_mmds = np.std(mmds_without_cv, axis = 0)\n",
    "mean_aucs = np.mean(aucs_without_cv, axis = 0)\n",
    "std_aucs = np.std(aucs_without_cv, axis = 0)\n",
    "\n",
    "median_mmds = np.median(mmds_without_cv, axis = 0)\n",
    "mad_mmds = np.median(np.abs(mmds_without_cv - np.median(mmds_without_cv, axis=0)), axis=0)\n",
    "median_aucs = np.median(aucs_without_cv, axis = 0)\n",
    "mad_aucs = np.median(np.abs(aucs_without_cv - np.median(aucs_without_cv, axis=0)), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(median_aucs, open(\"results/median_aucs_without_cv\", 'wb'))\n",
    "pickle.dump(mad_aucs, open(\"results/mad_aucs_without_cv\", 'wb'))\n",
    "pickle.dump(median_mmds, open(\"results/median_mmds_without_cv\", 'wb'))\n",
    "pickle.dump(mad_mmds, open(\"results/mad_mmds_without_cv\", 'wb'))\n",
    "\n",
    "pickle.dump(mean_aucs, open(\"results/mean_aucs_without_cv\", 'wb'))\n",
    "pickle.dump(std_aucs, open(\"results/std_aucs_without_cv\", 'wb'))\n",
    "pickle.dump(mean_mmds, open(\"results/mean_mmds_without_cv\", 'wb'))\n",
    "pickle.dump(std_mmds, open(\"results/std_mmds_without_cv\", 'wb'))\n",
    "\n",
    "pickle.dump(mrs_iterations, open(\"results/mrs_iterations_without_cv\", 'wb'))\n",
    "pickle.dump(drop, open(\"results/drop_without_cv\", 'wb'))\n",
    "pickle.dump(mmd_iteration, open(\"results/mmd_iteration_without_cv\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gesis_median_aucs = pickle.load(open(\"results/gesis_median_aucs\", 'rb'))\n",
    "gesis_mad_aucs = pickle.load(open(\"results/gesis_mad_aucs\", 'rb'))\n",
    "median_aucs_without_cv = pickle.load(open(\"results/median_aucs_without_cv\", 'rb'))\n",
    "mad_aucs_without_cv = pickle.load(open(\"results/mad_aucs_without_cv\", 'rb'))\n",
    "median_mmds_without_cv = pickle.load(open(\"results/median_mmds_without_cv\", 'rb'))\n",
    "mad_mmds_without_cv = pickle.load(open(\"results/mad_mmds_without_cv\", 'rb'))\n",
    "gesis_median_mmds = pickle.load(open(\"results/gesis_median_mmds\", 'rb'))\n",
    "gesis_mad_mmds = pickle.load(open(\"results/gesis_mad_mmds\", 'rb'))\n",
    "\n",
    "gesis_mean_aucs = pickle.load(open(\"results/gesis_mean_aucs\", 'rb'))\n",
    "gesis_std_aucs = pickle.load(open(\"results/gesis_std_aucs\", 'rb'))\n",
    "mean_aucs_without_cv = pickle.load(open(\"results/mean_aucs_without_cv\", 'rb'))\n",
    "std_aucs_without_cv = pickle.load(open(\"results/std_aucs_without_cv\", 'rb'))\n",
    "mean_mmds_without_cv = pickle.load(open(\"results/mean_mmds_without_cv\", 'rb'))\n",
    "std_mmds_without_cv = pickle.load(open(\"results/std_mmds_without_cv\", 'rb'))\n",
    "gesis_mean_mmds = pickle.load(open(\"results/gesis_mean_mmds\", 'rb'))\n",
    "gesis_std_mmds = pickle.load(open(\"results/gesis_std_mmds\", 'rb'))\n",
    "\n",
    "mrs_iterations_without_cv = pickle.load(open(\"results/mrs_iterations_without_cv\", 'rb'))\n",
    "drop_without_cv = pickle.load(open(\"results/drop_without_temperature\", 'rb'))\n",
    "mmd_iteration_without_cv = pickle.load(open(\"results/mmd_iteration_without_temperature\", 'rb'))\n",
    "len_gbs = pickle.load(open('results/len_gbs', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/cross_validation_comparison/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "\n",
    "experiment_label = 'MRS without cross-validation'\n",
    "\n",
    "\n",
    "plot_experiment_comparison_auc(gesis_mean_aucs, gesis_std_aucs, mean_aucs_without_cv,\n",
    "                                std_aucs_without_cv, experiment_label, drop_without_cv,\n",
    "                           file_directory+'auc_cv_mean', len_gbs, save=save)\n",
    "plot_experiment_comparison_mmd(gesis_mean_mmds, gesis_std_mmds,  median_mmds_without_cv,\n",
    "                               mad_mmds_without_cv,\n",
    "                               experiment_label, drop_without_cv, mmd_iteration_without_cv,\n",
    "                               file_directory+'mmd_cv_mean', len_gbs, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Random drops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop = 5\n",
    "cv = 5\n",
    "repetitions = 10\n",
    "number_of_splits = 5\n",
    "aucs_random_drop = []\n",
    "mmds = []\n",
    "mrs_iterations = []\n",
    "mmd_iteration = 1\n",
    "\n",
    "iterations = int(len(scaled_gesis_gbs[scaled_gesis_gbs['label'] == 1]) / drop)\n",
    "\n",
    "for _ in tqdm(range(repetitions)):\n",
    "    N = scaled_gesis_gbs[scaled_gesis_gbs['label'] == 1].copy()\n",
    "    R = scaled_gesis_gbs[scaled_gesis_gbs['label'] == 0].copy()\n",
    "    aucs = [] \n",
    "    mmd = []\n",
    "    \n",
    "    #start value\n",
    "    auc, _, _ = auc_prediction(N, R, gesis_columns, drop, 0, cv, False)\n",
    "    aucs.append(auc)\n",
    "    mmd.append(compute_maximum_mean_discrepancy(N[gesis_columns], R[gesis_columns]))\n",
    "    \n",
    "    best_auc = auc\n",
    "    mrs_iteration = 0\n",
    "    min_delta = 0.005\n",
    "    \n",
    "    for i in tqdm(range(iterations)):\n",
    "        drop_ids = random.sample(range(0, len(N)), drop)\n",
    "        N.drop(N.index[drop_ids], inplace=True)\n",
    "\n",
    "        auc, _, _ = auc_prediction(N, R, gesis_columns, drop, i+1, cv, calculate_roc=False)\n",
    "        aucs.append(auc)\n",
    "        \n",
    "        if abs(auc - 0.5) < abs(best_auc - 0.5) - min_delta:\n",
    "            best_auc = auc\n",
    "            mrs_iteration = (i + 1) * drop\n",
    "            \n",
    "        if (i+1) % mmd_iteration == 0:\n",
    "            mmd.append(compute_maximum_mean_discrepancy(N[gesis_columns], R[gesis_columns]))\n",
    "            \n",
    "        if len(N)-drop <= cv or len(N)-drop <= number_of_splits:\n",
    "            break\n",
    "        \n",
    "    mrs_iterations.append(mrs_iteration)\n",
    "    aucs_random_drop.append(aucs)\n",
    "    mmds.append(mmd)\n",
    "\n",
    "median_aucs_random_drop = np.median(aucs_random_drop, axis = 0)\n",
    "mean_aucs_random_drop = np.mean(aucs_random_drop, axis = 0)\n",
    "median_mmd_random_drop = np.median(mmds, axis = 0)\n",
    "mean_mmd_random_drop = np.mean(mmds, axis = 0)\n",
    "\n",
    "std_aucs_random_drop = np.std(aucs_random_drop, axis = 0)\n",
    "std_mmds_random_drop = np.std(mmds, axis = 0)\n",
    "mad_aucs_random_drop = np.median(np.abs(aucs_random_drop - np.median(aucs_random_drop, axis=0)), axis=0)\n",
    "mad_mmds_random_drop = np.median(np.abs(mmds - np.median(mmds, axis=0)), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(median_aucs_random_drop, open(\"results/median_aucs_random_drop\", 'wb'))\n",
    "pickle.dump(mad_aucs_random_drop, open(\"results/mad_aucs_random_drop\", 'wb'))\n",
    "pickle.dump(median_mmd_random_drop, open(\"results/median_mmds_random_drop\", 'wb'))\n",
    "pickle.dump(mad_mmds_random_drop, open(\"results/mad_mmds_random_drop\", 'wb'))\n",
    "\n",
    "pickle.dump(mean_aucs_random_drop, open(\"results/mean_aucs_random_drop\", 'wb'))\n",
    "pickle.dump(std_mmds_random_drop, open(\"results/std_mmds_random_drop\", 'wb'))\n",
    "pickle.dump(mean_mmd_random_drop, open(\"results/mean_mmds_random_drop\", 'wb'))\n",
    "pickle.dump(std_aucs_random_drop, open(\"results/std_aucs_random_drop\", 'wb'))\n",
    "\n",
    "pickle.dump(drop, open(\"results/random_drop_drop\", \"wb\"))\n",
    "pickle.dump(mmd_iteration, open(\"results/random_drop_mmd_iteration\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load saved results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "median_aucs_random_drop = pickle.load(open(\"results/median_aucs_random_drop\", 'rb'))\n",
    "mad_aucs_random_drop = pickle.load(open(\"results/mad_aucs_random_drop\", 'rb'))\n",
    "median_mmds_random_drop = pickle.load(open(\"results/median_mmds_random_drop\", 'rb'))\n",
    "mad_mmds_random_drop = pickle.load(open(\"results/mad_mmds_random_drop\", 'rb'))\n",
    "gesis_median_aucs = pickle.load(open(\"results/gesis_median_aucs\", 'rb'))\n",
    "gesis_mad_aucs = pickle.load(open(\"results/gesis_mad_aucs\", 'rb'))\n",
    "gesis_median_mmds = pickle.load(open(\"results/gesis_median_mmds\", 'rb'))\n",
    "gesis_mad_mmds = pickle.load(open(\"results/gesis_mad_mmds\", 'rb'))\n",
    "\n",
    "mean_aucs_random_drop = pickle.load(open(\"results/mean_aucs_random_drop\", 'rb'))\n",
    "std_aucs_random_drop = pickle.load(open(\"results/std_aucs_random_drop\", 'rb'))\n",
    "mean_mmds_random_drop = pickle.load(open(\"results/mean_mmds_random_drop\", 'rb'))\n",
    "std_mmds_random_drop = pickle.load(open(\"results/std_mmds_random_drop\", 'rb'))\n",
    "gesis_mean_aucs = pickle.load(open(\"results/gesis_mean_aucs\", 'rb'))\n",
    "gesis_std_aucs = pickle.load(open(\"results/gesis_std_aucs\", 'rb'))\n",
    "gesis_mean_mmds = pickle.load(open(\"results/gesis_mean_mmds\", 'rb'))\n",
    "gesis_std_mmds = pickle.load(open(\"results/gesis_std_mmds\", 'rb'))\n",
    "\n",
    "random_drop_mmd_iteration = pickle.load(open(\"results/random_drop_mmd_iteration\", \"rb\"))\n",
    "len_gbs = pickle.load(open('results/len_gbs', 'rb'))\n",
    "random_drop_drop = pickle.load(open(\"results/random_drop_drop\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file_directory = os.path.join(os.getcwd(), \"final_results/random/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "save = True\n",
    "experiment_label = 'Random drop'\n",
    "plot_experiment_comparison_auc(gesis_median_aucs, gesis_mad_aucs,\n",
    "                               median_aucs_random_drop, mad_aucs_random_drop,\n",
    "                               experiment_label, random_drop_drop, file_directory+'aucs_random_median', len_gbs, save)\n",
    "plot_experiment_comparison_mmd(gesis_median_mmds, gesis_mad_mmds,  median_mmds_random_drop,\n",
    "                               mad_mmds_random_drop,\n",
    "                               experiment_label, random_drop_drop, random_drop_mmd_iteration,\n",
    "                               file_directory+'mmd_random_median', len_gbs, save=save)\n",
    "\n",
    "plot_experiment_comparison_auc(gesis_mean_aucs, gesis_std_aucs,\n",
    "                               mean_aucs_random_drop, std_aucs_random_drop,\n",
    "                               experiment_label, random_drop_drop, file_directory+'aucs_random_mean', len_gbs, save)\n",
    "plot_experiment_comparison_mmd(gesis_mean_mmds, gesis_std_mmds,  mean_mmds_random_drop,\n",
    "                               std_mmds_random_drop,\n",
    "                               experiment_label, random_drop_drop, random_drop_mmd_iteration,\n",
    "                               file_directory+'mmd_random_mean', len_gbs, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Correlation between resilience and voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_columns = allensbach_gbs.drop(['label', 'GBS-CODE', 'IE_ext1', 'IE_ext2', 'IE_int1',\n",
    "       'IE_int2', 'BRS1',\n",
    "       'BRS2', 'BRS3', 'BRS4', 'BRS5', 'BRS6', 'Nervoes', 'Nervös', 'Gruppe',\n",
    "                                  'Wahlabsicht']\n",
    "                                  , axis='columns').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_mrs = 100\n",
    "mrs_list = []\n",
    "drop = 5\n",
    "number_of_splits = 5\n",
    "cv = 5\n",
    "number_of_iterations = int(len(allensbach[allensbach['label'] == 1]) / drop)\n",
    "mmd_iteration = 700\n",
    "\n",
    "for _ in tqdm(range(number_of_mrs)):\n",
    "    _, _, mrs, _, _ = repeated_MRS(allensbach, allensbach_columns,  number_of_splits=number_of_splits,\n",
    "                            n_drop=drop, cv=cv, number_of_iterations=number_of_iterations)\n",
    "    mrs_list.append(mrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save MRS list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "anonyme_list = []\n",
    "for mrs in mrs_list:\n",
    "    anonyme_list.append(mrs[[save_columns, 'Wahlteilnahme']])\n",
    "all_mrs_elements = pd.concat(anonyme_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(all_mrs_elements, open(\"results/all_mrs_elements\", 'wb'))\n",
    "pickle.dump(anonyme_list, open(\"results/anonyme_list\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load MRS list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_mrs_elements = pickle.load(open(\"results/all_mrs_elements\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_mrs_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "allensbach_gbs = allensbach[allensbach['label'] == 1]\n",
    "allensbach_without_gbs = allensbach[allensbach['label'] == 0]\n",
    "bins = []\n",
    "for i in range(6, 32):\n",
    "    bins.append(round(i/6, 6))\n",
    "\n",
    "value = 'Resilienz'\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, sharex=True)\n",
    "\n",
    "weights_gbs = np.ones_like(allensbach_gbs[value]) / len(allensbach_gbs[value])\n",
    "weights_mrs = np.ones_like(all_mrs_elements[value]) / len(all_mrs_elements[value])\n",
    "weights_allensbach = np.ones_like(allensbach_without_gbs[value]) / len(allensbach_without_gbs[value])\n",
    "\n",
    "\n",
    "allensbach_without_gbs[value] = round(allensbach_without_gbs[value], 6)\n",
    "allensbach_without_gbs.plot.hist(y=value, bins=bins, ax=ax1, weights=weights_allensbach, ec='black')\n",
    "\n",
    "allensbach_gbs[value] = round(allensbach_gbs[value], 6)\n",
    "allensbach_gbs.plot.hist(y=value, bins=bins, ax=ax2, weights=weights_gbs, ec='black')\n",
    "\n",
    "all_mrs_elements[value] = round(all_mrs_elements[value], 6)\n",
    "all_mrs_elements.plot.hist(y=value, bins=bins, ax=ax3, weights=weights_mrs, ec='black')\n",
    "\n",
    "ax2.set_title('GBS')\n",
    "ax3.set_title('MRS')\n",
    "ax1.set_title('Allensbach')\n",
    "ax1.set_xticks([1, 2, 3, 4, 5])\n",
    "ax1.set_ylabel('Percent')\n",
    "\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/statistic/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "f.savefig(file_directory + f'/{value}_histogram.pdf')\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot cumulative distribution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, sharey=True, sharex=True)\n",
    "\n",
    "ax.hist(allensbach_without_gbs['Resilienz'], bins=bins, density=True, histtype='step',\n",
    "                           cumulative=True, label='Allensbach', color='orange', linewidth=2,\n",
    "       linestyle=':')\n",
    "ax.hist(allensbach_gbs['Resilienz'], bins=bins,  density=True, histtype='step',\n",
    "                           cumulative=True, color='blue', linestyle='-.', label='GBS', linewidth=2)\n",
    "ax.hist(all_mrs_elements['Resilienz'], bins=bins, density=True, histtype='step',\n",
    "                           cumulative=True, color='black', linestyle='-', label='All MRS', linewidth=2)\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_xticks([1, 2, 3, 4, 5])\n",
    "ax.set_title('Cumulative distribution functions')\n",
    "plt.xlim(1, 5)\n",
    "plt.savefig(file_directory + f'/{value}_comulative_density.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbs_columns = allensbach_gbs.drop(['label', 'GBS-CODE', 'IE_ext1', 'IE_ext2', 'IE_int1',\n",
    "       'IE_int2', 'BRS1',\n",
    "       'BRS2', 'BRS3', 'BRS4', 'BRS5', 'BRS6', 'Nervoes', 'Nervös', 'Gruppe' ,'Wahlteilnahme',\n",
    "                                  'Wahlabsicht']\n",
    "                                  , axis='columns').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = allensbach_gbs['Resilienz']\n",
    "X = sm.add_constant(X)\n",
    "y = allensbach_gbs['Wahlteilnahme']\n",
    "model_gbs = sm.Logit(y, X)\n",
    "results_gbs = model_gbs.fit() \n",
    "\n",
    "y = all_mrs_elements[\"Wahlteilnahme\"]\n",
    "X = all_mrs_elements['Resilienz']\n",
    "X = sm.add_constant(X)\n",
    "model_all = sm.Logit(y, X)\n",
    "results_all = model_all.fit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_gbs.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create mean models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Likelihood-ratio test GBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loglikelihood_full = results_gbs.llf\n",
    "loglikelihood_restr = restricted_results_gbs.llf\n",
    "lrstat = -2*(loglikelihood_restr - loglikelihood_full)\n",
    "lr_pvalue_gbs = stats.chi2.sf(lrstat, df=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Log Likelihood test MRS list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loglikelihood_full = results_all.llf\n",
    "loglikelihood_restr = restricted_results_all.llf\n",
    "lrstat = -2*(loglikelihood_restr - loglikelihood_full)\n",
    "lr_pvalue_all = stats.chi2.sf(lrstat, df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True)\n",
    "f.suptitle('Logistic regression with 95% Confidence Interval')\n",
    "ax1.set_title(f'GBS')\n",
    "ax1.set_ylabel('Probabilities')\n",
    "ax1.set_xlabel('BRS')\n",
    "ax1.set_xticks([1, 2, 3, 4, 5])\n",
    "\n",
    "intercept_gbs, slope_gbs = results_gbs.params\n",
    "x_line = np.linspace(1, 5, 200)\n",
    "x = allensbach_gbs['Resilienz']\n",
    "y = allensbach_gbs['Wahlteilnahme']\n",
    "log_odds  = slope_gbs * x_line + intercept_gbs\n",
    "y_line = 1 / (1+ np.exp(-log_odds))\n",
    "y_model = results_gbs.predict()\n",
    "x_mean = np.mean(x)\n",
    "n = x.size                        # number of samples\n",
    "m = 1                             # number of parameters\n",
    "dof = n - m  \n",
    "t = stats.t.ppf(0.975, dof)\n",
    "residual = y - y_model\n",
    "std_error = (np.sum(residual**2) / dof)**.5\n",
    "# confidence interval\n",
    "ci = t * std_error * (1/n + (x_line - x_mean)**2 / np.sum((x - x_mean)**2))**.5\n",
    "ci_high = [1 if i>1 else i for i in y_line + ci]\n",
    "ax1.plot(x_line, y_line)\n",
    "ax1.fill_between(x_line, ci_high, y_line - ci, alpha=0.3)\n",
    "\n",
    "intercept_all, slope_all = results_all.params\n",
    "x = all_mrs_elements['Resilienz']\n",
    "y = all_mrs_elements['Wahlteilnahme']\n",
    "log_odds  = slope_all * x_line + intercept_all\n",
    "y_line = 1 / (1 + np.exp(-log_odds))\n",
    "y_model = results_all.predict()\n",
    "x_mean = np.mean(x)\n",
    "n = x.size                        # number of samples\n",
    "m = 1                             # number of parameters\n",
    "dof = n - m  \n",
    "t = stats.t.ppf(0.975, dof)\n",
    "residual = y - y_model\n",
    "std_error = (np.sum(residual**2) / dof)**.5\n",
    "# confidence interval\n",
    "ci = t * std_error * (1/n + (x_line - x_mean)**2 / np.sum((x - x_mean)**2))**.5\n",
    "ci_low = y_line - ci\n",
    "ci_high = [1 if i>1 else i for i in y_line + ci]\n",
    "ax2.set_title('All MRS')\n",
    "ax2.set_xlabel('BRS')\n",
    "ax2.plot(x_line, y_line)\n",
    "ax2.fill_between(x_line, ci_low, ci_high, alpha=0.3)\n",
    "\n",
    "# Show the plot\n",
    "ax1.text(1, 0.99, f'p={round(lr_pvalue_gbs, 3)}',\n",
    "        bbox=dict(facecolor='none', edgecolor='black', pad=2))\n",
    "ax2.text(1, 0.99, f'p={round(lr_pvalue_all, 3)}', \n",
    "         bbox=dict(facecolor='none', edgecolor='black', pad=2))\n",
    "f.savefig(file_directory + '/glm_brs_wahlteilnahme.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrs",
   "language": "python",
   "name": "mrs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
