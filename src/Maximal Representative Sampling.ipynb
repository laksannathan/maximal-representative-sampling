{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MRS Algorithm\n",
    "\n",
    "To allow statistical inference in social sciences, survey participants must be selected at random\n",
    "from the target population. When samples are drawn from parts of the population that are\n",
    "close to hand, subgroups might be over-represented. This leads to statistical analyses under\n",
    "sampling bias, which in turn may produce similarly biased outcomes. This notebook uses machine learning to reduce this selection bias in a psychological survey (**GBS**) using auxiliary information (**GESIS**/**Allensbach**) from comparable studies that are known to be representative. The proposed algorithm is first tested on US national Census data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "from cycler import cycler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.spatial.distance import pdist\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "path = Path(os.getcwd()).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_auc_average(auc_score, std_aucs, drop, file_name, number_of_samples, save, mrs_iterations):\n",
    "    aucs_upper = np.minimum(auc_score + std_aucs, 1)\n",
    "    aucs_younger = np.maximum(auc_score - std_aucs, 0)\n",
    "    x_labels = range(number_of_samples, drop, -drop)\n",
    "    plt.fill_between(x_labels, aucs_younger, aucs_upper, color='blue', alpha=0.2)\n",
    "    plt.plot(x_labels, auc_score, color='blue', linestyle='-')\n",
    "    plt.plot((len(x_labels)-1)*drop *[0.5], color='black', linestyle='--', label='Random')\n",
    "    plt.ylabel('AUROC')\n",
    "    mrs_iterations = number_of_samples - np.array(mrs_iterations)\n",
    "    minimum = min(0.5, np.min(aucs_younger))\n",
    "    maximum = plt.gca().get_ylim()[1]\n",
    "    plt.margins(0.05, 0)\n",
    "    plt.vlines(mrs_iterations, minimum, maximum, colors='black', linestyles='solid')\n",
    "    plt.xticks(list(range(number_of_samples, 0, -100)) + [0])\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xlabel('Number of remaining samples')\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    ax2 = plt.gca().twiny()\n",
    "    ax2.set_xlim(xlim)\n",
    "    plt.xticks(list(mrs_iterations))\n",
    "    [tick.set_color(\"blue\") for tick in plt.gca().get_xticklabels()]\n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_auc(auc_score, drop, file_name, number_of_samples, save=False, mrs_iterations=None):\n",
    "    x_labels = range(number_of_samples, 0, -drop)\n",
    "    plt.plot(x_labels, auc_score, color='blue', linestyle='-', label='AUROC')\n",
    "    plt.plot((len(x_labels)-1)*drop *[0.5], color='black', linestyle='--', label='Random')\n",
    "    plt.ylabel('AUROC')\n",
    "\n",
    "    mrs_iterations = number_of_samples - np.array(mrs_iterations)\n",
    "    minimum = min(0.5, np.min(auc_score))\n",
    "    maximum = plt.gca().get_ylim()[1]\n",
    "    plt.margins(0.05, 0)\n",
    "    plt.vlines(mrs_iterations, minimum, maximum, colors='black', linestyles='solid')\n",
    "    plt.xticks(list(range(number_of_samples, 0, -500)) + [0])\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xlabel('Number of remaining samples')\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    ax2 = plt.gca().twiny()\n",
    "    ax2.set_xlim(xlim)\n",
    "    plt.xticks([mrs_iterations])\n",
    "    [tick.set_color(\"blue\") for tick in plt.gca().get_xticklabels()]\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "def plot_rocs(rocs, file_name,  save=False):\n",
    "    default_cycle = (cycler('linestyle',[':','-.', (0, (3, 5, 1, 5, 1, 5)), '-',]) +\n",
    "                    cycler(color=['blue', 'orange', 'orangered', 'cyan']))\n",
    "    plt.rc('')\n",
    "    plt.rc('axes', prop_cycle=default_cycle)\n",
    "    for fper, tper, std, deleted_elements in rocs:\n",
    "        tpfrs_higher = np.minimum(tper + std, 1)\n",
    "        tpfrs_lower = np.maximum(tper - std, 0)\n",
    "        plt.plot(fper, tper, label=f'{int(deleted_elements[0])} samples removed')\n",
    "        plt.fill_between(fper, tpfrs_lower, tpfrs_higher, alpha=0.2)\n",
    "    plt.plot([0, 1], [0, 1], color='black', linestyle='--', label='Random', linewidth=0.8)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_mmds(mmds, drop, mmd_iteration, file_name, mrs_iterations, number_of_samples, save=False):\n",
    "    x_labels = range(number_of_samples, 0, -drop * mmd_iteration)\n",
    "    plt.plot(x_labels, mmds, linestyle='-')\n",
    "    minimum =  np.min(mmds)\n",
    "    maximum = plt.gca().get_ylim()[1]\n",
    "    plt.margins(0.05, 0)\n",
    "    mrs_iterations = number_of_samples - np.array(mrs_iterations)\n",
    "    plt.vlines(mrs_iterations, minimum, maximum, colors='black', linestyles='solid')\n",
    "    plt.ylabel('Maximum Mean Discrepancy')\n",
    "    plt.xlabel('Number of remaining samples')\n",
    "    plt.xticks(list(range(number_of_samples, 0, -500)) + [0])\n",
    "    plt.gca().invert_xaxis()\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    ax2 = plt.gca().twiny()\n",
    "    ax2.set_xlim(xlim)\n",
    "    plt.xticks([mrs_iterations])\n",
    "    [tick.set_color(\"blue\") for tick in plt.gca().get_xticklabels()]\n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_mmds_average(mmds, std, drop, mmd_iteration, file_name, mrs_iterations,\n",
    "                      number_of_samples, save=False):\n",
    "    mmds_upper = np.minimum(mmds + std, 1)\n",
    "    mmds_more_negative = np.maximum(mmds - std, 0)\n",
    "    x_labels = range(number_of_samples, drop*mmd_iteration, -drop*mmd_iteration)\n",
    "    plt.fill_between(x_labels, mmds_more_negative, mmds_upper, color='black', alpha=0.2)\n",
    "    plt.plot(x_labels, mmds, linestyle='-')\n",
    "    minimum = np.min(mmds_more_negative)\n",
    "    maximum = plt.gca().get_ylim()[1]\n",
    "    plt.margins(0.05, 0)\n",
    "    mrs_iterations = number_of_samples - np.array(mrs_iterations)\n",
    "    plt.vlines(mrs_iterations, minimum, maximum, colors='black', linestyles='solid')\n",
    "    plt.ylabel('Maximum Mean Discrepancy')\n",
    "    plt.xlabel('Number of remaining samples')\n",
    "    plt.xticks(list(range(number_of_samples, 0, -100)) + [0])\n",
    "    plt.gca().invert_xaxis()\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    ax2 = plt.gca().twiny()\n",
    "    ax2.set_xlim(xlim)\n",
    "    plt.xticks(mrs_iterations)\n",
    "    [tick.set_color(\"blue\") for tick in plt.gca().get_xticklabels()]\n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "def plot_class_ratio(ratios, representative_ratio, file_name,  mrs_iterations, number_of_samples, save=False):\n",
    "    plt.xlabel('Number of remaining samples')\n",
    "    plt.ylabel('Ratio of married persons')\n",
    "    x_labels = range(number_of_samples, 0, -drop)\n",
    "\n",
    "    plt.plot(x_labels, ratios, label='non-representative', linestyle='-', color='blue')\n",
    "    plt.plot(number_of_samples*[representative_ratio], color='black', linestyle='--', label='representative')\n",
    "    minimum = np.min(ratios)\n",
    "    maximum = plt.gca().get_ylim()[1]\n",
    "    plt.margins(0.05, 0)\n",
    "    mrs_iterations = number_of_samples - np.array(mrs_iterations)\n",
    "    plt.vlines(mrs_iterations, minimum, maximum, colors='black', linestyles='solid')\n",
    "    plt.xticks(list(range(number_of_samples, 0, -500)) + [0])\n",
    "    plt.legend()\n",
    "    plt.gca().invert_xaxis()\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    ax2 = plt.gca().twiny()\n",
    "    ax2.set_xlim(xlim)\n",
    "    plt.xticks([mrs_iterations])\n",
    "    [tick.set_color(\"blue\") for tick in plt.gca().get_xticklabels()]\n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()\n",
    "  \n",
    "    \n",
    "def plot_experiment_comparison_auc(auc_score_mrs, std_aucs_mrs, auc_score_experiment, std_aucs_experiment, \n",
    "                               experiment_label, drop, file_name, number_of_samples, save=False):\n",
    "    aucs_upper = np.minimum(auc_score_mrs + std_aucs_mrs, 1)\n",
    "    aucs_lower = np.maximum(auc_score_mrs - std_aucs_mrs, 0)\n",
    "    \n",
    "    aucs_upper_experiment = np.minimum(auc_score_experiment + std_aucs_experiment, 1)\n",
    "    aucs_lower_experiment = np.maximum(auc_score_experiment - std_aucs_experiment, 0)\n",
    "    \n",
    "    x_labels = range(number_of_samples, drop, -drop)\n",
    "    \n",
    "    plt.fill_between(x_labels, aucs_lower, aucs_upper, color='blue', alpha=0.2)\n",
    "    plt.plot(x_labels, auc_score_mrs, color='blue', linestyle='-', label='MRS')\n",
    "    \n",
    "    plt.fill_between(x_labels, aucs_lower_experiment, aucs_upper_experiment, color='orange', alpha=0.2)\n",
    "    plt.plot(x_labels, auc_score_experiment, linestyle=':', color='orange', label=experiment_label)\n",
    "    \n",
    "    plt.plot(len(auc_score_mrs)*drop*[0.5], color='black', linestyle='--')\n",
    "    \n",
    "    plt.ylabel('AUROC')\n",
    "    plt.xlabel('Number of remaining samples')\n",
    "    plt.xticks(list(range(number_of_samples, 0, -100)) + [0])\n",
    "    plt.legend()\n",
    "    plt.gca().invert_xaxis()\n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_experiment_comparison_mmd(median_mmd, std_mmd,  median_mmd_experiment, std_mmd_experiment, \n",
    "                               experiment_label, drop, mmd_iteration, file_name, number_of_samples,\n",
    "                                   save=False):\n",
    "    mmd_upper = np.minimum(median_mmd + std_mmd, 1)\n",
    "    mmd_lower = np.maximum(median_mmd - std_mmd, 0)\n",
    "    \n",
    "    mmd_upper_experiment = np.minimum(median_mmd_experiment + std_mmd_experiment, 1)\n",
    "    mmd_lower_experiment = np.maximum(median_mmd_experiment - std_mmd_experiment, 0)\n",
    "    \n",
    "    x_labels = range(number_of_samples, drop*mmd_iteration, -drop*mmd_iteration)\n",
    "    \n",
    "    plt.fill_between(x_labels, mmd_lower, mmd_upper, color='blue', alpha=0.2)\n",
    "    plt.plot(x_labels, median_mmd, color='blue', linestyle='-', label='MRS')\n",
    "    \n",
    "    plt.fill_between(x_labels, mmd_lower_experiment, mmd_upper_experiment, color='orange', alpha=0.2)\n",
    "    plt.plot(x_labels, median_mmd_experiment, linestyle=':', color='orange', label=experiment_label)\n",
    "    \n",
    "    plt.ylabel('Maximum mean discrepancy')\n",
    "    plt.xlabel('Number of remaining samples')\n",
    "    plt.xticks(list(range(number_of_samples, 0, -100)) + [0])\n",
    "    plt.legend()\n",
    "    plt.gca().invert_xaxis()\n",
    "    if save:\n",
    "        plt.savefig(f'{file_name}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_rbf_gamma(aggregate_set):\n",
    "    all_distances = pdist(aggregate_set.values, 'euclid')\n",
    "    sigma = np.median(all_distances)\n",
    "    return 1 / (2 * (sigma ** 2))\n",
    "\n",
    "def compute_maximum_mean_discrepancy(x, y):\n",
    "    gamma = calculate_rbf_gamma(pd.concat([x, y]))\n",
    "    x_x_rbf_matrix = rbf_kernel(x, x, gamma)\n",
    "    y_y_rbf_matrix = rbf_kernel(y, y, gamma)\n",
    "    x_y_rbf_matrix = rbf_kernel(x, y, gamma)\n",
    "    a = 1 / (len(x) * len(x))\n",
    "    b = 2 / (len(x) * len(y))\n",
    "    c = 1 / (len(y) * len(y))\n",
    "    maximum_mean_discrepancy = (a * x_x_rbf_matrix.sum()) -(b * x_y_rbf_matrix.sum()) \\\n",
    "    + (c * y_y_rbf_matrix.sum())\n",
    "    return np.sqrt(maximum_mean_discrepancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def grid_search(X_train, y_train, cv=5):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "    ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "    ccp_alphas[ccp_alphas < 0] = 0\n",
    "    param_grid = {'ccp_alpha': ccp_alphas}\n",
    "    grid = GridSearchCV(DecisionTreeClassifier(random_state=5), param_grid, cv=cv, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def temperature_sample(softmax: list,\n",
    "                       temperature: float,\n",
    "                       drop: int):\n",
    "    EPSILON = 10e-16 # to avoid taking the log of zero\n",
    "    softmax = (np.array(softmax)).astype('float64')\n",
    "    softmax[softmax == 0] = EPSILON\n",
    "    preds = np.log(softmax) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    count = 0\n",
    "    while np.isnan(preds).any() and count < 100:\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        count += 1\n",
    "        \n",
    "    if count == 100:\n",
    "        return []\n",
    "        \n",
    "    if len(preds[preds != 0]) < drop:\n",
    "        drop = preds[preds != 0]\n",
    "    return np.random.choice(len(preds), drop, replace=False, p=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cv_bootstrap_prediction(N, R, number_of_splits, columns, cv):\n",
    "    preds = np.zeros(len(N))\n",
    "    preds_r = np.zeros(len(R))\n",
    "    bootstrap_iterations = 10\n",
    "    \n",
    "    kf = KFold(n_splits=number_of_splits, shuffle=True)\n",
    "    for split_n, split_r in zip(kf.split(N), kf.split(R)):\n",
    "        train_index, test_index = split_n\n",
    "        train_index_r, test_index_r  = split_r\n",
    "        N_train, N_test = N.iloc[train_index], N.iloc[test_index]\n",
    "        R_train, R_test = R.iloc[train_index_r], R.iloc[test_index_r]\n",
    "        n = min(len(R_train), len(N_train))\n",
    "        bootstrap_predictions = []\n",
    "        bootstrap_predictions_r = []\n",
    "        for j in range(bootstrap_iterations):\n",
    "            bootstrap = pd.concat([N_train.sample(n=n, replace=True),\n",
    "                                      R_train.sample(n=n, replace=True)])\n",
    "            clf = grid_search(bootstrap[columns], bootstrap.label, cv)\n",
    "            bootstrap_predictions.append(clf.predict_proba(N_test[columns])[:,1])\n",
    "            bootstrap_predictions_r.append(clf.predict_proba(R_test[columns])[:,1])\n",
    "        preds[test_index]  = np.mean(bootstrap_predictions, axis=0)\n",
    "        preds_r[test_index_r] = np.mean(bootstrap_predictions_r, axis=0)\n",
    "    return preds, preds_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def auc_prediction(N, R, columns, drop, iteration, cv=5, calculate_roc=False):\n",
    "    data = pd.concat([N, R])\n",
    "    auroc_scores = []\n",
    "    rocs = []\n",
    "    median_roc = None\n",
    "    mean_roc = None\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    for train, test in kf.split(data[columns], data['label']):\n",
    "        train, test = data.iloc[train], data.iloc[test]\n",
    "        y_train = train['label']\n",
    "        clf = grid_search(train[columns], y_train, cv)\n",
    "        y_predict = clf.predict_proba(test[columns])[:,1]\n",
    "        y_test = test['label']\n",
    "        auroc_scores.append(roc_auc_score(y_test, y_predict))\n",
    "        if calculate_roc:\n",
    "            rocs.append(interpolate_roc(y_test, y_predict, drop, iteration))\n",
    "    if calculate_roc:\n",
    "        median_roc = calculate_median_roc(rocs)\n",
    "        mean_roc = calculate_mean_roc(rocs)\n",
    "        \n",
    "    return np.mean(auroc_scores), median_roc, mean_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def interpolate_roc(y_test, y_predict, drop, iteration):\n",
    "    interpolation_points = 250\n",
    "    interpolated_fpr = np.linspace(0, 1, interpolation_points)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_predict)\n",
    "    interp_tpr = np.interp(interpolated_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    return interpolated_fpr, interp_tpr, [iteration * drop] * interpolation_points\n",
    "\n",
    "def calculate_median_roc(rocs):\n",
    "    rocs = np.array(rocs)\n",
    "    median_fpr = np.median(rocs[:, 0], axis = 0)\n",
    "    median_tpr = np.median(rocs[:, 1], axis = 0)\n",
    "    mad_tpr = np.median(np.absolute(rocs[:, 1] - np.median(rocs[:, 1], axis=0)), axis=0)\n",
    "    removed_samples = rocs[0, 2]\n",
    "    return median_fpr, median_tpr, mad_tpr, removed_samples\n",
    "\n",
    "def calculate_mean_roc(rocs):\n",
    "    rocs = np.array(rocs)\n",
    "    mean_fpr = np.mean(rocs[:, 0], axis = 0)\n",
    "    mean_tpr = np.mean(rocs[:, 1], axis = 0)\n",
    "    std_tpr = np.std(rocs[:, 1], axis = 0)\n",
    "    removed_samples = rocs[0, 2]\n",
    "    return mean_fpr, mean_tpr, std_tpr, removed_samples\n",
    "\n",
    "def calculate_median_rocs(rocs):\n",
    "    rocs = np.array(rocs)\n",
    "    median_rocs = []\n",
    "    for i in range(rocs.shape[1]):\n",
    "        rocs_at_iteration = rocs[:, i]\n",
    "        median_fpr = np.median(rocs_at_iteration[:, 0], axis = 0)\n",
    "        median_tpr = np.median(rocs_at_iteration[:, 1], axis = 0)\n",
    "        mad_tpr = np.median(np.absolute(rocs_at_iteration[:, 1] - np.median(rocs_at_iteration[:, 1], axis=0)), axis=0)\n",
    "        removed_samples = rocs_at_iteration[0, 3]\n",
    "        median_rocs.append((median_fpr, median_tpr, mad_tpr, removed_samples))\n",
    "    return median_rocs\n",
    "\n",
    "def calculate_mean_rocs(rocs):\n",
    "    rocs = np.array(rocs)\n",
    "    median_rocs = []\n",
    "    for i in range(rocs.shape[1]):\n",
    "        rocs_at_iteration = rocs[:, i]\n",
    "        mean_fpr = np.mean(rocs_at_iteration[:, 0], axis = 0)\n",
    "        mean_tpr = np.mean(rocs_at_iteration[:, 1], axis = 0)\n",
    "        std_tpr = np.std(rocs_at_iteration[:, 1], axis = 0)\n",
    "        removed_samples = rocs_at_iteration[0, 3]\n",
    "        median_rocs.append((mean_fpr, mean_tpr, std_tpr, removed_samples))\n",
    "    return median_rocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def MRS(N, R, columns, number_of_splits = 5, n_drop: int=1, cv=5, temperature_sampling=True):\n",
    "    \"\"\"\n",
    "    MRS Algorithm\n",
    "    \n",
    "    Input:\n",
    "        * N: dataset that is assumed to not be representative.\n",
    "        * R: dataset that is known to be representative.\n",
    "        * temperature: temperature value for probabilistic sampling procedure.\n",
    "        * drop: number of instances to drop per iteration (small values result in long runtimes).\n",
    "        * number_of_splits: splits per iteration.\n",
    "    \n",
    "    Output:\n",
    "        * N/Drop: N without the dropped elements\n",
    "    \"\"\" \n",
    "    \n",
    "    preds, preds_r = cv_bootstrap_prediction(N, R, number_of_splits, columns, cv)\n",
    "    all_preds = np.concatenate([preds, preds_r])\n",
    "    all_true = np.concatenate([np.ones(len(preds)), np.zeros(len(preds_r))])\n",
    "    auc = roc_auc_score(all_true, all_preds)\n",
    "    \n",
    "    if temperature_sampling:\n",
    "        mapped_auc = abs(auc - 0.5)\n",
    "        temperature = -0.55 * mapped_auc + 0.3\n",
    "    else:\n",
    "        temperature = 1\n",
    "    drop_ids = temperature_sample(preds, temperature, n_drop)\n",
    "    \n",
    "   \n",
    "    return N.drop(N.index[drop_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def repeated_MRS(df, columns, number_of_splits, n_drop=1, cv=5, us=False,\n",
    "                 census_bias='', temperature_sampling=True, number_of_iterations=None, mmd_iteration = 1):\n",
    "    \n",
    "    N = df[df['label'] == 1].copy()\n",
    "    R = df[df['label'] == 0].copy()\n",
    "    if number_of_iterations is None:\n",
    "        number_of_iterations = int(len(N) / drop)\n",
    "    aucs = []\n",
    "    mean_rocs = []\n",
    "    median_rocs = []\n",
    "    ratio = []\n",
    "    mmds = []\n",
    "    \n",
    "    \n",
    "    auroc_iteration = int(int(len(N) / n_drop) / 3.5) + 1\n",
    "    \n",
    "    if us:\n",
    "        ratio.extend([len(N[N[census_bias] == 1]) / (len(N[N[census_bias] == 0]))])\n",
    "        \n",
    "    #start value\n",
    "    auc, median_roc, mean_roc = auc_prediction(N, R, columns, drop, 0, cv, True)\n",
    "    aucs.append(auc)\n",
    "    median_rocs.append(median_roc)\n",
    "    mean_rocs.append(mean_roc)\n",
    "    mmds.append(compute_maximum_mean_discrepancy(N[columns], R[columns]))\n",
    "    \n",
    "    best_auc = auc\n",
    "    mrs_iteration = 0\n",
    "    min_delta = 0.01\n",
    "    mrs = N\n",
    "    \n",
    "    for i in tqdm(range(number_of_iterations)):\n",
    "        N = MRS(N, R, columns,\n",
    "                                number_of_splits=number_of_splits,\n",
    "                                n_drop=n_drop, cv=cv,\n",
    "                                temperature_sampling=temperature_sampling)\n",
    "\n",
    "        if (i+1) % auroc_iteration == 0:\n",
    "            auc, median_roc, mean_roc = auc_prediction(N, R, columns, drop, i+1, cv, calculate_roc=True)\n",
    "            aucs.append(auc)\n",
    "            median_rocs.append(median_roc)\n",
    "            mean_rocs.append(mean_roc)\n",
    "        else:\n",
    "            auc, _ = auc_prediction(N, R, columns, drop, i+1, cv, calculate_roc=False)\n",
    "            aucs.append(auc)\n",
    "        \n",
    "        if abs(auc - 0.5) < abs(best_auc - 0.5) - min_delta:\n",
    "            best_auc = auc\n",
    "            mrs_iteration = (i + 1) * n_drop\n",
    "            mrs = N.copy(deep=True)\n",
    "            \n",
    "        \n",
    "        # only for US Census experiment\n",
    "        if us:\n",
    "            ratio.extend([len(N[N[census_bias] == 1]) / (len(N[N[census_bias] == 0]))])\n",
    "                 \n",
    "        if (i+1) % mmd_iteration == 0:\n",
    "            mmds.append(compute_maximum_mean_discrepancy(N[columns], R[columns]))\n",
    "            \n",
    "        if len(N)-drop <= cv or len(N)-drop <= number_of_splits:\n",
    "            break\n",
    "    \n",
    "    if us:\n",
    "        return ratio, aucs,  mmds, mrs_iteration\n",
    "    else:\n",
    "        return aucs, mean_rocs, median_rocs, mrs, mmds, mrs_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment 1\n",
    "### <font color='darkblue'>US National Census (Income)</font>  <a name=\"us\"></a>\n",
    "\n",
    "*About this Dataset*\n",
    "\n",
    "**US Adult Census** (1994) relates income to social factors: \n",
    "\n",
    "- *age*: continuous.\n",
    "- *workclass*: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "- *fnlwgt*: continuous.\n",
    "- *education*: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "- *education-num*: continuous.\n",
    "- *marital-status*: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "- *occupation*: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "- *relationship*: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "- *race*: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "- *sex*: Female, Male.\n",
    "- *capital-gain*: continuous.\n",
    "- *capital-loss*: continuous.\n",
    "- *hours-per-week*: continuous.\n",
    "- *native-country*: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n",
    "Each row is labelled as either being married or not.\n",
    "\n",
    "Note: This Dataset was obtained from the UCI repository, it can be found on:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/census+income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columns = ['Age','Workclass','fnlgwt','Education','Education Num','Marital Status',\n",
    "           'Occupation','Relationship','Race','Sex','Capital Gain','Capital Loss',\n",
    "           'Hours/Week','Country','Above_Below 50K']\n",
    "\n",
    "df = pd.read_csv(os.path.join(path, 'data/Census_Income/adult.data'), names=columns, \n",
    "                    na_values=['-1', -1, ' ?'])\n",
    "\n",
    "df = df.replace([\" Cambodia\" , \" China\", \" Hong\", \" Laos\", \" Thailand\",\n",
    "                \" Japan\", \" Taiwan\", \" Vietnam\", \" Philippines\", \" India\", \" Iran\",\n",
    "                \" Cuba\", \" Guatemala\", \" Jamaica\", \" Nicaragua\", \n",
    "                        \" Puerto-Rico\",  \" Dominican-Republic\", \" El-Salvador\", \n",
    "                        \" Haiti\", \" Honduras\", \" Mexico\", \" Trinadad&Tobago\",\n",
    "                \" Ecuador\", \" Peru\", \" Columbia\", \" South\",\n",
    "               \" Poland\", \" Yugoslavia\", \" Hungary\", \" Outlying-US(Guam-USVI-etc)\"], \"other\")\n",
    "df = df.replace([\" England\", \" Germany\", \" Holand-Netherlands\", \" Ireland\", \n",
    "                \" France\", \" Greece\", \" Italy\", \" Portugal\", \" Scotland\"], \"west_europe\")\n",
    "df = df.replace([\" Married-civ-spouse\", \" Married-spouse-absent\", \" Married-AF-spouse\"], 'Married')\n",
    "\n",
    "df.replace(' >50K.', 1, inplace=True)\n",
    "df.replace(' >50K', 1, inplace=True)\n",
    "df.replace(' <=50K.', 0, inplace=True)\n",
    "df.replace(' <=50K', 0, inplace=True)\n",
    "\n",
    "df['Sex'].replace(' Male', 1, inplace=True)\n",
    "df['Sex'].replace(' Female', 0, inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "census_bias = 'Marital Status_Married'\n",
    "education_num_border =  12\n",
    "\n",
    "ctg = [\n",
    "    'Workclass', \n",
    "    'Marital Status',       \n",
    "    'Occupation',\n",
    "    'Race', \n",
    "    'Country'\n",
    "      ]\n",
    "\n",
    "for c in ctg:\n",
    "    df = pd.concat([df, pd.get_dummies(df[c], \n",
    "                                       prefix=c,\n",
    "                                       dummy_na=False)], axis=1).drop([c],axis=1)\n",
    "    \n",
    "census_columns = list(df.columns)\n",
    "meta = ['label', 'index', 'fnlgwt', 'Education', 'Relationship', census_bias]\n",
    "for m in meta:\n",
    "    if m in census_columns:\n",
    "        census_columns.remove(m)\n",
    "\n",
    "\n",
    "scaling_columns = [\n",
    "    'Age', \n",
    "    'Capital Loss',\n",
    "    'Capital Gain',\n",
    "    'Education Num',\n",
    "    'Hours/Week',\n",
    "]\n",
    "\n",
    "scale = StandardScaler()\n",
    "df[scaling_columns] = scale.fit_transform(df[scaling_columns])\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correlation = df.corr()\n",
    "plt.matshow(abs(correlation))\n",
    "plt.savefig('final_results/census/correlation_census.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correlation = abs(correlation)\n",
    "correlation_ranking = correlation.mean().sort_values(ascending=False)\n",
    "correlation_ranking.to_csv('final_results/census/correlation_ranking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)\n",
    "\n",
    "df_copy = df.copy()\n",
    "df_positive_class = df_copy[(df_copy[census_bias] == 1)].copy()\n",
    "df_negative_class = df_copy[(df_copy[census_bias] == 0)].copy()\n",
    "\n",
    "rep_fraction = 0.12\n",
    "bias_fraction = 0.05\n",
    "negative_normal = len(df_negative_class)\n",
    "positive_normal = len(df_positive_class)\n",
    "\n",
    "\n",
    "#-----------------Simulate non-representative data---------------------#\n",
    "rep = pd.concat([df_negative_class.head(int(negative_normal * 0.2)),\n",
    "                df_positive_class.head(int(positive_normal * 0.2))],\n",
    "                ignore_index=True) \n",
    "\n",
    "nonrep_more_negative_class = pd.concat([df_negative_class.tail(int(negative_normal * rep_fraction)), \n",
    "                             df_positive_class.tail(int(positive_normal * (rep_fraction - bias_fraction)))],\n",
    "                            ignore_index=True)\n",
    "\n",
    "nonrep_more_positive_class = pd.concat([df_negative_class.tail(int(negative_normal * (rep_fraction - bias_fraction))),\n",
    "                             df_positive_class.tail(int(positive_normal * rep_fraction))], \n",
    "                             ignore_index=True)\n",
    "\n",
    "\n",
    "#-----------------Simulate representative data---------------------#\n",
    "rep2 = pd.concat([df_negative_class.tail(int(negative_normal * rep_fraction)),\n",
    "                 df_positive_class.tail(int(positive_normal * rep_fraction))], \n",
    "                 ignore_index=True) \n",
    "\n",
    "rep['label'] = 0\n",
    "nonrep_more_negative_class['label'] = 1\n",
    "nonrep_more_positive_class['label'] = 1\n",
    "rep2['label'] = 1\n",
    "\n",
    "print(\"Current setting:\")\n",
    "print('Rep: \\n', rep[census_bias].value_counts())\n",
    "print('Rep 2: \\n', rep2[census_bias].value_counts())\n",
    "print('nonrep_more_positive_class: \\n', nonrep_more_positive_class[census_bias].value_counts())\n",
    "print('nonrep_more_negative_class: \\n', nonrep_more_negative_class[census_bias].value_counts())\n",
    "\n",
    "census_nonrep_more_negative_class = pd.concat([rep.copy(deep=True), nonrep_more_negative_class.copy(deep=True)])\n",
    "census_nonrep_more_positive_class = pd.concat([rep.copy(deep=True), nonrep_more_positive_class.copy(deep=True)])\n",
    "census_rep = pd.concat([rep.copy(deep=True), rep2.copy(deep=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment 1 a)\n",
    "\n",
    "\n",
    "### Simulate non-representative data. More married persons than in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop = 25\n",
    "number_of_splits = 5\n",
    "cv = 5\n",
    "mmd_iteration = 1\n",
    "\n",
    "representative_ratio = (len(rep[rep[census_bias] == 1]) / len(rep[rep[census_bias] == 0]))\n",
    "ratio, auc_more_negative, mmds, mrs_iteration = repeated_MRS(census_nonrep_more_negative_class,\n",
    "                    census_columns,\n",
    "                    number_of_splits = number_of_splits, \n",
    "                    n_drop = drop,\n",
    "                    cv = cv, us = True,\n",
    "                    census_bias=census_bias, \n",
    "                    mmd_iteration=mmd_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(ratio, open(\"results/ratio_more_negative_class\", 'wb'))\n",
    "pickle.dump(representative_ratio, open(\"results/representative_ratio_more_negative_class\", 'wb'))\n",
    "pickle.dump(auc_more_negative, open(\"results/auc_more_negative_class\", 'wb'))\n",
    "pickle.dump(mmds, open(\"results/mmd_more_negative_class\", 'wb'))\n",
    "pickle.dump(mrs_iteration, open(\"results/more_negative_class_mrs_iterations\", 'wb'))\n",
    "pickle.dump(len(nonrep_more_negative_class), \n",
    "            open('results/len_of_more_negative_class', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratio_more_negative_class = pickle.load(open(\"results/ratio_more_negative_class\", 'rb'))\n",
    "representative_ratio_more_negative_class = pickle.load(open(\n",
    "    \"results/representative_ratio_more_negative_class\", 'rb'))\n",
    "auc_more_negative = pickle.load(open(\"results/auc_more_negative_class\", 'rb'))\n",
    "mmd_more_negative_class = pickle.load(open(\"results/mmd_more_negative_class\", 'rb'))\n",
    "more_negative_class_mrs_iterations = pickle.load(open(\"results/more_negative_class_mrs_iterations\", 'rb'))\n",
    "len_of_more_negative_class = pickle.load(open('results/len_of_more_negative_class', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "mmd_iteration = 1\n",
    "drop = 25\n",
    "\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/census/more_negative/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "\n",
    "plot_class_ratio(ratio_more_negative_class, representative_ratio_more_negative_class, \n",
    "                 file_directory+'ratio_more_negative',\n",
    "                 more_negative_class_mrs_iterations, len_of_more_negative_class,\n",
    "                 save=save)\n",
    "plot_auc(auc_more_negative, drop, file_directory+'auc_more_negative', len_of_more_negative_class,\n",
    "         save=save, \n",
    "         mrs_iterations=more_negative_class_mrs_iterations)\n",
    "plot_mmds(mmd_more_negative_class, drop, mmd_iteration, file_directory+'mmd_more_negative', \n",
    "          more_negative_class_mrs_iterations, len_of_more_negative_class, save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment 1 b)\n",
    "\n",
    "\n",
    "### Simulate non-representative data. Less married persons than in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop = 25\n",
    "number_of_splits = 5\n",
    "mmd_iteration = 1\n",
    "representative_ratio = (len(rep[rep[census_bias] == 1]) / len(rep[rep[census_bias] == 0]))\n",
    "save = True\n",
    "cv = 5\n",
    "\n",
    "ratio, auc_more_positive_class, mmds, mrs_iteration = repeated_MRS(census_nonrep_more_positive_class, census_columns,\n",
    "                                                   number_of_splits = number_of_splits, n_drop = drop,\n",
    "                                                   cv = cv, us = True,\n",
    "                                                   census_bias=census_bias, \n",
    "                                                   mmd_iteration=mmd_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(ratio, open(\"results/ratio_more_positive_class\", 'wb'))\n",
    "pickle.dump(representative_ratio, open(\"results/representative_ratio_more_positive_class\", 'wb'))\n",
    "pickle.dump(auc_more_positive_class, open(\"results/auc_more_positive_class\", 'wb'))\n",
    "pickle.dump(mmds, open(\"results/mmd_more_positive_class\", 'wb'))\n",
    "pickle.dump(mrs_iteration, open(\"results/more_positive_class_mrs_iterations\", 'wb'))\n",
    "pickle.dump(len(nonrep_more_positive_class), \n",
    "            open('results/len_of_more_positive_class', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratio_more_positive = pickle.load(open(\"results/ratio_more_positive_class\", 'rb'))\n",
    "representative_ratio_more_positive = pickle.load(open(\"results/representative_ratio_more_positive_class\", 'rb'))\n",
    "auc_more_positive_class = pickle.load(open(\"results/auc_more_positive_class\", 'rb'))\n",
    "mmd_more_positive = pickle.load(open(\"results/mmd_more_positive_class\", 'rb'))\n",
    "more_positive_mrs_iterations = pickle.load(open(\"results/more_positive_class_mrs_iterations\", 'rb'))\n",
    "len_of_more_positive_class = pickle.load(open('results/len_of_more_positive_class', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "mmd_iteration = 1\n",
    "\n",
    "drop = 25\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/census/more_positive/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "\n",
    "plot_class_ratio(ratio_more_positive, representative_ratio_more_positive,\n",
    "                 file_directory+'ratio_more_positive', more_positive_mrs_iterations, \n",
    "                 len_of_more_positive_class, save=save)\n",
    "plot_auc(auc_more_positive_class, drop, file_directory+'auc_more_positive', len_of_more_positive_class, \n",
    "         save=save,\n",
    "         mrs_iterations=more_positive_mrs_iterations)\n",
    "plot_mmds(mmd_more_positive, drop, mmd_iteration, file_directory+'mmd_more_positive', \n",
    "          more_positive_mrs_iterations, len_of_more_positive_class, save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment 1 c)\n",
    "\n",
    "\n",
    "### Simulate already representative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop = 25\n",
    "number_of_splits = 5\n",
    "representative_ratio = (len(rep[rep[census_bias] == 1]) / len(rep[rep[census_bias] == 0]))\n",
    "cv = 3\n",
    "mmd_iteration = 1\n",
    "save = True\n",
    "\n",
    "ratio, auc_same, mmds, mrs_iteration = repeated_MRS(census_rep, census_columns,\n",
    "                                            number_of_splits = number_of_splits, n_drop = drop,\n",
    "                                            cv = cv, us = True,\n",
    "                                            census_bias=census_bias, \n",
    "                                            mmd_iteration=mmd_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(ratio, open(\"results/ratio_same\", 'wb'))\n",
    "pickle.dump(representative_ratio, open(\"results/representative_ratio_same\", 'wb'))\n",
    "pickle.dump(auc_same, open(\"results/auc_same\", 'wb'))\n",
    "pickle.dump(mmds, open(\"results/mmd_same\", 'wb'))\n",
    "pickle.dump(mrs_iteration, open(\"results/same_mrs_iterations\", 'wb'))\n",
    "pickle.dump(len(rep2), open('results/len_of_rep', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratio_same = pickle.load(open(\"results/ratio_same\", 'rb'))\n",
    "representative_ratio_same = pickle.load(open(\"results/representative_ratio_same\", 'rb'))\n",
    "auc_same = pickle.load(open(\"results/auc_same\", 'rb'))\n",
    "mmd_same = pickle.load(open(\"results/mmd_same\", 'rb'))\n",
    "same_mrs_iterations = pickle.load(open(\"results/same_mrs_iterations\", 'rb'))\n",
    "len_of_rep = pickle.load(open('results/len_of_rep', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "mmd_iteration = 1\n",
    "same_drop = 25\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/census/same/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "\n",
    "plot_class_ratio(ratio_same, representative_ratio_same, file_directory+'ratio_same', \n",
    "                 same_mrs_iterations, len_of_rep, save=save)\n",
    "plot_auc(auc_same, same_drop, file_directory+'auc_same', len_of_rep, \n",
    "         save=save, mrs_iterations=same_mrs_iterations)\n",
    "plot_mmds(mmd_same, same_drop, mmd_iteration,\n",
    "          file_directory+'mmd_same', same_mrs_iterations, len_of_rep, save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment 2\n",
    "### <font color='darkgreen'>Allensbach</font>   <---MRS---> <font color='darkred'>GBS</font> <---MRS---> <font color='darkgreen'>GESIS</font> \n",
    "\n",
    "*Figure shows MRS concept on GBS and GESIS for experiment 2 a). Replace Allensbach with GESIS for experiment 2 b)*\n",
    "\n",
    "<img src=\"overview.PNG\" width=\"450\" height=\"450\"/>\n",
    "\n",
    "\n",
    "**Multivariate auxiliary information GESIS linked to GBS so that expected selection bias can be detected and corrected for. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment 2 a)\n",
    "### <font color='darkgreen'>Allensbach Studie - Institut f√ºr Demoskopie(IfD)</font>  <a name=\"us\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color='darkred'>Important note:</font>  <a name=\"allensbach\"></a> Allensbach is already merged with GBS in this data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "allensbach = pd.read_csv(os.path.join(path, 'data/allensbach_mrs.csv'))\n",
    "allensbach.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "allensbach_columns = ['Alter', 'Berufsgruppe', 'Erwerbstaetigkeit', 'Geschlecht',\n",
    "                      'Optimismus', 'Pessimismus', 'Schulabschluss', 'woechentlicheArbeitszeit', 'Resilienz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90978ae5cb4b4c3196f5f371f9733c77"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1185097114272007\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/115 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eee5f39e560a4e8f8faabe34ec90ad1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 16>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     14\u001B[0m mrs_iterations \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(repetitions)):\n\u001B[0;32m---> 17\u001B[0m     auc, mean_roc, median_roc, mrs, mmd, mrs_iteration \u001B[38;5;241m=\u001B[39m \u001B[43mrepeated_MRS\u001B[49m\u001B[43m(\u001B[49m\u001B[43mallensbach\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallensbach_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mnumber_of_splits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumber_of_splits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_drop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m     aucs\u001B[38;5;241m.\u001B[39mappend(auc)\n\u001B[1;32m     20\u001B[0m     mean_rocs\u001B[38;5;241m.\u001B[39mappend(mean_roc)\n",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36mrepeated_MRS\u001B[0;34m(df, columns, number_of_splits, n_drop, test_size, cv, us, census_bias, temperature_sampling, number_of_iterations, mmd_iteration)\u001B[0m\n\u001B[1;32m     28\u001B[0m mrs \u001B[38;5;241m=\u001B[39m N\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(number_of_iterations)):\n\u001B[0;32m---> 31\u001B[0m     N \u001B[38;5;241m=\u001B[39m \u001B[43mMRS\u001B[49m\u001B[43m(\u001B[49m\u001B[43mN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mnumber_of_splits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumber_of_splits\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mn_drop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_drop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mtemperature_sampling\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtemperature_sampling\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m%\u001B[39m auroc_iteration \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     37\u001B[0m         auc, roc \u001B[38;5;241m=\u001B[39m auc_prediction(N, R, columns, drop, i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m, cv, calculate_roc\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36mMRS\u001B[0;34m(N, R, columns, number_of_splits, n_drop, cv, temperature_sampling)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mMRS\u001B[39m(N, R, columns, number_of_splits \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m, n_drop: \u001B[38;5;28mint\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, temperature_sampling\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m    MRS Algorithm\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m    \u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03m        * N/Drop: N without the dropped elements\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m \n\u001B[0;32m---> 16\u001B[0m     preds, preds_r \u001B[38;5;241m=\u001B[39m \u001B[43mcv_bootstrap_prediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_splits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m     all_preds \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate([preds, preds_r])\n\u001B[1;32m     18\u001B[0m     all_true \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate([np\u001B[38;5;241m.\u001B[39mones(\u001B[38;5;28mlen\u001B[39m(preds)), np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mlen\u001B[39m(preds_r))])\n",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36mcv_bootstrap_prediction\u001B[0;34m(N, R, number_of_splits, columns, cv)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(bootstrap_iterations):\n\u001B[1;32m     16\u001B[0m     bootstrap \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([N_train\u001B[38;5;241m.\u001B[39msample(n\u001B[38;5;241m=\u001B[39mn, replace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[1;32m     17\u001B[0m                               R_train\u001B[38;5;241m.\u001B[39msample(n\u001B[38;5;241m=\u001B[39mn, replace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)])\n\u001B[0;32m---> 18\u001B[0m     clf \u001B[38;5;241m=\u001B[39m \u001B[43mgrid_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbootstrap\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m     bootstrap_predictions\u001B[38;5;241m.\u001B[39mappend(clf\u001B[38;5;241m.\u001B[39mpredict_proba(N_test[columns])[:,\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m     20\u001B[0m     bootstrap_predictions_r\u001B[38;5;241m.\u001B[39mappend(clf\u001B[38;5;241m.\u001B[39mpredict_proba(R_test[columns])[:,\u001B[38;5;241m1\u001B[39m])\n",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36mgrid_search\u001B[0;34m(X_train, y_train, cv)\u001B[0m\n\u001B[1;32m      6\u001B[0m param_grid \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mccp_alpha\u001B[39m\u001B[38;5;124m'\u001B[39m: ccp_alphas}\n\u001B[1;32m      7\u001B[0m grid \u001B[38;5;241m=\u001B[39m GridSearchCV(DecisionTreeClassifier(random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m), param_grid, cv\u001B[38;5;241m=\u001B[39mcv, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m----> 8\u001B[0m \u001B[43mgrid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m grid\u001B[38;5;241m.\u001B[39mbest_estimator_\n",
      "File \u001B[0;32m~/.virtualenvs/mrs/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    869\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    870\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    871\u001B[0m     )\n\u001B[1;32m    873\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 875\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    878\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    879\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/.virtualenvs/mrs/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1375\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1373\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1374\u001B[0m     \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1375\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/mrs/lib/python3.9/site-packages/sklearn/model_selection/_search.py:822\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    817\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    818\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    819\u001B[0m         )\n\u001B[1;32m    820\u001B[0m     )\n\u001B[0;32m--> 822\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    823\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    832\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    835\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    837\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    841\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    842\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    843\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    844\u001B[0m     )\n",
      "File \u001B[0;32m~/.virtualenvs/mrs/lib/python3.9/site-packages/joblib/parallel.py:1056\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1053\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1055\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1056\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1057\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1058\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m~/.virtualenvs/mrs/lib/python3.9/site-packages/joblib/parallel.py:935\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    933\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    934\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 935\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    936\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    937\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m~/.virtualenvs/mrs/lib/python3.9/site-packages/joblib/_parallel_backends.py:542\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    539\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    540\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    541\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 542\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:441\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    438\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 441\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[1;32m    444\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[0;32m/usr/lib/python3.9/threading.py:312\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 312\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    313\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "drop = 5\n",
    "number_of_splits = 5\n",
    "repetitions = 10\n",
    "cv = 5\n",
    "\n",
    "number_of_iterations = int(len(allensbach[allensbach['label']  == 1]) / drop)\n",
    "\n",
    "aucs = []\n",
    "median_rocs = []\n",
    "mean_rocs = []\n",
    "\n",
    "mmds = []\n",
    "mmd_iteration = 1\n",
    "mrs_iterations = []\n",
    "\n",
    "for _ in tqdm(range(repetitions)):\n",
    "    auc, mean_roc, median_roc, mrs, mmd, mrs_iteration = repeated_MRS(allensbach, allensbach_columns,\n",
    "                     number_of_splits=number_of_splits, n_drop=drop, cv=cv)\n",
    "    aucs.append(auc)\n",
    "    mean_rocs.append(mean_roc)\n",
    "    median_rocs.append(median_roc)\n",
    "    mmds.append(mmd)\n",
    "    mrs_iterations.append(mrs_iteration)\n",
    "\n",
    "    mean_mmds = np.mean(mmds, axis = 0)\n",
    "    std_mmds = np.std(mmds, axis = 0)\n",
    "    mean_aucs = np.mean(aucs, axis = 0)\n",
    "    std_aucs = np.std(aucs, axis = 0)\n",
    "\n",
    "    median_mmds = np.median(mmds, axis = 0)\n",
    "    mad_mmds = np.median(np.abs(mmds - np.median(mmds, axis=0)), axis=0)\n",
    "    median_aucs = np.median(aucs, axis = 0)\n",
    "    mad_aucs = np.median(np.abs(aucs - np.median(aucs, axis=0)), axis=0)\n",
    "\n",
    "median_rocs = calculate_median_rocs(median_rocs)\n",
    "mean_rocs = calculate_mean_rocs(mean_rocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(median_rocs, open(\"results/allensbach_median_rocs\", 'wb'))\n",
    "pickle.dump(mean_rocs, open(\"results/allensbach_median_rocs\", 'wb'))\n",
    "pickle.dump(mrs_iterations, open(\"results/allensbach_mrs_iterations\", 'wb'))\n",
    "pickle.dump(drop, open(\"results/allensbach_drop\", \"wb\"))\n",
    "\n",
    "pickle.dump(median_aucs, open(\"results/allensbach_median_aucs\", 'wb'))\n",
    "pickle.dump(std_aucs, open(\"results/allensbach_std_aucs\", 'wb'))\n",
    "pickle.dump(median_mmds, open(\"results/allensbach_median_mmds\", 'wb'))\n",
    "pickle.dump(std_mmds, open(\"results/allensbach_std_mmds\", 'wb'))\n",
    "\n",
    "pickle.dump(mean_aucs, open(\"results/allensbach_median_aucs\", 'wb'))\n",
    "pickle.dump(mad_aucs, open(\"results/allensbach_std_aucs\", 'wb'))\n",
    "pickle.dump(mean_mmds, open(\"results/allensbach_median_mmds\", 'wb'))\n",
    "pickle.dump(mad_mmds, open(\"results/allensbach_std_mmds\", 'wb'))\n",
    "\n",
    "pickle.dump(mmd_iteration, (open(\"results/allensbach_mmd_iteration\", 'wb')))\n",
    "pickle.dump(len(allensbach[allensbach['label']  == 1]), (open(\"results/allensbach_len\", 'wb')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load  results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "allensbach_median_rocs = pickle.load(open(\"results/allensbach_median_rocs\", \"rb\"))\n",
    "allensbach_mean_rocs = pickle.load(open(\"results/allensbach_mean_rocs\", \"rb\"))\n",
    "allensbach_mrs_iterations =  pickle.load(open(\"results/allensbach_mrs_iterations\", 'rb'))\n",
    "allensbach_drop = pickle.load(open(\"results/allensbach_drop\", 'rb'))\n",
    "allensbach_mmd_iteration = pickle.load(open(\"results/allensbach_mmd_iteration\", 'rb'))\n",
    "allensbach_len = pickle.load(open(\"results/allensbach_len\", 'rb'))\n",
    "\n",
    "allensbach_mean_aucs = pickle.load(open(\"results/allensbach_mean_aucs\", \"rb\"))\n",
    "allensbach_std_aucs = pickle.load(open(\"results/allensbach_std_aucs\", \"rb\"))\n",
    "allensbach_mean_mmds =  pickle.load(open(\"results/allensbach_mean_mmds\", 'rb'))\n",
    "allensbach_std_mmds =  pickle.load(open(\"results/allensbach_std_mmds\", 'rb'))\n",
    "\n",
    "allensbach_median_aucs = pickle.load(open(\"results/allensbach_median_aucs\", \"rb\"))\n",
    "allensbach_mad_aucs = pickle.load(open(\"results/allensbach_mad_aucs\", \"rb\"))\n",
    "allensbach_median_mmds =  pickle.load(open(\"results/allensbach_median_mmds\", 'rb'))\n",
    "allensbach_mad_mmds =  pickle.load(open(\"results/allensbach_mad_mmds\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/allensbach/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "mmd_iteration = 1\n",
    "\n",
    "plot_auc_average(allensbach_median_aucs, allensbach_mad_aucs, allensbach_drop,\n",
    "                 file_directory +\"allensbach_auc_with_iterations_median\", allensbach_len, save=save,\n",
    "                 mrs_iterations=allensbach_mrs_iterations)\n",
    "plot_auc_average(allensbach_mean_aucs, allensbach_std_aucs, allensbach_drop,\n",
    "                 file_directory +\"allensbach_auc_with_iterations_mean\", allensbach_len, save=save,\n",
    "                 mrs_iterations=allensbach_mrs_iterations)\n",
    "\n",
    "plot_rocs(allensbach_mean_rocs, file_directory+\"allensbach_mean_rocs\", save=save)\n",
    "plot_rocs(allensbach_median_rocs, file_directory+\"allensbach_median_rocs\", save=save)\n",
    "\n",
    "plot_mmds_average(allensbach_median_mmds, allensbach_mad_mmds, allensbach_drop, allensbach_mmd_iteration,\n",
    "                  file_directory + \"median_mmds_allensbach\", allensbach_mrs_iterations, allensbach_len, save=save)\n",
    "plot_mmds_average(allensbach_mean_mmds, allensbach_std_mmds, allensbach_drop, allensbach_mmd_iteration,\n",
    "                  file_directory + \"mean_mmds_allensbach\", allensbach_mrs_iterations, allensbach_len, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Experiment 2 b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### <font color='darkgreen'>Load Gesis</font>  <a name=\"us\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gesis = pd.read_csv(os.path.join(path, 'data/gesis_processed.csv'), engine='python')\n",
    "gbs = pd.read_csv(os.path.join(path, 'data/gbs_processed.csv'), engine='python')\n",
    "\n",
    "gesis_columns = ['Geschlecht', 'Geburtsjahr', 'Geburtsland',\n",
    "       'Nationalitaet', 'Familienstand', 'Hoechster Bildungsabschluss',\n",
    "       'Berufliche Ausbildung', 'Erwerbstaetigkeit', 'Nettoeinkommen Selbst',\n",
    "       'Zufriedenheit Wahlergebnis', 'Gesellig', 'Andere kritisieren',\n",
    "       'Gruendlich', 'Nervoes', 'Phantasievoll', 'Berufsgruppe', 'Wahlteilnahme', 'BRS6']\n",
    "\n",
    "N = gbs.copy()\n",
    "R = gesis.copy()\n",
    "\n",
    "N['label'] = 1\n",
    "R['label'] = 0\n",
    "\n",
    "gesis_gbs = pd.concat([N, R], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop = 5\n",
    "number_of_splits = 5\n",
    "cv = 5\n",
    "\n",
    "repetitions = 10\n",
    "number_of_iterations = int(len(gesis_gbs[gesis_gbs['label'] == 1]) / drop)\n",
    "\n",
    "aucs = []\n",
    "mean_rocs = []\n",
    "median_rocs = []\n",
    "mmds = []\n",
    "mmd_iteration = 1\n",
    "mrs_iterations = []\n",
    "\n",
    "for _ in tqdm(range(repetitions)):\n",
    "    auc, mean_roc, median_roc, mrs, mmd, mrs_iteration = repeated_MRS(gesis_gbs, gesis_columns,\n",
    "                                                     number_of_splits=number_of_splits,\n",
    "                        n_drop=drop,  cv=cv, number_of_iterations=number_of_iterations)\n",
    "    aucs.append(auc)\n",
    "    mean_rocs.append(mean_roc)\n",
    "    median_rocs.append(median_roc)\n",
    "    mmds.append(mmd)\n",
    "    mrs_iterations.append(mrs_iteration)\n",
    "\n",
    "    mean_mmds = np.mean(mmds, axis = 0)\n",
    "    std_mmds = np.std(mmds, axis = 0)\n",
    "    mean_aucs = np.mean(aucs, axis = 0)\n",
    "    std_aucs = np.std(aucs, axis = 0)\n",
    "\n",
    "    median_mmds = np.median(mmds, axis = 0)\n",
    "    mad_mmds = np.median(np.abs(mmds - np.median(mmds, axis=0)), axis=0)\n",
    "    median_aucs = np.median(aucs, axis = 0)\n",
    "    mad_aucs = np.median(np.abs(aucs - np.median(aucs, axis=0)), axis=0)\n",
    "\n",
    "median_rocs = calculate_median_rocs(median_rocs)\n",
    "mean_rocs = calculate_mean_rocs(mean_rocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(median_aucs, open(\"results/gesis_median_aucs\", 'wb'))\n",
    "pickle.dump(std_aucs, open(\"results/gesis_std_aucs\", 'wb'))\n",
    "pickle.dump(median_rocs, open(\"results/gesis_median_rocs\", 'wb'))\n",
    "pickle.dump(median_mmds, open(\"results/gesis_median_mmds\", 'wb'))\n",
    "pickle.dump(std_mmds, open(\"results/gesis_std_mmds\", 'wb'))\n",
    "pickle.dump(mrs_iterations, open(\"results/gesis_mrs_iterations\", 'wb'))\n",
    "pickle.dump(drop, open(\"results/gesis_drop\", \"wb\"))\n",
    "pickle.dump(mmd_iteration, open(\"results/gesis_mmd_iteration\", 'wb'))\n",
    "pickle.dump(len(gbs), open('results/len_gbs', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gesis_median_aucs = pickle.load(open(\"results/gesis_median_aucs\", 'rb'))\n",
    "gesis_std_aucs = pickle.load(open(\"results/gesis_std_aucs\", 'rb'))\n",
    "gesis_median_rocs =  pickle.load(open(\"results/gesis_median_rocs\", 'rb'))\n",
    "gesis_mrs_iterations =  pickle.load(open(\"results/gesis_mrs_iterations\", 'rb'))\n",
    "gesis_median_mmds =  pickle.load(open(\"results/gesis_median_mmds\", 'rb'))\n",
    "gesis_std_mmds =  pickle.load(open(\"results/gesis_std_mmds\", 'rb'))\n",
    "gesis_drop = pickle.load(open(\"results/gesis_drop\", 'rb'))\n",
    "gesis_mmd_iteration = pickle.load(open(\"results/gesis_mmd_iteration\", 'rb'))\n",
    "len_gbs = pickle.load(open('results/len_gbs', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/gesis/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "\n",
    "plot_auc_average(gesis_median_aucs, gesis_std_aucs, gesis_drop,\n",
    "                 file_directory +\"gesis_auc_with_iterations\", len_gbs, save=save,\n",
    "                 mrs_iterations=gesis_mrs_iterations)\n",
    "plot_rocs(gesis_median_rocs, file_directory+\"gesis_rocs\", save=save)\n",
    "plot_mmds_average(gesis_median_mmds, gesis_std_mmds, gesis_drop, gesis_mmd_iteration,\n",
    "                  file_directory + \"median_mmds_gesis\", gesis_mrs_iterations, len_gbs, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Compare MRS with temperature sampling and sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop = 5\n",
    "number_of_splits = 5\n",
    "\n",
    "cv= 5\n",
    "repetitions = 10\n",
    "number_of_iterations = int(len(gesis_gbs[gesis_gbs['label'] == 1]) / drop)\n",
    "aucs_without_temperature = []\n",
    "mmds_without_temperature = []\n",
    "mrs_iterations = []\n",
    "mmd_iteration = 1\n",
    "    \n",
    "for _ in tqdm(range(repetitions)):\n",
    "    auc, roc, mrs, mmd, mrs_iteration = repeated_MRS(gesis_gbs, gesis_columns,\n",
    "                     number_of_splits=number_of_splits,\n",
    "                    n_drop=drop, cv=cv,\n",
    "                                                 number_of_iterations=number_of_iterations, \n",
    "                                                     temperature_sampling=False)\n",
    "    \n",
    "    aucs_without_temperature.append(auc)\n",
    "    mmds_without_temperature.append(mmd)\n",
    "    mrs_iterations.append(mrs_iteration)\n",
    "\n",
    "\n",
    "    mean_mmds = np.mean(mmds_without_temperature, axis = 0)\n",
    "    std_mmds = np.std(mmds_without_temperature, axis = 0)\n",
    "    mean_aucs = np.mean(aucs_without_temperature, axis = 0)\n",
    "    std_aucs = np.std(aucs_without_temperature, axis = 0)\n",
    "\n",
    "    median_mmds = np.median(mmds_without_temperature, axis = 0)\n",
    "    mad_mmds = np.median(np.abs(mmds_without_temperature - np.median(mmds_without_temperature, axis=0)), axis=0)\n",
    "    median_aucs = np.median(aucs_without_temperature, axis = 0)\n",
    "    mad_aucs = np.median(np.abs(aucs_without_temperature - np.median(aucs_without_temperature, axis=0)), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(median_aucs, open(\"results/median_aucs_without_temperature\", 'wb'))\n",
    "pickle.dump(mad_aucs, open(\"results/mad_aucs_without_temperature\", 'wb'))\n",
    "pickle.dump(median_mmds, open(\"results/median_mmds_without_temperature\", 'wb'))\n",
    "pickle.dump(mad_mmds, open(\"results/mad_mmds_without_temperature\", 'wb'))\n",
    "\n",
    "pickle.dump(mean_aucs, open(\"results/mean_aucs_without_temperature\", 'wb'))\n",
    "pickle.dump(std_aucs, open(\"results/std_aucs_without_temperature\", 'wb'))\n",
    "pickle.dump(mean_mmds, open(\"results/mean_mmds_without_temperature\", 'wb'))\n",
    "pickle.dump(std_mmds, open(\"results/std_mmds_without_temperature\", 'wb'))\n",
    "\n",
    "pickle.dump(mrs_iterations, open(\"results/mrs_iterations_without_temperature\", 'wb'))\n",
    "pickle.dump(drop, open(\"results/drop_without_temperature\", 'wb'))\n",
    "pickle.dump(mmd_iteration, open(\"results/mmd_iteration_without_temperature\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load saved results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mean_aucs_without_temperature = pickle.load(open(\"results/mean_aucs_without_temperature\", 'rb'))\n",
    "std_aucs_without_temperature = pickle.load(open(\"results/std_aucs_without_temperature\", 'rb'))\n",
    "mean_aucs_temperature = pickle.load(open(\"results/gesis_mean_aucs\", 'rb'))\n",
    "std_aucs_temperature = pickle.load(open(\"results/gesis_std_aucs\", 'rb'))\n",
    "mean_mmds_without_temperature = pickle.load(open(\"results/mean_mmds_without_temperature\", 'rb'))\n",
    "std_mmds_without_temperature = pickle.load(open(\"results/std_mmds_without_temperature\", 'rb'))\n",
    "gesis_mean_mmds = pickle.load(open(\"results/gesis_mean_mmds\", 'rb'))\n",
    "gesis_std_mmds = pickle.load(open(\"results/gesis_std_mmds\", 'rb'))\n",
    "\n",
    "median_aucs_without_temperature = pickle.load(open(\"results/median_aucs_without_temperature\", 'rb'))\n",
    "mad_aucs_without_temperature = pickle.load(open(\"results/mad_aucs_without_temperature\", 'rb'))\n",
    "median_aucs_temperature = pickle.load(open(\"results/gesis_median_aucs\", 'rb'))\n",
    "mad_aucs_temperature = pickle.load(open(\"results/gesis_mad_aucs\", 'rb'))\n",
    "median_mmds_without_temperature = pickle.load(open(\"results/mean_mmds_without_temperature\", 'rb'))\n",
    "mad_mmds_without_temperature = pickle.load(open(\"results/mad_mmds_without_temperature\", 'rb'))\n",
    "gesis_median_mmds = pickle.load(open(\"results/gesis_mean_mmds\", 'rb'))\n",
    "gesis_mad_mmds = pickle.load(open(\"results/gesis_mad_mmds\", 'rb'))\n",
    "\n",
    "mrs_iterations_without_temperature = pickle.load(open(\"results/mrs_iterations_without_temperature\", 'rb'))\n",
    "drop_without_temperature = pickle.load(open(\"results/drop_without_temperature\", 'rb'))\n",
    "mmd_iteration_without_temperature = pickle.load(open(\"results/mmd_iteration_without_temperature\", 'rb'))\n",
    "len_gbs = pickle.load(open('results/len_gbs', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "experiment_label = 'MRS without temperature sampling'\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/temperature_comparison/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "save = True\n",
    "\n",
    "plot_experiment_comparison_auc(mean_aucs_temperature, std_aucs_temperature, mean_aucs_without_temperature,\n",
    "                            std_aucs_without_temperature, experiment_label,\n",
    "                                drop_without_temperature, file_directory + 'aucs_temperature_mean', len_gbs,\n",
    "                               save=save)   \n",
    "plot_experiment_comparison_mmd(gesis_mean_mmds, gesis_std_mmds,  mean_mmds_without_temperature,\n",
    "                               std_mmds_without_temperature, \n",
    "                               experiment_label, drop_without_temperature, mmd_iteration_without_temperature, \n",
    "                               file_directory + 'mmds_temperature_mean', len_gbs, save=save)\n",
    "\n",
    "plot_experiment_comparison_auc(median_aucs_temperature, mad_aucs_temperature, median_aucs_without_temperature,\n",
    "                            mad_aucs_without_temperature, experiment_label,\n",
    "                                drop_without_temperature, file_directory + 'aucs_temperature_median', len_gbs,\n",
    "                               save=save)\n",
    "plot_experiment_comparison_mmd(gesis_median_mmds, gesis_mad_mmds,  median_mmds_without_temperature,\n",
    "                               mad_mmds_without_temperature,\n",
    "                               experiment_label, drop_without_temperature, mmd_iteration_without_temperature,\n",
    "                               file_directory + 'mmds_temperature_median', len_gbs, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Compare MRS with cross-validation and without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mrs_without_cv(N: pd.DataFrame, R: pd.DataFrame, columns: list, n_drop: int=1):\n",
    "    EPSILON = 10e-16 # to avoid dividing by zero\n",
    "    bootstrap_iterations = 25\n",
    "    bootstrap_predictions_n = np.zeros(len(N))\n",
    "    bootstrap_predictions_r = np.zeros(len(R))\n",
    "    counter_n = np.zeros(len(N))\n",
    "    counter_r = np.zeros(len(R))\n",
    "    \n",
    "    n = min(len(R), len(N))\n",
    "    for _ in range(bootstrap_iterations):\n",
    "        n_sample = N.sample(n=n, replace=True)\n",
    "        N_test = N.drop(n_sample.index)\n",
    "        r_sample = R.sample(n=n, replace=True)\n",
    "        R_test = R.drop(r_sample.index)\n",
    "        locations_not_in_bootstrap_n = list(set([N.index.get_loc(index) for index in N_test.index]))\n",
    "        locations_not_in_bootstrap_r = list(set([R.index.get_loc(index) for index in R_test.index]))\n",
    "        \n",
    "        bootstrap = pd.concat([n_sample, r_sample])\n",
    "        clf = grid_search(bootstrap[columns], bootstrap.label, 5)\n",
    "        proba_n = clf.predict_proba(N_test[columns])[:,1]\n",
    "        proba_r = clf.predict_proba(R_test[columns])[:,1]\n",
    "        bootstrap_single_n = np.zeros(len(N))\n",
    "        bootstrap_single_n[list(locations_not_in_bootstrap_n)] = proba_n\n",
    "        counter_n[list(locations_not_in_bootstrap_n)] += 1\n",
    "        bootstrap_predictions_n += bootstrap_single_n\n",
    "        \n",
    "        bootstrap_single_r = np.zeros(len(R))\n",
    "        bootstrap_single_r[list(locations_not_in_bootstrap_r)] = proba_r\n",
    "        counter_r[list(locations_not_in_bootstrap_r)] += 1\n",
    "        bootstrap_predictions_r += bootstrap_single_r\n",
    "        \n",
    "    counter_n = [EPSILON if x == 0 else x for x in counter_n]\n",
    "    counter_r = [EPSILON if x == 0 else x for x in counter_r]\n",
    "    preds_n = bootstrap_predictions_n / counter_n\n",
    "    preds_r = bootstrap_predictions_r / counter_r\n",
    "    \n",
    "    all_preds = np.concatenate([preds_n, preds_r])\n",
    "    all_true = np.concatenate([np.ones(len(preds_n)), np.zeros(len(preds_r))])\n",
    "    auc = roc_auc_score(all_true, all_preds)\n",
    "    mapped_auc = abs(auc - 0.5)\n",
    "    temperature = -0.55 * mapped_auc + 0.3\n",
    "    drop_ids = temperature_sample(preds_n, temperature, n_drop)\n",
    "    return N.drop(N.index[drop_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def repeated_MRS_without_cv(df, columns, number_of_splits, n_drop=1, cv=5, us=False, census_bias='', number_of_iterations=None):\n",
    "    \n",
    "    N = df[df['label'] == 1].copy()\n",
    "    R = df[df['label'] == 0].copy()\n",
    "    if number_of_iterations is None:\n",
    "        number_of_iterations = int(len(N) / drop)\n",
    "    aucs = []\n",
    "    ratio = []\n",
    "    mmds = []\n",
    "    mmd_iteration = 1\n",
    "    \n",
    "    auroc_iteration = int(int(len(N) / n_drop) / 3.5) + 1\n",
    "    \n",
    "    if us:\n",
    "        ratio.extend([len(N[N[census_bias] == 1]) / \n",
    "                         (len(N[N[census_bias] == 0]))]*drop)\n",
    "        \n",
    "    #start value\n",
    "    auc, _, _ = auc_prediction(N, R, columns, drop, 0, cv, False)\n",
    "    aucs.append(auc)\n",
    "    mmds.append(compute_maximum_mean_discrepancy(N[columns], R[columns]))\n",
    "    \n",
    "    best_auc = auc\n",
    "    mrs_iteration = 0\n",
    "    min_delta = 0.005\n",
    "    mrs = N\n",
    "    \n",
    "    for i in tqdm(range(number_of_iterations)):\n",
    "        N = mrs_without_cv(N, R, columns, n_drop=n_drop)\n",
    "        auc, _, _ = auc_prediction(N, R, columns, drop, i+1, cv, calculate_roc=False)\n",
    "        aucs.append(auc)\n",
    "        \n",
    "        if abs(auc - 0.5) < abs(best_auc - 0.5) - min_delta:\n",
    "            best_auc = auc\n",
    "            mrs_iteration = (i + 1) * n_drop\n",
    "            mrs = N.copy(deep=True)\n",
    "\n",
    "        if (i+1) % mmd_iteration == 0:\n",
    "            mmds.append(compute_maximum_mean_discrepancy(N[columns], R[columns]))\n",
    "            \n",
    "        if len(N)-drop <= cv or len(N)-drop <= number_of_splits:\n",
    "            break\n",
    "    \n",
    "    return aucs, mrs, mmds, mrs_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop = 5\n",
    "number_of_splits = 5\n",
    "\n",
    "number_of_iterations = int(len(gesis_gbs[gesis_gbs['label']  == 1]) / drop)\n",
    "repetitions = 10\n",
    "cv = 5\n",
    "aucs_without_cv = []\n",
    "mmds_without_cv = []\n",
    "mrs_iterations = []\n",
    "mmd_iteration = 1\n",
    "save=False\n",
    "    \n",
    "for temp in tqdm(range(repetitions)):\n",
    "    auc,  mrs, mmd, mrs_iteration = repeated_MRS_without_cv(gesis_gbs, gesis_columns,\n",
    "                    number_of_splits=number_of_splits,\n",
    "                    n_drop=drop,  cv=cv, number_of_iterations=number_of_iterations)\n",
    "    \n",
    "    aucs_without_cv.append(auc)\n",
    "    mmds_without_cv.append(mmd)\n",
    "    mrs_iterations.append(mrs_iteration)\n",
    "\n",
    "    mean_mmds = np.mean(mmds_without_cv, axis = 0)\n",
    "    std_mmds = np.std(mmds_without_cv, axis = 0)\n",
    "    mean_aucs = np.mean(aucs_without_cv, axis = 0)\n",
    "    std_aucs = np.std(aucs_without_cv, axis = 0)\n",
    "\n",
    "    median_mmds = np.median(mmds_without_cv, axis = 0)\n",
    "    mad_mmds = np.median(np.abs(mmds_without_cv - np.median(mmds_without_cv, axis=0)), axis=0)\n",
    "    median_aucs = np.median(aucs_without_cv, axis = 0)\n",
    "    mad_aucs = np.median(np.abs(aucs_without_cv - np.median(aucs_without_cv, axis=0)), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(median_aucs, open(\"results/median_aucs_without_cv\", 'wb'))\n",
    "pickle.dump(mad_aucs, open(\"results/mad_aucs_without_cv\", 'wb'))\n",
    "pickle.dump(median_mmds, open(\"results/median_mmds_without_cv\", 'wb'))\n",
    "pickle.dump(mad_mmds, open(\"results/mad_mmds_without_cv\", 'wb'))\n",
    "\n",
    "pickle.dump(mean_aucs, open(\"results/mean_aucs_without_cv\", 'wb'))\n",
    "pickle.dump(std_aucs, open(\"results/std_aucs_without_cv\", 'wb'))\n",
    "pickle.dump(mean_mmds, open(\"results/mean_mmds_without_cv\", 'wb'))\n",
    "pickle.dump(std_mmds, open(\"results/std_mmds_without_cv\", 'wb'))\n",
    "\n",
    "pickle.dump(mrs_iterations, open(\"results/mrs_iterations_without_cv\", 'wb'))\n",
    "pickle.dump(drop, open(\"results/drop_without_cv\", 'wb'))\n",
    "pickle.dump(mmd_iteration, open(\"results/mmd_iteration_without_cv\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gesis_median_aucs = pickle.load(open(\"results/gesis_median_aucs\", 'rb'))\n",
    "gesis_mad_aucs = pickle.load(open(\"results/gesis_mad_aucs\", 'rb'))\n",
    "median_aucs_without_cv = pickle.load(open(\"results/median_aucs_without_cv\", 'rb'))\n",
    "mad_aucs_without_cv = pickle.load(open(\"results/mad_aucs_without_cv\", 'rb'))\n",
    "median_mmds_without_cv = pickle.load(open(\"results/median_mmds_without_cv\", 'rb'))\n",
    "mad_mmds_without_cv = pickle.load(open(\"results/mad_mmds_without_cv\", 'rb'))\n",
    "gesis_median_mmds = pickle.load(open(\"results/gesis_median_mmds\", 'rb'))\n",
    "gesis_mad_mmds = pickle.load(open(\"results/gesis_mad_mmds\", 'rb'))\n",
    "\n",
    "gesis_mean_aucs = pickle.load(open(\"results/gesis_mean_aucs\", 'rb'))\n",
    "gesis_std_aucs = pickle.load(open(\"results/gesis_std_aucs\", 'rb'))\n",
    "mean_aucs_without_cv = pickle.load(open(\"results/mean_aucs_without_cv\", 'rb'))\n",
    "std_aucs_without_cv = pickle.load(open(\"results/std_aucs_without_cv\", 'rb'))\n",
    "mean_mmds_without_cv = pickle.load(open(\"results/mean_mmds_without_cv\", 'rb'))\n",
    "std_mmds_without_cv = pickle.load(open(\"results/std_mmds_without_cv\", 'rb'))\n",
    "gesis_mean_mmds = pickle.load(open(\"results/gesis_mean_mmds\", 'rb'))\n",
    "gesis_std_mmds = pickle.load(open(\"results/gesis_std_mmds\", 'rb'))\n",
    "\n",
    "mrs_iterations_without_cv = pickle.load(open(\"results/mrs_iterations_without_cv\", 'rb'))\n",
    "drop_without_cv = pickle.load(open(\"results/drop_without_temperature\", 'rb'))\n",
    "mmd_iteration_without_cv = pickle.load(open(\"results/mmd_iteration_without_temperature\", 'rb'))\n",
    "len_gbs = pickle.load(open('results/len_gbs', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/cross_validation_comparison/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "\n",
    "experiment_label = 'MRS without cross-validation'\n",
    " \n",
    "plot_experiment_comparison_auc(gesis_median_aucs, gesis_std_aucs, median_aucs_without_cv, \n",
    "                                std_aucs_without_cv, experiment_label, drop_without_cv, \n",
    "                           file_directory+'auc_cv', len_gbs, save=save)    \n",
    "plot_experiment_comparison_mmd(gesis_median_mmds, gesis_std_mmds,  median_mmds_without_cv, \n",
    "                               std_mmds_without_cv, \n",
    "                               experiment_label, drop_without_cv, mmd_iteration_without_cv, \n",
    "                               file_directory+'mmd_cv', len_gbs, save=save)\n",
    "\n",
    "plot_experiment_comparison_auc(gesis_mean_aucs, gesis_std_aucs, mean_aucs_without_cv,\n",
    "                                std_aucs_without_cv, experiment_label, drop_without_cv,\n",
    "                           file_directory+'auc_cv_mean', len_gbs, save=save)\n",
    "plot_experiment_comparison_mmd(gesis_median_mmds, gesis_mad_mmds,  median_mmds_without_cv,\n",
    "                               mad_mmds_without_cv,\n",
    "                               experiment_label, drop_without_cv, mmd_iteration_without_cv,\n",
    "                               file_directory+'mmd_cv_median', len_gbs, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Random drops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop = 5\n",
    "cv = 5\n",
    "repetitions = 10\n",
    "number_of_splits = 5\n",
    "aucs_random_drop = []\n",
    "mmds = []\n",
    "mrs_iterations = []\n",
    "mmd_iteration = 1\n",
    "\n",
    "iterations = int(len(gesis_gbs[gesis_gbs['label'] == 1]) / drop)\n",
    "\n",
    "for _ in tqdm(range(repetitions)):\n",
    "    N = gesis_gbs[gesis_gbs['label'] == 1].copy()\n",
    "    R = gesis_gbs[gesis_gbs['label'] == 0].copy()\n",
    "    aucs = [] \n",
    "    mmd = []\n",
    "    \n",
    "    #start value\n",
    "    auc, _, _ = auc_prediction(N, R, gesis_columns, drop, 0, cv, False)\n",
    "    aucs.append(auc)\n",
    "    mmd.append(compute_maximum_mean_discrepancy(N[gesis_columns], R[gesis_columns]))\n",
    "    \n",
    "    best_auc = auc\n",
    "    mrs_iteration = 0\n",
    "    min_delta = 0.005\n",
    "    \n",
    "    for i in tqdm(range(iterations)):\n",
    "        drop_ids = random.sample(range(0, len(N)), drop)\n",
    "        N.drop(N.index[drop_ids], inplace=True)\n",
    "\n",
    "        auc, _ = auc_prediction(N, R, gesis_columns, drop, i+1, cv, calculate_roc=False)\n",
    "        aucs.append(auc)\n",
    "        \n",
    "        if abs(auc - 0.5) < abs(best_auc - 0.5) - min_delta:\n",
    "            best_auc = auc\n",
    "            mrs_iteration = (i + 1) * drop\n",
    "            \n",
    "        if (i+1) % mmd_iteration == 0:\n",
    "            mmd.append(compute_maximum_mean_discrepancy(N[gesis_columns], R[gesis_columns]))\n",
    "            \n",
    "        if len(N)-drop <= cv or len(N)-drop <= number_of_splits:\n",
    "            break\n",
    "        \n",
    "    mrs_iterations.append(mrs_iteration)\n",
    "    aucs_random_drop.append(aucs)\n",
    "    mmds.append(mmd)\n",
    "\n",
    "median_aucs_random_drop = np.median(aucs_random_drop, axis = 0)\n",
    "mean_aucs_random_drop = np.mean(aucs_random_drop, axis = 0)\n",
    "median_mmd_random_drop = np.median(mmds, axis = 0)\n",
    "mean_mmd_random_drop = np.mean(mmds, axis = 0)\n",
    "\n",
    "std_aucs_random_drop = np.std(aucs_random_drop, axis = 0)\n",
    "std_mmds_random_drop = np.std(mmds, axis = 0)\n",
    "mad_aucs_random_drop = np.median(np.abs(aucs_random_drop - np.median(aucs_random_drop, axis=0)), axis=0)\n",
    "mad_mmds_random_drop = np.median(np.abs(mmds - np.median(mmds, axis=0)), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(median_aucs_random_drop, open(\"results/median_aucs_random_drop\", 'wb'))\n",
    "pickle.dump(mad_aucs_random_drop, open(\"results/mad_aucs_random_drop\", 'wb'))\n",
    "pickle.dump(median_mmd_random_drop, open(\"results/median_mmds_random_drop\", 'wb'))\n",
    "pickle.dump(mad_mmds_random_drop, open(\"results/mad_mmds_random_drop\", 'wb'))\n",
    "\n",
    "pickle.dump(mean_aucs_random_drop, open(\"results/mean_aucs_random_drop\", 'wb'))\n",
    "pickle.dump(std_mmds_random_drop, open(\"results/std_mmds_random_drop\", 'wb'))\n",
    "pickle.dump(mean_mmd_random_drop, open(\"results/mean_mmds_random_drop\", 'wb'))\n",
    "pickle.dump(std_aucs_random_drop, open(\"results/std_aucs_random_drop\", 'wb'))\n",
    "\n",
    "pickle.dump(drop, open(\"results/random_drop_drop\", \"wb\"))\n",
    "pickle.dump(mmd_iteration, open(\"results/random_drop_mmd_iteration\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load saved results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "median_aucs_random_drop = pickle.load(open(\"results/median_aucs_random_drop\", 'rb'))\n",
    "mad_aucs_random_drop = pickle.load(open(\"results/mad_aucs_random_drop\", 'rb'))\n",
    "median_mmds_random_drop = pickle.load(open(\"results/median_mmds_random_drop\", 'rb'))\n",
    "mad_mmds_random_drop = pickle.load(open(\"results/mad_mmds_random_drop\", 'rb'))\n",
    "gesis_median_aucs = pickle.load(open(\"results/gesis_median_aucs\", 'rb'))\n",
    "gesis_mad_aucs = pickle.load(open(\"results/gesis_mad_aucs\", 'rb'))\n",
    "gesis_median_mmds = pickle.load(open(\"results/gesis_median_mmds\", 'rb'))\n",
    "gesis_mad_mmds = pickle.load(open(\"results/gesis_mad_mmds\", 'rb'))\n",
    "\n",
    "mean_aucs_random_drop = pickle.load(open(\"results/mean_aucs_random_drop\", 'rb'))\n",
    "std_aucs_random_drop = pickle.load(open(\"results/std_aucs_random_drop\", 'rb'))\n",
    "mean_mmds_random_drop = pickle.load(open(\"results/mean_mmds_random_drop\", 'rb'))\n",
    "std_mmds_random_drop = pickle.load(open(\"results/std_mmds_random_drop\", 'rb'))\n",
    "gesis_mean_aucs = pickle.load(open(\"results/gesis_mean_aucs\", 'rb'))\n",
    "gesis_std_aucs = pickle.load(open(\"results/gesis_std_aucs\", 'rb'))\n",
    "gesis_mean_mmds = pickle.load(open(\"results/gesis_mean_mmds\", 'rb'))\n",
    "gesis_std_mmds = pickle.load(open(\"results/gesis_std_mmds\", 'rb'))\n",
    "\n",
    "random_drop_mmd_iteration = pickle.load(open(\"results/random_drop_mmd_iteration\", \"rb\"))\n",
    "len_gbs = pickle.load(open('results/len_gbs', 'rb'))\n",
    "random_drop_drop = pickle.load(open(\"results/random_drop_drop\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file_directory = os.path.join(os.getcwd(), \"final_results/random/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "save = True\n",
    "experiment_label = 'Random drop'\n",
    "plot_experiment_comparison_auc(gesis_median_aucs, gesis_mad_aucs,\n",
    "                               median_aucs_random_drop, mad_aucs_random_drop,\n",
    "                               experiment_label, random_drop_drop, file_directory+'aucs_random_median', len_gbs, save)\n",
    "plot_experiment_comparison_mmd(gesis_median_mmds, gesis_mad_mmds,  median_mmds_random_drop,\n",
    "                               mad_mmds_random_drop,\n",
    "                               experiment_label, random_drop_drop, random_drop_mmd_iteration,\n",
    "                               file_directory+'mmd_random_median', len_gbs, save=save)\n",
    "\n",
    "plot_experiment_comparison_auc(gesis_mean_aucs, gesis_std_aucs,\n",
    "                               mean_aucs_random_drop, std_aucs_random_drop,\n",
    "                               experiment_label, random_drop_drop, file_directory+'aucs_random_mean', len_gbs, save)\n",
    "plot_experiment_comparison_mmd(gesis_mean_mmds, gesis_std_mmds,  mean_mmds_random_drop,\n",
    "                               std_mmds_random_drop,\n",
    "                               experiment_label, random_drop_drop, random_drop_mmd_iteration,\n",
    "                               file_directory+'mmd_random_mean', len_gbs, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Correlation between resilience and voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "number_of_mrs = 5\n",
    "mrs_list = []\n",
    "drop = 5\n",
    "number_of_splits = 5\n",
    "cv = 5\n",
    "number_of_iterations = int(len(allensbach[allensbach['label'] == 1]) / drop)\n",
    "mmd_iteration = 700\n",
    "\n",
    "for _ in tqdm(range(number_of_mrs)):\n",
    "    _, _, mrs, _, _ = repeated_MRS(allensbach, allensbach_columns,  number_of_splits=number_of_splits,\n",
    "                            n_drop=drop, cv=cv, number_of_iterations=number_of_iterations)\n",
    "    mrs_list.append(mrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save MRS list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "anonyme_list = []\n",
    "for mrs in mrs_list:\n",
    "    anonyme_list.append(mrs[['Resilienz', 'Wahlteilnahme']])\n",
    "all_mrs_elements = pd.concat(anonyme_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(all_mrs_elements, open(\"results/all_mrs_elements\", 'wb'))\n",
    "pickle.dump(anonyme_list, open(\"results/anonyme_list\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load MRS list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_mrs_elements = pickle.load(open(\"results/all_mrs_elements\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_mrs_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "allensbach_gbs = allensbach[allensbach['label'] == 1]\n",
    "allensbach_without_gbs = allensbach[allensbach['label'] == 0]\n",
    "bins = []\n",
    "for i in range(6, 32):\n",
    "    bins.append(round(i/6, 6))\n",
    "\n",
    "value = 'Resilienz'\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, sharex=True)\n",
    "\n",
    "weights_gbs = np.ones_like(allensbach_gbs[value]) / len(allensbach_gbs[value])\n",
    "weights_mrs = np.ones_like(all_mrs_elements[value]) / len(all_mrs_elements[value])\n",
    "weights_allensbach = np.ones_like(allensbach_without_gbs[value]) / len(allensbach_without_gbs[value])\n",
    "\n",
    "\n",
    "allensbach_without_gbs[value] = round(allensbach_without_gbs[value], 6)\n",
    "allensbach_without_gbs.plot.hist(y=value, bins=bins, ax=ax1, weights=weights_allensbach, ec='black')\n",
    "\n",
    "allensbach_gbs[value] = round(allensbach_gbs[value], 6)\n",
    "allensbach_gbs.plot.hist(y=value, bins=bins, ax=ax2, weights=weights_gbs, ec='black')\n",
    "\n",
    "all_mrs_elements[value] = round(all_mrs_elements[value], 6)\n",
    "all_mrs_elements.plot.hist(y=value, bins=bins, ax=ax3, weights=weights_mrs, ec='black')\n",
    "\n",
    "ax2.set_title('GBS')\n",
    "ax3.set_title('MRS')\n",
    "ax1.set_title('Allensbach')\n",
    "ax1.set_xticks([1, 2, 3, 4, 5])\n",
    "ax1.set_ylabel('Percent')\n",
    "\n",
    "file_directory = os.path.join(os.getcwd(), \"final_results/statistic/\")\n",
    "os.makedirs(file_directory, exist_ok=True)\n",
    "f.savefig(file_directory + f'/{value}_histogram.pdf')\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot cumulative distribution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, sharey=True, sharex=True)\n",
    "\n",
    "ax.hist(allensbach_without_gbs['Resilienz'], bins=bins, density=True, histtype='step',\n",
    "                           cumulative=True, label='Allensbach', color='orange', linewidth=2,\n",
    "       linestyle=':')\n",
    "ax.hist(allensbach_gbs['Resilienz'], bins=bins,  density=True, histtype='step',\n",
    "                           cumulative=True, color='blue', linestyle='-.', label='GBS', linewidth=2)\n",
    "ax.hist(all_mrs_elements['Resilienz'], bins=bins, density=True, histtype='step',\n",
    "                           cumulative=True, color='black', linestyle='-', label='All MRS', linewidth=2)\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_xticks([1, 2, 3, 4, 5])\n",
    "ax.set_title('Cumulative distribution functions')\n",
    "plt.xlim(1, 5)\n",
    "plt.savefig(file_directory + f'/{value}_comulative_density.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y, X = dmatrices('Wahlteilnahme ~ Resilienz', data=allensbach_gbs, return_type='dataframe')\n",
    "model_gbs = sm.Logit(y, X)\n",
    "results_gbs = model_gbs.fit() \n",
    "\n",
    "restricted_model_gbs = sm.Logit(y, X.drop(columns='Resilienz'))\n",
    "restricted_results_gbs = restricted_model_gbs.fit() \n",
    " \n",
    "y, X = dmatrices('Wahlteilnahme ~ Resilienz', data=all_mrs_elements, return_type='dataframe')\n",
    "model_all = sm.Logit(y, X)\n",
    "results_all = model_all.fit() \n",
    "\n",
    "restricted_model_all = sm.Logit(y, X.drop(columns='Resilienz'))\n",
    "restricted_results_all = restricted_model_all.fit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_gbs.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create mean models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Likelihood-ratio test GBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loglikelihood_full = results_gbs.llf\n",
    "loglikelihood_restr = restricted_results_gbs.llf\n",
    "lrstat = -2*(loglikelihood_restr - loglikelihood_full)\n",
    "lr_pvalue_gbs = stats.chi2.sf(lrstat, df=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Log Likelihood test MRS list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loglikelihood_full = results_all.llf\n",
    "loglikelihood_restr = restricted_results_all.llf\n",
    "lrstat = -2*(loglikelihood_restr - loglikelihood_full)\n",
    "lr_pvalue_all = stats.chi2.sf(lrstat, df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True)\n",
    "f.suptitle('Logistic regression with 95% Confidence Interval')\n",
    "ax1.set_title(f'GBS')\n",
    "ax1.set_ylabel('Probabilities')\n",
    "ax1.set_xlabel('BRS')\n",
    "ax1.set_xticks([1, 2, 3, 4, 5])\n",
    "\n",
    "intercept_gbs, slope_gbs = results_gbs.params\n",
    "x_line = np.linspace(1, 5, 200)\n",
    "x = allensbach_gbs['Resilienz']\n",
    "y = allensbach_gbs['Wahlteilnahme']\n",
    "log_odds  = slope_gbs * x_line + intercept_gbs\n",
    "y_line = 1 / (1+ np.exp(-log_odds))\n",
    "y_model = results_gbs.predict()\n",
    "x_mean = np.mean(x)\n",
    "n = x.size                        # number of samples\n",
    "m = 1                             # number of parameters\n",
    "dof = n - m  \n",
    "t = stats.t.ppf(0.975, dof)\n",
    "residual = y - y_model\n",
    "std_error = (np.sum(residual**2) / dof)**.5\n",
    "# confidence interval\n",
    "ci = t * std_error * (1/n + (x_line - x_mean)**2 / np.sum((x - x_mean)**2))**.5\n",
    "ci_high = [1 if i>1 else i for i in y_line + ci]\n",
    "ax1.plot(x_line, y_line)\n",
    "ax1.fill_between(x_line, ci_high, y_line - ci, alpha=0.3)\n",
    "\n",
    "intercept_all, slope_all = results_all.params\n",
    "x = all_mrs_elements['Resilienz']\n",
    "y = all_mrs_elements['Wahlteilnahme']\n",
    "log_odds  = slope_all * x_line + intercept_all\n",
    "y_line = 1 / (1 + np.exp(-log_odds))\n",
    "y_model = results_all.predict()\n",
    "x_mean = np.mean(x)\n",
    "n = x.size                        # number of samples\n",
    "m = 1                             # number of parameters\n",
    "dof = n - m  \n",
    "t = stats.t.ppf(0.975, dof)\n",
    "residual = y - y_model\n",
    "std_error = (np.sum(residual**2) / dof)**.5\n",
    "# confidence interval\n",
    "ci = t * std_error * (1/n + (x_line - x_mean)**2 / np.sum((x - x_mean)**2))**.5\n",
    "ci_low = y_line - ci\n",
    "ci_high = [1 if i>1 else i for i in y_line + ci]\n",
    "ax2.set_title('All MRS')\n",
    "ax2.set_xlabel('BRS')\n",
    "ax2.plot(x_line, y_line)\n",
    "ax2.fill_between(x_line, ci_low, ci_high, alpha=0.3)\n",
    "\n",
    "# Show the plot\n",
    "ax1.text(1, 0.99, f'p={round(lr_pvalue_gbs, 3)}',\n",
    "        bbox=dict(facecolor='none', edgecolor='black', pad=2))\n",
    "ax2.text(1, 0.99, f'p={round(lr_pvalue_all, 3)}', \n",
    "         bbox=dict(facecolor='none', edgecolor='black', pad=2))\n",
    "f.savefig(file_directory + '/glm_brs_wahlteilnahme.pdf')\n",
    "f.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrs",
   "language": "python",
   "name": "mrs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}